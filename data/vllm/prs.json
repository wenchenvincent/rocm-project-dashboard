{
  "collected_at": "2026-03-01T08:18:06Z",
  "prs": [
    {
      "number": 33747,
      "title": "feat(grpc): expose kv_connector and kv_role in GetServerInfoResponse",
      "author": "slin1237",
      "state": "open",
      "merged": false,
      "created_at": "2026-02-04T01:29:34Z",
      "updated_at": "2026-03-01T08:16:04Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/33747",
      "labels": [
        "documentation",
        "performance",
        "new-model",
        "rocm",
        "structured-output",
        "frontend",
        "speculative-decoding",
        "needs-rebase",
        "ci/build",
        "v1",
        "multi-modality",
        "llama",
        "qwen",
        "deepseek",
        "cpu",
        "gpt-oss",
        "kv-connector",
        "nvidia"
      ],
      "draft": false
    },
    {
      "number": 34931,
      "title": "[AMD][CI] Support Triton attention with ExampleConnector",
      "author": "rjrock",
      "state": "closed",
      "merged": true,
      "created_at": "2026-02-20T01:46:21Z",
      "updated_at": "2026-03-01T07:58:08Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/34931",
      "labels": [
        "rocm",
        "ready",
        "v1",
        "kv-connector"
      ],
      "draft": false
    },
    {
      "number": 35416,
      "title": "[CI] Enable Crosslayer KV layout tests for ROCm platforms",
      "author": "qli88",
      "state": "open",
      "merged": false,
      "created_at": "2026-02-26T15:50:53Z",
      "updated_at": "2026-03-01T06:44:47Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/35416",
      "labels": [
        "rocm",
        "ci/build",
        "v1",
        "kv-connector"
      ],
      "draft": false
    },
    {
      "number": 34046,
      "title": "[Feature][Scheduler] Add split prefix caching feature to eliminate bf16 GEMM tiling divergence across cache-hit/miss paths",
      "author": "AndreasKaratzas",
      "state": "open",
      "merged": false,
      "created_at": "2026-02-07T08:11:29Z",
      "updated_at": "2026-03-01T05:41:04Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/34046",
      "labels": [
        "performance",
        "rocm",
        "ready",
        "v1"
      ],
      "draft": false
    },
    {
      "number": 32070,
      "title": "[RFC] Improve environment variable declaration and handling (#31249)",
      "author": "nliu365",
      "state": "open",
      "merged": false,
      "created_at": "2026-01-10T01:06:48Z",
      "updated_at": "2026-03-01T05:26:59Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/32070",
      "labels": [
        "documentation",
        "performance",
        "new-model",
        "rocm",
        "structured-output",
        "frontend",
        "speculative-decoding",
        "ci/build",
        "v1",
        "multi-modality",
        "tool-calling",
        "llama",
        "qwen",
        "deepseek",
        "cpu",
        "gpt-oss",
        "kv-connector",
        "nvidia"
      ],
      "draft": false
    },
    {
      "number": 34556,
      "title": "[WIP][Quantization] add humming quantization kernel",
      "author": "jinzhen-lin",
      "state": "open",
      "merged": false,
      "created_at": "2026-02-14T14:05:10Z",
      "updated_at": "2026-03-01T04:23:18Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/34556",
      "labels": [],
      "draft": false
    },
    {
      "number": 35427,
      "title": "[Refactor] Fix maxsim cuda platform and add cli to control it",
      "author": "yewentao256",
      "state": "open",
      "merged": false,
      "created_at": "2026-02-26T17:37:18Z",
      "updated_at": "2026-03-01T03:50:19Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/35427",
      "labels": [
        "frontend",
        "ready",
        "nvidia"
      ],
      "draft": false
    },
    {
      "number": 35239,
      "title": "[ROCm][CI] Added MI325 mirrors (stage C)",
      "author": "AndreasKaratzas",
      "state": "open",
      "merged": false,
      "created_at": "2026-02-24T22:07:31Z",
      "updated_at": "2026-03-01T02:46:48Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/35239",
      "labels": [
        "rocm",
        "ready",
        "ci/build"
      ],
      "draft": false
    },
    {
      "number": 31941,
      "title": "LoRA Per Request Loading Pipelining Support",
      "author": "kfhfar",
      "state": "open",
      "merged": false,
      "created_at": "2026-01-08T03:27:58Z",
      "updated_at": "2026-03-01T02:31:53Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/31941",
      "labels": [
        "documentation",
        "ci/build",
        "v1",
        "gpt-oss",
        "nvidia"
      ],
      "draft": false
    },
    {
      "number": 29047,
      "title": "Online Rotations to vLLM",
      "author": "gametekker",
      "state": "open",
      "merged": false,
      "created_at": "2025-11-19T23:09:25Z",
      "updated_at": "2026-03-01T02:15:02Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/29047",
      "labels": [
        "documentation",
        "rocm",
        "needs-rebase",
        "ci/build",
        "stale",
        "llama"
      ],
      "draft": false
    },
    {
      "number": 35173,
      "title": "[Kernel] Immediately execute argument assertions in wvSplitK",
      "author": "wjabbour",
      "state": "open",
      "merged": false,
      "created_at": "2026-02-24T05:40:05Z",
      "updated_at": "2026-03-01T00:57:12Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/35173",
      "labels": [
        "rocm"
      ],
      "draft": false
    },
    {
      "number": 34692,
      "title": "[ROCm] Enable DeepEP ROCm as all2allbackend for AMD GPUs. ",
      "author": "lcskrishna",
      "state": "open",
      "merged": false,
      "created_at": "2026-02-17T11:53:31Z",
      "updated_at": "2026-02-28T23:16:52Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/34692",
      "labels": [
        "documentation",
        "rocm",
        "needs-rebase",
        "ci/build"
      ],
      "draft": true
    },
    {
      "number": 34709,
      "title": "[ROCm] Enable wvSplitK skinny GEMM kernel for RDNA4/gfx1x decode",
      "author": "laudney",
      "state": "open",
      "merged": false,
      "created_at": "2026-02-17T14:41:45Z",
      "updated_at": "2026-02-28T21:18:27Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/34709",
      "labels": [
        "new-model",
        "rocm",
        "needs-rebase",
        "ci/build"
      ],
      "draft": false
    },
    {
      "number": 34839,
      "title": "[ROCm][CI] Cleaning and restructuring amd-ci legacy pipeline",
      "author": "AndreasKaratzas",
      "state": "open",
      "merged": false,
      "created_at": "2026-02-18T18:25:14Z",
      "updated_at": "2026-02-28T21:12:51Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/34839",
      "labels": [
        "rocm",
        "ready",
        "ci/build"
      ],
      "draft": false
    },
    {
      "number": 35571,
      "title": "[ROCm][CI] Parametrize vision score tests across attention backends with per-backend tolerances",
      "author": "AndreasKaratzas",
      "state": "closed",
      "merged": true,
      "created_at": "2026-02-28T02:36:11Z",
      "updated_at": "2026-02-28T20:37:09Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/35571",
      "labels": [
        "rocm",
        "ready"
      ],
      "draft": false
    },
    {
      "number": 29184,
      "title": "[Core] NGram GPU Implementation compatible with Async Scheduler",
      "author": "PatchouliTIS",
      "state": "open",
      "merged": false,
      "created_at": "2025-11-21T14:42:44Z",
      "updated_at": "2026-02-28T16:02:23Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/29184",
      "labels": [
        "speculative-decoding",
        "ready",
        "v1",
        "ready-run-all-tests"
      ],
      "draft": false
    },
    {
      "number": 34644,
      "title": "[release 2.11] Update to torch 2.11-rc1",
      "author": "atalman",
      "state": "open",
      "merged": false,
      "created_at": "2026-02-16T19:54:58Z",
      "updated_at": "2026-02-28T15:44:18Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/34644",
      "labels": [
        "performance",
        "rocm",
        "ci/build",
        "v1",
        "llama",
        "cpu",
        "nvidia"
      ],
      "draft": false
    },
    {
      "number": 35601,
      "title": "[ROCm][Bugfix]: Disable AITER Triton ROPE by default",
      "author": "Rohan138",
      "state": "open",
      "merged": false,
      "created_at": "2026-02-28T08:17:44Z",
      "updated_at": "2026-02-28T15:22:15Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/35601",
      "labels": [
        "bug",
        "rocm",
        "ready"
      ],
      "draft": false
    },
    {
      "number": 35198,
      "title": "[ROCm] [Release] Change the package from `aiter` to `amd-aiter`",
      "author": "tjtanaa",
      "state": "open",
      "merged": false,
      "created_at": "2026-02-24T14:27:42Z",
      "updated_at": "2026-02-28T14:48:23Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/35198",
      "labels": [
        "rocm",
        "ready",
        "ci/build"
      ],
      "draft": false
    },
    {
      "number": 35485,
      "title": "[Bugfix][ROCm] Disable full CUDA graph capture on RDNA3/RDNA4 (gfx1x)",
      "author": "haosdent",
      "state": "closed",
      "merged": false,
      "created_at": "2026-02-27T07:11:06Z",
      "updated_at": "2026-02-28T14:33:25Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/35485",
      "labels": [
        "bug",
        "rocm",
        "nvidia"
      ],
      "draft": false
    },
    {
      "number": 35597,
      "title": "[ROCm][Quantization] Enable compressed-tensors WNA16 test on ROCm",
      "author": "brucechanglongxu",
      "state": "open",
      "merged": false,
      "created_at": "2026-02-28T07:18:19Z",
      "updated_at": "2026-02-28T14:23:34Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/35597",
      "labels": [
        "rocm",
        "ready"
      ],
      "draft": false
    },
    {
      "number": 35280,
      "title": "custom dataset img support base64",
      "author": "flutist",
      "state": "closed",
      "merged": true,
      "created_at": "2026-02-25T09:47:27Z",
      "updated_at": "2026-02-28T11:49:52Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/35280",
      "labels": [
        "documentation",
        "performance",
        "rocm",
        "frontend",
        "ready",
        "v1",
        "deepseek",
        "kv-connector",
        "nvidia"
      ],
      "draft": false
    },
    {
      "number": 33762,
      "title": "Add padding support to wvSplitK solution for skinny GEMMs",
      "author": "amd-hhashemi",
      "state": "closed",
      "merged": true,
      "created_at": "2026-02-04T04:33:02Z",
      "updated_at": "2026-02-28T09:02:06Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/33762",
      "labels": [
        "rocm",
        "ready"
      ],
      "draft": false
    },
    {
      "number": 34861,
      "title": "[1/N] Elastic EP Milestone 2",
      "author": "itayalroy",
      "state": "closed",
      "merged": true,
      "created_at": "2026-02-19T00:53:57Z",
      "updated_at": "2026-02-28T08:56:33Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/34861",
      "labels": [
        "rocm",
        "frontend",
        "ready",
        "ci/build",
        "v1",
        "multi-modality",
        "cpu",
        "nvidia"
      ],
      "draft": false
    },
    {
      "number": 35596,
      "title": "[ROCm][Quantization] Enable moe_wna16 on ROCm via Triton fallback",
      "author": "brucechanglongxu",
      "state": "open",
      "merged": false,
      "created_at": "2026-02-28T07:18:02Z",
      "updated_at": "2026-02-28T07:28:52Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/35596",
      "labels": [
        "rocm"
      ],
      "draft": false
    },
    {
      "number": 35245,
      "title": "[ROCm][WIP]: Fused aiter rope kvcache mla",
      "author": "Rohan138",
      "state": "open",
      "merged": false,
      "created_at": "2026-02-24T23:32:53Z",
      "updated_at": "2026-02-28T07:26:22Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/35245",
      "labels": [
        "rocm",
        "v1"
      ],
      "draft": true
    },
    {
      "number": 35595,
      "title": "[ROCm][Quantization] Enable experts_int8 on ROCm",
      "author": "brucechanglongxu",
      "state": "open",
      "merged": false,
      "created_at": "2026-02-28T07:17:35Z",
      "updated_at": "2026-02-28T07:20:56Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/35595",
      "labels": [
        "rocm"
      ],
      "draft": false
    },
    {
      "number": 35071,
      "title": "[ROCm][CI] Expose tests to AMD production CI and fix amdsmi heap corruption",
      "author": "AndreasKaratzas",
      "state": "closed",
      "merged": true,
      "created_at": "2026-02-23T01:18:34Z",
      "updated_at": "2026-02-28T05:58:36Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/35071",
      "labels": [
        "rocm",
        "ready",
        "ci/build"
      ],
      "draft": false
    },
    {
      "number": 35069,
      "title": "[ROCm] Derive device capability from GCN arch string without CUDA init",
      "author": "AndreasKaratzas",
      "state": "closed",
      "merged": true,
      "created_at": "2026-02-23T00:32:59Z",
      "updated_at": "2026-02-28T05:58:28Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/35069",
      "labels": [
        "rocm",
        "ready",
        "nvidia"
      ],
      "draft": false
    },
    {
      "number": 35170,
      "title": "[ROCm][CI] Adding infiniband mappings for moriio tests",
      "author": "AndreasKaratzas",
      "state": "closed",
      "merged": true,
      "created_at": "2026-02-24T05:18:40Z",
      "updated_at": "2026-02-28T05:57:46Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/35170",
      "labels": [
        "rocm",
        "ready",
        "ci/build",
        "v1",
        "kv-connector"
      ],
      "draft": false
    },
    {
      "number": 35152,
      "title": "[ROCm][CI] Disable skinny GEMMs in language model standard tests to fix non-determinism",
      "author": "AndreasKaratzas",
      "state": "open",
      "merged": false,
      "created_at": "2026-02-23T23:38:25Z",
      "updated_at": "2026-02-28T05:56:15Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/35152",
      "labels": [
        "rocm",
        "ready"
      ],
      "draft": false
    },
    {
      "number": 35560,
      "title": "[WIP][Bugfix][ROCm] Fix MXFP4 online quantization for MoE models at tp=1",
      "author": "SandishKumarHN",
      "state": "open",
      "merged": false,
      "created_at": "2026-02-27T22:58:02Z",
      "updated_at": "2026-02-28T05:46:00Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/35560",
      "labels": [
        "bug",
        "rocm",
        "needs-rebase"
      ],
      "draft": false
    },
    {
      "number": 30515,
      "title": "[UX][Startup] Account for CUDA graphs during memory profiling",
      "author": "MatthewBonanni",
      "state": "open",
      "merged": false,
      "created_at": "2025-12-11T21:12:12Z",
      "updated_at": "2026-02-28T04:52:48Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/30515",
      "labels": [
        "ready",
        "needs-rebase",
        "v1",
        "nvidia"
      ],
      "draft": false
    },
    {
      "number": 32104,
      "title": "Add tensor IPC transfer mechanism for multimodal data",
      "author": "brandonpelfrey",
      "state": "open",
      "merged": false,
      "created_at": "2026-01-11T04:00:35Z",
      "updated_at": "2026-02-28T04:52:07Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/32104",
      "labels": [
        "performance",
        "frontend",
        "needs-rebase",
        "v1",
        "multi-modality"
      ],
      "draft": false
    },
    {
      "number": 35466,
      "title": "[CI/Build] CPU release supports both of AVX2 and AVX512",
      "author": "majian4work",
      "state": "closed",
      "merged": true,
      "created_at": "2026-02-27T02:36:08Z",
      "updated_at": "2026-02-28T04:35:21Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/35466",
      "labels": [
        "ready",
        "ci/build",
        "v1",
        "cpu"
      ],
      "draft": false
    },
    {
      "number": 30908,
      "title": "[1/n] Migrate activation kernels to libtorch stable ABI",
      "author": "mikaylagawarecki",
      "state": "open",
      "merged": false,
      "created_at": "2025-12-17T22:49:35Z",
      "updated_at": "2026-02-28T04:26:27Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/30908",
      "labels": [
        "documentation",
        "rocm",
        "needs-rebase",
        "ci/build",
        "cpu",
        "nvidia"
      ],
      "draft": false
    },
    {
      "number": 35527,
      "title": "[ROCm] Add `stablelm` Head Size 80 To Supported Head Sizes For ROCM_ATTN",
      "author": "micah-wil",
      "state": "closed",
      "merged": true,
      "created_at": "2026-02-27T16:39:56Z",
      "updated_at": "2026-02-28T04:16:35Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/35527",
      "labels": [
        "documentation",
        "rocm",
        "ready",
        "v1"
      ],
      "draft": false
    },
    {
      "number": 35553,
      "title": "[ROCm][CI] Fix tool use test stability - disable skinny GEMM, prefix caching, eliminate batch variance",
      "author": "AndreasKaratzas",
      "state": "open",
      "merged": false,
      "created_at": "2026-02-27T21:58:47Z",
      "updated_at": "2026-02-28T04:03:11Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/35553",
      "labels": [
        "rocm",
        "ready"
      ],
      "draft": false
    },
    {
      "number": 34301,
      "title": "[ROCm][Quantization] Add Composable Kernel (CK) backend support for M\u2026",
      "author": "dllehr-amd",
      "state": "closed",
      "merged": true,
      "created_at": "2026-02-11T02:09:51Z",
      "updated_at": "2026-02-28T03:37:01Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/34301",
      "labels": [
        "rocm",
        "ready"
      ],
      "draft": false
    },
    {
      "number": 35105,
      "title": "[Refactor][Kernel] Add global helper to deduplicate vectorized memory ops",
      "author": "LopezCastroRoberto",
      "state": "closed",
      "merged": true,
      "created_at": "2026-02-23T14:50:44Z",
      "updated_at": "2026-02-28T00:28:17Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/35105",
      "labels": [
        "ready",
        "nvidia"
      ],
      "draft": false
    },
    {
      "number": 34285,
      "title": "[Refactor] Move FusedMoE hidden_size roundup to quant_method",
      "author": "BowenBao",
      "state": "open",
      "merged": false,
      "created_at": "2026-02-10T23:32:35Z",
      "updated_at": "2026-02-28T00:19:00Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/34285",
      "labels": [
        "nvidia"
      ],
      "draft": false
    },
    {
      "number": 35533,
      "title": "[ROCm]: fix aiter rope functionalization",
      "author": "Rohan138",
      "state": "closed",
      "merged": true,
      "created_at": "2026-02-27T17:49:51Z",
      "updated_at": "2026-02-27T22:42:31Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/35533",
      "labels": [
        "rocm",
        "ready"
      ],
      "draft": false
    },
    {
      "number": 35334,
      "title": "[ROCm] Enabling encoder and encoder-decoder on ROCm and AITER unified backends",
      "author": "gshtras",
      "state": "closed",
      "merged": true,
      "created_at": "2026-02-25T21:59:30Z",
      "updated_at": "2026-02-27T22:02:25Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/35334",
      "labels": [
        "documentation",
        "rocm",
        "ready",
        "v1"
      ],
      "draft": false
    },
    {
      "number": 35180,
      "title": "[ROCm]: Enable customop and rope+kvcache fusion for AITER RoPE",
      "author": "Rohan138",
      "state": "closed",
      "merged": true,
      "created_at": "2026-02-24T07:21:21Z",
      "updated_at": "2026-02-27T21:19:55Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/35180",
      "labels": [
        "rocm",
        "ready"
      ],
      "draft": false
    },
    {
      "number": 31481,
      "title": "[CI/Build] Add source build test to catch build failures early",
      "author": "mhetrerajat",
      "state": "open",
      "merged": false,
      "created_at": "2025-12-29T07:33:05Z",
      "updated_at": "2026-02-27T21:13:40Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/31481",
      "labels": [
        "ci/build"
      ],
      "draft": false
    },
    {
      "number": 34627,
      "title": "[Performance] Extract kv update ops from MLA attention backends",
      "author": "ElizaWszola",
      "state": "open",
      "merged": false,
      "created_at": "2026-02-16T15:21:08Z",
      "updated_at": "2026-02-27T21:12:03Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/34627",
      "labels": [
        "ready",
        "v1"
      ],
      "draft": false
    },
    {
      "number": 35404,
      "title": "[Bugfix][Model] Fix gpt-oss batch invariance",
      "author": "jzakrzew",
      "state": "closed",
      "merged": true,
      "created_at": "2026-02-26T14:36:10Z",
      "updated_at": "2026-02-27T20:41:24Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/35404",
      "labels": [
        "bug",
        "ready",
        "gpt-oss"
      ],
      "draft": false
    },
    {
      "number": 34265,
      "title": "[Attention][Perf][Kernel] Improve topKperRow for large context decode path - DeepSeek-V3.2 sparse attention",
      "author": "LopezCastroRoberto",
      "state": "open",
      "merged": false,
      "created_at": "2026-02-10T18:47:29Z",
      "updated_at": "2026-02-27T20:31:31Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/34265",
      "labels": [
        "performance",
        "rocm",
        "needs-rebase",
        "v1",
        "deepseek",
        "nvidia"
      ],
      "draft": true
    },
    {
      "number": 34304,
      "title": "Improvements to wvSplitKrc skinny GEMM solution",
      "author": "amd-hhashemi",
      "state": "open",
      "merged": false,
      "created_at": "2026-02-11T03:25:20Z",
      "updated_at": "2026-02-27T19:32:27Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/34304",
      "labels": [
        "rocm"
      ],
      "draft": false
    },
    {
      "number": 35538,
      "title": "docs: Add kernel/operator fusions reference page",
      "author": "Copilot",
      "state": "open",
      "merged": false,
      "created_at": "2026-02-27T19:04:35Z",
      "updated_at": "2026-02-27T19:12:16Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/35538",
      "labels": [
        "documentation"
      ],
      "draft": true
    },
    {
      "number": 35253,
      "title": "Enabling some B200-specific tests on MI355",
      "author": "Alexei-V-Ivanov-AMD",
      "state": "open",
      "merged": false,
      "created_at": "2026-02-25T01:40:05Z",
      "updated_at": "2026-02-27T17:57:02Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/35253",
      "labels": [
        "ci/build"
      ],
      "draft": false
    },
    {
      "number": 35182,
      "title": "[DO NOT MERGE] Reorganize inputs",
      "author": "DarkLight1337",
      "state": "open",
      "merged": false,
      "created_at": "2026-02-24T08:08:49Z",
      "updated_at": "2026-02-27T17:46:25Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/35182",
      "labels": [
        "documentation",
        "performance",
        "rocm",
        "frontend",
        "ready",
        "needs-rebase",
        "v1",
        "multi-modality",
        "llama",
        "qwen",
        "deepseek"
      ],
      "draft": false
    },
    {
      "number": 35246,
      "title": "[ROCm] Refactor ROCm attention backend selection logic",
      "author": "SageMoore",
      "state": "open",
      "merged": false,
      "created_at": "2026-02-25T00:25:26Z",
      "updated_at": "2026-02-27T17:24:59Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/35246",
      "labels": [
        "documentation",
        "rocm",
        "ready",
        "v1"
      ],
      "draft": false
    },
    {
      "number": 34390,
      "title": "[Kernel] [Helion] [7/N] Use HOP to represent Helion Kernel call to enable fx tracing and pattern matching",
      "author": "gmagogsfm",
      "state": "closed",
      "merged": true,
      "created_at": "2026-02-12T00:43:45Z",
      "updated_at": "2026-02-27T17:21:35Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/34390",
      "labels": [
        "rocm",
        "ready"
      ],
      "draft": false
    },
    {
      "number": 34760,
      "title": "Add platform method to enable custom collective ops registration",
      "author": "nkm-meta",
      "state": "open",
      "merged": false,
      "created_at": "2026-02-17T23:23:40Z",
      "updated_at": "2026-02-27T16:20:15Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/34760",
      "labels": [
        "rocm",
        "ready",
        "nvidia",
        "meta-exported",
        "fb-exported"
      ],
      "draft": false
    },
    {
      "number": 32419,
      "title": "Support ROCm aiter specific fusion of per_tensor RMSNorm+QuantFP8",
      "author": "tpopp",
      "state": "open",
      "merged": false,
      "created_at": "2026-01-15T16:25:44Z",
      "updated_at": "2026-02-27T14:58:57Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/32419",
      "labels": [
        "rocm"
      ],
      "draft": false
    },
    {
      "number": 34320,
      "title": "[Bugfix] Fix Dynamo unexpected keyword argument ",
      "author": "samutamm",
      "state": "closed",
      "merged": true,
      "created_at": "2026-02-11T08:27:18Z",
      "updated_at": "2026-02-27T14:05:07Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/34320",
      "labels": [
        "bug",
        "ready"
      ],
      "draft": false
    },
    {
      "number": 34798,
      "title": "[Mamba1] - Kernel Level Chunk Alignment for Prefix Caching",
      "author": "Josephasafg",
      "state": "open",
      "merged": false,
      "created_at": "2026-02-18T12:38:11Z",
      "updated_at": "2026-02-27T13:33:00Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/34798",
      "labels": [
        "ready",
        "v1"
      ],
      "draft": false
    },
    {
      "number": 32914,
      "title": "[ROCm][perf] Shuffle KV cache to use paged_attention_common",
      "author": "samutamm",
      "state": "open",
      "merged": false,
      "created_at": "2026-01-23T06:37:25Z",
      "updated_at": "2026-02-27T12:59:14Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/32914",
      "labels": [
        "rocm",
        "ready",
        "ci/build",
        "v1"
      ],
      "draft": false
    },
    {
      "number": 35491,
      "title": "[ROCm][Quantization] support amd-quark quantized Qwen3.5 model",
      "author": "xuebwang-amd",
      "state": "open",
      "merged": false,
      "created_at": "2026-02-27T07:27:40Z",
      "updated_at": "2026-02-27T07:28:36Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/35491",
      "labels": [
        "rocm",
        "qwen"
      ],
      "draft": true
    },
    {
      "number": 35483,
      "title": "Add AMD AITER MLA fusion optimization for DeepSeek models",
      "author": "khairulkabir1661",
      "state": "open",
      "merged": false,
      "created_at": "2026-02-27T06:47:13Z",
      "updated_at": "2026-02-27T06:53:52Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/35483",
      "labels": [
        "rocm",
        "deepseek"
      ],
      "draft": false
    },
    {
      "number": 35196,
      "title": "[ROCm] [CI] Gate the changes to `Dockerfile.rocm_base`.",
      "author": "tjtanaa",
      "state": "open",
      "merged": false,
      "created_at": "2026-02-24T14:22:55Z",
      "updated_at": "2026-02-27T04:32:10Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/35196",
      "labels": [
        "rocm",
        "ci/build"
      ],
      "draft": true
    },
    {
      "number": 30357,
      "title": "[ROCm][Quantization] GPT OSS Upstream MoE wmxfp4_afp8 with static scales",
      "author": "maleksan85",
      "state": "closed",
      "merged": true,
      "created_at": "2025-12-09T19:49:32Z",
      "updated_at": "2026-02-26T22:50:17Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/30357",
      "labels": [
        "rocm",
        "ready",
        "gpt-oss"
      ],
      "draft": false
    },
    {
      "number": 34307,
      "title": "[ROCm] [CI] Add new fusion test cases that are relevant to vLLM IR Ops",
      "author": "tjtanaa",
      "state": "open",
      "merged": false,
      "created_at": "2026-02-11T04:17:18Z",
      "updated_at": "2026-02-26T21:20:15Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/34307",
      "labels": [
        "rocm",
        "ready",
        "ci/build"
      ],
      "draft": false
    },
    {
      "number": 26847,
      "title": "[Frontend][torch.compile] CompilationConfig Overhaul (#20283): Set up -O infrastructure",
      "author": "morrison-turnansky",
      "state": "closed",
      "merged": true,
      "created_at": "2025-10-14T22:04:35Z",
      "updated_at": "2026-02-26T20:51:38Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/26847",
      "labels": [
        "documentation",
        "frontend",
        "speculative-decoding",
        "ready",
        "torch.compile",
        "v1",
        "llama",
        "nvidia",
        "ready-run-all-tests"
      ],
      "draft": false
    },
    {
      "number": 33271,
      "title": "[ROCm] Change default settings for ROCm",
      "author": "gshtras",
      "state": "open",
      "merged": false,
      "created_at": "2026-01-28T17:26:24Z",
      "updated_at": "2026-02-26T20:36:58Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/33271",
      "labels": [
        "rocm",
        "v1"
      ],
      "draft": false
    },
    {
      "number": 35316,
      "title": "[ROCm][Quantization] add quark w4a8 mxfp4_fp8 for LinearLayer",
      "author": "divakar-amd",
      "state": "open",
      "merged": false,
      "created_at": "2026-02-25T18:11:16Z",
      "updated_at": "2026-02-26T18:33:03Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/35316",
      "labels": [
        "rocm",
        "gpt-oss"
      ],
      "draft": false
    },
    {
      "number": 22070,
      "title": "[DO NOT MERGE] Enable HF processing on GPU",
      "author": "DarkLight1337",
      "state": "open",
      "merged": false,
      "created_at": "2025-08-01T08:25:21Z",
      "updated_at": "2026-02-26T17:35:58Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/22070",
      "labels": [
        "documentation",
        "performance",
        "frontend",
        "ready",
        "v1",
        "multi-modality"
      ],
      "draft": true
    },
    {
      "number": 35095,
      "title": "[MLA] Add fused Triton concat+quantize kernel for fp8 decode queries",
      "author": "elvircrn",
      "state": "open",
      "merged": false,
      "created_at": "2026-02-23T11:23:19Z",
      "updated_at": "2026-02-26T16:59:30Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/35095",
      "labels": [],
      "draft": true
    },
    {
      "number": 34387,
      "title": "[ROCm] Update the torch version in rocm_build.txt to use the official 2.10 release",
      "author": "SageMoore",
      "state": "closed",
      "merged": true,
      "created_at": "2026-02-11T23:42:16Z",
      "updated_at": "2026-02-26T16:28:46Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/34387",
      "labels": [
        "rocm",
        "ready",
        "ci/build"
      ],
      "draft": false
    },
    {
      "number": 34157,
      "title": "[ROCm] Add dynamic mxfp4 quantization for DeepSeek V2 projection layers",
      "author": "dllehr-amd",
      "state": "closed",
      "merged": true,
      "created_at": "2026-02-09T17:57:11Z",
      "updated_at": "2026-02-26T16:00:55Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/34157",
      "labels": [
        "rocm",
        "ready",
        "deepseek"
      ],
      "draft": false
    },
    {
      "number": 34336,
      "title": "[Bugfix] fix device_name for routing replay",
      "author": "Li-Yongwen",
      "state": "closed",
      "merged": true,
      "created_at": "2026-02-11T12:52:17Z",
      "updated_at": "2026-02-26T12:18:38Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/34336",
      "labels": [
        "bug",
        "ready"
      ],
      "draft": false
    },
    {
      "number": 35302,
      "title": "[Bugfix][Hardware][AMD] Support all MoE activations in WNA16 quantization on ROCm",
      "author": "c0de128",
      "state": "open",
      "merged": false,
      "created_at": "2026-02-25T15:36:19Z",
      "updated_at": "2026-02-26T09:35:16Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/35302",
      "labels": [
        "bug",
        "rocm"
      ],
      "draft": false
    },
    {
      "number": 35304,
      "title": "[Bugfix][Hardware][AMD] Fix startup hang on ROCm gfx1151 in MinTokensLogitsProcessor",
      "author": "c0de128",
      "state": "open",
      "merged": false,
      "created_at": "2026-02-25T15:49:48Z",
      "updated_at": "2026-02-26T09:35:00Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/35304",
      "labels": [
        "bug",
        "rocm",
        "v1"
      ],
      "draft": false
    },
    {
      "number": 33992,
      "title": "[Bugfix] Fix CUDA compatibility path setting for both datacenter and consumer NVIDIA GPUs",
      "author": "ehfd",
      "state": "closed",
      "merged": true,
      "created_at": "2026-02-06T12:35:55Z",
      "updated_at": "2026-02-26T09:11:48Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/33992",
      "labels": [
        "bug",
        "documentation",
        "ready",
        "ci/build",
        "nvidia"
      ],
      "draft": false
    },
    {
      "number": 35250,
      "title": "[Bugfix][Hardware][AMD] Gate FP4 ops on gfx950 to prevent MI300X crash",
      "author": "c0de128",
      "state": "closed",
      "merged": true,
      "created_at": "2026-02-25T00:47:29Z",
      "updated_at": "2026-02-26T08:11:08Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/35250",
      "labels": [
        "bug",
        "rocm",
        "ready"
      ],
      "draft": false
    },
    {
      "number": 34848,
      "title": "[ROCm] Add extra step in config initialization to populate custom ops before compilation config init",
      "author": "gshtras",
      "state": "closed",
      "merged": true,
      "created_at": "2026-02-18T22:49:51Z",
      "updated_at": "2026-02-26T08:05:41Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/34848",
      "labels": [
        "rocm",
        "ready"
      ],
      "draft": false
    },
    {
      "number": 33807,
      "title": "[UX] Add `--moe-backend` arg for explicit kernel selection",
      "author": "mgoin",
      "state": "closed",
      "merged": true,
      "created_at": "2026-02-04T17:07:59Z",
      "updated_at": "2026-02-26T01:44:49Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/33807",
      "labels": [
        "ready",
        "nvidia"
      ],
      "draft": false
    },
    {
      "number": 35042,
      "title": "[Platform] Add current_platform.num_compute_units interface",
      "author": "jikunshang",
      "state": "closed",
      "merged": true,
      "created_at": "2026-02-22T02:09:19Z",
      "updated_at": "2026-02-26T00:03:50Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/35042",
      "labels": [
        "performance",
        "rocm",
        "ready",
        "v1",
        "nvidia"
      ],
      "draft": false
    },
    {
      "number": 33825,
      "title": "[vLLM IR] 1/N Implement IR skeleton and rms_norm op",
      "author": "ProExpertProg",
      "state": "open",
      "merged": false,
      "created_at": "2026-02-04T20:08:50Z",
      "updated_at": "2026-02-25T23:56:59Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/33825",
      "labels": [
        "rocm",
        "ready",
        "torch.compile",
        "ci/build",
        "nvidia",
        "vllm-ir"
      ],
      "draft": false
    },
    {
      "number": 35322,
      "title": "[ROCm][CI] Amending deletion of AMD mirror",
      "author": "AndreasKaratzas",
      "state": "closed",
      "merged": true,
      "created_at": "2026-02-25T18:47:30Z",
      "updated_at": "2026-02-25T22:18:13Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/35322",
      "labels": [
        "rocm",
        "ready",
        "ci/build"
      ],
      "draft": false
    },
    {
      "number": 35265,
      "title": "[ROCm][CI] Extending attention backend coverage for Eagle spec decode tests",
      "author": "AndreasKaratzas",
      "state": "closed",
      "merged": true,
      "created_at": "2026-02-25T06:19:13Z",
      "updated_at": "2026-02-25T22:16:48Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/35265",
      "labels": [
        "rocm",
        "ready",
        "ci/build",
        "v1"
      ],
      "draft": false
    },
    {
      "number": 35156,
      "title": "[BUGFIX][Qwen3.5] Hardcode `mlp.gate` as not quantizable ",
      "author": "vadiklyutiy",
      "state": "closed",
      "merged": true,
      "created_at": "2026-02-24T00:13:00Z",
      "updated_at": "2026-02-25T21:55:56Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/35156",
      "labels": [
        "bug",
        "ready",
        "qwen"
      ],
      "draft": false
    },
    {
      "number": 34169,
      "title": "[CPU][Distributed] Fix Enable _CPUSHMDistributed only when TP/PP ranks share the same SHM group name",
      "author": "charlesashby",
      "state": "open",
      "merged": false,
      "created_at": "2026-02-09T20:21:11Z",
      "updated_at": "2026-02-25T20:04:50Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/34169",
      "labels": [
        "v1",
        "cpu"
      ],
      "draft": false
    },
    {
      "number": 34985,
      "title": "[CI][AMD][BugFix] Add  torch.cuda.set_device to test_punica_ops so punica kernels execute on same device as tensor",
      "author": "rasmith",
      "state": "closed",
      "merged": true,
      "created_at": "2026-02-20T20:17:24Z",
      "updated_at": "2026-02-25T19:18:01Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/34985",
      "labels": [
        "bug",
        "rocm",
        "ready",
        "nvidia"
      ],
      "draft": false
    },
    {
      "number": 35049,
      "title": "[ROCm][CI] Disable skinny GEMMs in multimodal tests to fix non-deterministic results",
      "author": "AndreasKaratzas",
      "state": "closed",
      "merged": true,
      "created_at": "2026-02-22T06:56:40Z",
      "updated_at": "2026-02-25T17:34:32Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/35049",
      "labels": [
        "rocm",
        "ready",
        "multi-modality"
      ],
      "draft": false
    },
    {
      "number": 34773,
      "title": "[Misc][LoRA] Increase max vocab size limit to 258048 in logits processor",
      "author": "bhoomit",
      "state": "closed",
      "merged": true,
      "created_at": "2026-02-18T03:01:38Z",
      "updated_at": "2026-02-25T15:30:56Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/34773",
      "labels": [
        "rocm",
        "ready"
      ],
      "draft": false
    },
    {
      "number": 26807,
      "title": "[V1][Hybrid] GatedDeltaNet Automatic Prefix Caching (`all`-mode) ",
      "author": "simondanielsson",
      "state": "open",
      "merged": false,
      "created_at": "2025-10-14T13:02:11Z",
      "updated_at": "2026-02-25T10:29:00Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/26807",
      "labels": [
        "v1",
        "qwen"
      ],
      "draft": false
    },
    {
      "number": 34677,
      "title": "[Bugfix][CPU] Fix basic unit tests failing in CPU platforms",
      "author": "jasonyanwenl",
      "state": "closed",
      "merged": true,
      "created_at": "2026-02-17T07:47:54Z",
      "updated_at": "2026-02-25T08:36:16Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/34677",
      "labels": [
        "bug",
        "ready",
        "nvidia"
      ],
      "draft": false
    },
    {
      "number": 34100,
      "title": "Convert wvSplitKQ to 16x16 MFMA in prep for mi4xx.",
      "author": "amd-hhashemi",
      "state": "closed",
      "merged": true,
      "created_at": "2026-02-08T19:00:26Z",
      "updated_at": "2026-02-24T23:35:22Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/34100",
      "labels": [
        "rocm",
        "ready"
      ],
      "draft": false
    },
    {
      "number": 30976,
      "title": "Use aiter triton fused_add_rmsnorm_pad for gpt-oss",
      "author": "Rohan138",
      "state": "closed",
      "merged": true,
      "created_at": "2025-12-18T17:39:55Z",
      "updated_at": "2026-02-24T23:26:33Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/30976",
      "labels": [
        "rocm",
        "ready",
        "gpt-oss"
      ],
      "draft": false
    },
    {
      "number": 35232,
      "title": "[Build] Fix LTO build for ROCm when default compiler is GCC but ROCm/HIP is using Clang",
      "author": "davispuh",
      "state": "open",
      "merged": false,
      "created_at": "2026-02-24T20:48:28Z",
      "updated_at": "2026-02-24T21:55:08Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/35232",
      "labels": [
        "rocm",
        "ci/build"
      ],
      "draft": false
    },
    {
      "number": 34923,
      "title": "[ROCm][CI] Added MI325 mirrors",
      "author": "AndreasKaratzas",
      "state": "closed",
      "merged": true,
      "created_at": "2026-02-19T23:18:01Z",
      "updated_at": "2026-02-24T21:38:21Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/34923",
      "labels": [
        "rocm",
        "ready",
        "ci/build",
        "v1",
        "kv-connector"
      ],
      "draft": false
    },
    {
      "number": 34878,
      "title": "[ROCm][Test] Fix beam search determinism failures from batch-size-dependent FP divergence and removed wrong marker",
      "author": "AndreasKaratzas",
      "state": "closed",
      "merged": true,
      "created_at": "2026-02-19T06:43:47Z",
      "updated_at": "2026-02-24T08:48:11Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/34878",
      "labels": [
        "rocm",
        "ready",
        "ci/build"
      ],
      "draft": false
    },
    {
      "number": 34879,
      "title": "[ROCm][CI] Removing all blocking labels from MI355 until stable infra",
      "author": "AndreasKaratzas",
      "state": "closed",
      "merged": true,
      "created_at": "2026-02-19T07:26:21Z",
      "updated_at": "2026-02-23T22:49:37Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/34879",
      "labels": [
        "rocm",
        "ready",
        "ci/build"
      ],
      "draft": false
    },
    {
      "number": 35043,
      "title": "[ROCm][CI] Fix spec decode profile assertion and logprob test determinism",
      "author": "AndreasKaratzas",
      "state": "closed",
      "merged": true,
      "created_at": "2026-02-22T04:07:10Z",
      "updated_at": "2026-02-23T17:42:56Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/35043",
      "labels": [
        "rocm",
        "ready",
        "v1"
      ],
      "draft": false
    },
    {
      "number": 34275,
      "title": "[ROCm] Add RDNA3 tile-size heuristic for \"triton_scaled_mm\" kernel",
      "author": "monajafi-amd",
      "state": "open",
      "merged": false,
      "created_at": "2026-02-10T20:50:32Z",
      "updated_at": "2026-02-23T16:30:27Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/34275",
      "labels": [
        "rocm"
      ],
      "draft": false
    },
    {
      "number": 33277,
      "title": "[ROCm][CI] Force max_num_seqs=1 on ROCm In test_sharded_state_loader to reduce flakiness",
      "author": "micah-wil",
      "state": "closed",
      "merged": true,
      "created_at": "2026-01-28T19:06:39Z",
      "updated_at": "2026-02-23T14:36:38Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/33277",
      "labels": [
        "rocm",
        "ready"
      ],
      "draft": false
    },
    {
      "number": 35052,
      "title": "[ROCm][CI] Fix realtime test timeouts caused by aiter JIT compilation delays",
      "author": "AndreasKaratzas",
      "state": "closed",
      "merged": true,
      "created_at": "2026-02-22T07:49:19Z",
      "updated_at": "2026-02-22T21:21:06Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/35052",
      "labels": [
        "rocm",
        "ready"
      ],
      "draft": false
    },
    {
      "number": 34741,
      "title": "[ROCm] Enable FP8 KV-cache and relax constraints for RDNA4 custom paged attention",
      "author": "laudney",
      "state": "open",
      "merged": false,
      "created_at": "2026-02-17T19:59:05Z",
      "updated_at": "2026-02-22T08:49:06Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/34741",
      "labels": [
        "rocm"
      ],
      "draft": false
    },
    {
      "number": 35008,
      "title": "[CI] Stabilizing ROCm amd-ci signal and minor name fix in upstream",
      "author": "AndreasKaratzas",
      "state": "closed",
      "merged": true,
      "created_at": "2026-02-21T05:14:37Z",
      "updated_at": "2026-02-22T04:06:16Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/35008",
      "labels": [
        "rocm",
        "ready",
        "ci/build"
      ],
      "draft": false
    },
    {
      "number": 34466,
      "title": "[CI/Build] Add opentelemetry libs in default vllm build (requirements/common.txt)",
      "author": "vladmihailescu",
      "state": "closed",
      "merged": true,
      "created_at": "2026-02-12T21:20:48Z",
      "updated_at": "2026-02-21T20:52:25Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/34466",
      "labels": [
        "documentation",
        "ready",
        "ci/build"
      ],
      "draft": false
    },
    {
      "number": 34688,
      "title": "[ROCm] Enable bitsandbytes quantization support on ROCm",
      "author": "Abdennacer-Badaoui",
      "state": "closed",
      "merged": true,
      "created_at": "2026-02-17T10:46:33Z",
      "updated_at": "2026-02-21T08:35:03Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/34688",
      "labels": [
        "documentation",
        "rocm",
        "ready",
        "ci/build"
      ],
      "draft": false
    },
    {
      "number": 34570,
      "title": "[ROCm][AITER] Fix aiter paged_attention_v1 decode for sliding window and head_size < 64",
      "author": "AndreasKaratzas",
      "state": "closed",
      "merged": true,
      "created_at": "2026-02-15T01:55:35Z",
      "updated_at": "2026-02-21T04:26:23Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/34570",
      "labels": [
        "rocm",
        "ready",
        "v1"
      ],
      "draft": false
    },
    {
      "number": 34567,
      "title": "[CI] Fix ColBERT HF comparison tests on AMD CI + refactor",
      "author": "AndreasKaratzas",
      "state": "closed",
      "merged": true,
      "created_at": "2026-02-14T23:49:12Z",
      "updated_at": "2026-02-21T04:14:24Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/34567",
      "labels": [
        "rocm",
        "ready"
      ],
      "draft": false
    },
    {
      "number": 34735,
      "title": "[AMD][CI] Fix test_custom_allreduce for A100 testgroup",
      "author": "rjrock",
      "state": "closed",
      "merged": true,
      "created_at": "2026-02-17T19:03:48Z",
      "updated_at": "2026-02-20T21:33:15Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/34735",
      "labels": [
        "rocm",
        "ready"
      ],
      "draft": false
    },
    {
      "number": 34455,
      "title": "[Bugfix] Remove assert causing hipErrorStreamCaptureUnsupported",
      "author": "JadenMathias",
      "state": "closed",
      "merged": true,
      "created_at": "2026-02-12T19:35:40Z",
      "updated_at": "2026-02-18T18:54:54Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/34455",
      "labels": [
        "bug",
        "rocm",
        "ready"
      ],
      "draft": false
    },
    {
      "number": 34726,
      "title": "[ROCm] Enable DBO (Dynamic Batch Optimization) on ROCm",
      "author": "raviguptaamd",
      "state": "open",
      "merged": false,
      "created_at": "2026-02-17T17:30:04Z",
      "updated_at": "2026-02-18T01:25:05Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/34726",
      "labels": [
        "rocm",
        "v1"
      ],
      "draft": true
    },
    {
      "number": 33811,
      "title": "[Hardware][AMD] Add comments explaining gfx906 (MI50/MI60) is not supported",
      "author": "randomizedcoder",
      "state": "open",
      "merged": false,
      "created_at": "2026-02-04T17:43:47Z",
      "updated_at": "2026-02-18T00:33:43Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/33811",
      "labels": [
        "rocm",
        "ready",
        "ci/build"
      ],
      "draft": false
    },
    {
      "number": 27352,
      "title": "[cmake]  fix ROCm hip/clr build on platforms without GPUs attached",
      "author": "evil0sheep",
      "state": "open",
      "merged": false,
      "created_at": "2025-10-22T15:52:12Z",
      "updated_at": "2026-02-16T02:16:15Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/27352",
      "labels": [
        "rocm",
        "ci/build",
        "stale"
      ],
      "draft": false
    },
    {
      "number": 27943,
      "title": "[V1][Perf] Optimize Medusa proposer: reduce sync overhead ",
      "author": "skyloevil",
      "state": "open",
      "merged": false,
      "created_at": "2025-11-02T17:07:43Z",
      "updated_at": "2026-02-15T02:15:15Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/27943",
      "labels": [
        "speculative-decoding",
        "stale",
        "v1"
      ],
      "draft": false
    },
    {
      "number": 29556,
      "title": "[CI/Build] Skip ray tests on ROCm",
      "author": "rjrock",
      "state": "closed",
      "merged": true,
      "created_at": "2025-11-26T23:58:56Z",
      "updated_at": "2026-02-12T19:11:34Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/29556",
      "labels": [
        "rocm",
        "v1"
      ],
      "draft": false
    },
    {
      "number": 27881,
      "title": "Adding render group to docker container",
      "author": "dhonnappa-amd",
      "state": "open",
      "merged": false,
      "created_at": "2025-10-31T14:14:41Z",
      "updated_at": "2026-02-10T18:13:57Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/27881",
      "labels": [
        "rocm",
        "needs-rebase",
        "ci/build"
      ],
      "draft": false
    },
    {
      "number": 34108,
      "title": "[ROCm][Bugfix] Resolve Dynamo tracing crash from amdsmi calls in on_gfx* arch detection",
      "author": "AndreasKaratzas",
      "state": "closed",
      "merged": true,
      "created_at": "2026-02-09T02:05:10Z",
      "updated_at": "2026-02-10T17:06:08Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/34108",
      "labels": [
        "bug",
        "rocm",
        "ready"
      ],
      "draft": false
    },
    {
      "number": 31400,
      "title": "[wip] custom allreduce and custom unquantized_gemm",
      "author": "wxsIcey",
      "state": "open",
      "merged": false,
      "created_at": "2025-12-27T06:20:31Z",
      "updated_at": "2026-02-09T08:08:50Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/31400",
      "labels": [],
      "draft": true
    },
    {
      "number": 33941,
      "title": "[bugfix] [ROCm] Fix premature CUDA initialization in platform detection",
      "author": "kouroshHakha",
      "state": "closed",
      "merged": true,
      "created_at": "2026-02-05T20:37:24Z",
      "updated_at": "2026-02-06T22:17:55Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/33941",
      "labels": [
        "bug",
        "rocm",
        "ready",
        "ci/build",
        "nvidia"
      ],
      "draft": false
    },
    {
      "number": 33734,
      "title": "[Rocm][Bugfix] Fix dtype not same for gemm_a4w4 op",
      "author": "charlifu",
      "state": "closed",
      "merged": true,
      "created_at": "2026-02-03T21:33:59Z",
      "updated_at": "2026-02-06T19:09:59Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/33734",
      "labels": [
        "bug",
        "rocm",
        "ready"
      ],
      "draft": false
    },
    {
      "number": 33308,
      "title": "[rocm][ray] Fix: Unify Ray device visibility handling across CUDA and ROCm",
      "author": "kouroshHakha",
      "state": "closed",
      "merged": true,
      "created_at": "2026-01-29T05:53:56Z",
      "updated_at": "2026-02-06T02:25:09Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/33308",
      "labels": [
        "rocm",
        "ready",
        "ci/build",
        "v1",
        "nvidia"
      ],
      "draft": false
    },
    {
      "number": 29117,
      "title": "[torch.compile] refactor config hashing to compile_factors and unify factor collection",
      "author": "vnadathur",
      "state": "open",
      "merged": false,
      "created_at": "2025-11-20T21:39:28Z",
      "updated_at": "2026-02-05T19:46:00Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/29117",
      "labels": [
        "documentation",
        "needs-rebase",
        "v1",
        "llama"
      ],
      "draft": false
    },
    {
      "number": 33800,
      "title": "[Bugfix] Support `RotaryEmbedding` CustomOp for gpt-oss",
      "author": "simondanielsson",
      "state": "closed",
      "merged": true,
      "created_at": "2026-02-04T16:03:58Z",
      "updated_at": "2026-02-04T20:17:42Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/33800",
      "labels": [
        "bug",
        "ready",
        "gpt-oss"
      ],
      "draft": false
    },
    {
      "number": 32745,
      "title": "[Hardware][AMD][CI] Refactor AMD tests to properly use BuildKite parallelism",
      "author": "mawong-amd",
      "state": "closed",
      "merged": true,
      "created_at": "2026-01-21T01:36:38Z",
      "updated_at": "2026-02-04T15:23:39Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/32745",
      "labels": [
        "rocm",
        "ready",
        "ci/build"
      ],
      "draft": false
    },
    {
      "number": 33585,
      "title": "[7/n] Migrate cache_kernels to libtorch stable ABI",
      "author": "mikaylagawarecki",
      "state": "open",
      "merged": false,
      "created_at": "2026-02-02T19:59:26Z",
      "updated_at": "2026-02-02T23:10:17Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/33585",
      "labels": [
        "rocm",
        "ci/build",
        "cpu",
        "nvidia"
      ],
      "draft": true
    },
    {
      "number": 33077,
      "title": "[BUGFIX] Fix hipErrorIllegalState in Qwen3-Omni during startup profiling allow inference Omni on ROCM",
      "author": "JartX",
      "state": "closed",
      "merged": true,
      "created_at": "2026-01-26T09:56:14Z",
      "updated_at": "2026-02-01T13:36:36Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/33077",
      "labels": [
        "bug",
        "rocm",
        "ready",
        "qwen"
      ],
      "draft": false
    },
    {
      "number": 33047,
      "title": "[W8A8 Block Linear Refactor][1/N] Keep all quantization types into `QuantFP8` class.",
      "author": "maralbahari",
      "state": "closed",
      "merged": true,
      "created_at": "2026-01-26T02:18:24Z",
      "updated_at": "2026-02-01T09:28:11Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/33047",
      "labels": [
        "ready",
        "nvidia"
      ],
      "draft": false
    },
    {
      "number": 33200,
      "title": "[Bugfix] Handle Asym W4A16 (ConchLinearKernel) for CT",
      "author": "mgehre-amd",
      "state": "closed",
      "merged": true,
      "created_at": "2026-01-27T22:06:31Z",
      "updated_at": "2026-01-31T06:21:52Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/33200",
      "labels": [
        "bug",
        "ready"
      ],
      "draft": false
    },
    {
      "number": 32944,
      "title": "[ROCm][ViT] Enable Flash Attention Triton backend on RDNA3/RDNA4",
      "author": "monajafi-amd",
      "state": "closed",
      "merged": true,
      "created_at": "2026-01-23T15:34:20Z",
      "updated_at": "2026-01-30T14:06:17Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/32944",
      "labels": [
        "rocm",
        "ready"
      ],
      "draft": false
    },
    {
      "number": 33305,
      "title": "[CI][AMD] Skip 4 GPUs testgroup ray tests",
      "author": "rjrock",
      "state": "closed",
      "merged": true,
      "created_at": "2026-01-29T04:27:25Z",
      "updated_at": "2026-01-30T05:44:03Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/33305",
      "labels": [
        "documentation",
        "rocm",
        "ready",
        "ci/build",
        "v1"
      ],
      "draft": false
    },
    {
      "number": 32891,
      "title": "[ROCm][CI] Add TORCH_NCCL_BLOCKING_WAIT For Distributed Tests (A100)",
      "author": "micah-wil",
      "state": "closed",
      "merged": true,
      "created_at": "2026-01-22T22:56:06Z",
      "updated_at": "2026-01-28T03:32:32Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/32891",
      "labels": [
        "rocm",
        "ready",
        "ci/build"
      ],
      "draft": false
    },
    {
      "number": 31380,
      "title": "[Bugfix][ROCm]Fix Qwen3-Next-80B-A3B-Thinking inference and optimize non-standard block size (544) support under rocm_atten",
      "author": "vllmellm",
      "state": "closed",
      "merged": true,
      "created_at": "2025-12-26T07:16:31Z",
      "updated_at": "2026-01-28T03:31:13Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/31380",
      "labels": [
        "bug",
        "rocm",
        "ready",
        "v1",
        "qwen"
      ],
      "draft": false
    },
    {
      "number": 31590,
      "title": "[Bugfix] Replace BaseException with specific exceptions in FLA utils",
      "author": "c0de128",
      "state": "closed",
      "merged": true,
      "created_at": "2025-12-31T20:04:35Z",
      "updated_at": "2026-01-27T17:56:11Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/31590",
      "labels": [
        "ready"
      ],
      "draft": false
    },
    {
      "number": 31282,
      "title": "[Bugfix][Hardware][AMD] Fix last_page_len calculation in AITER MLA decode",
      "author": "c0de128",
      "state": "closed",
      "merged": true,
      "created_at": "2025-12-24T13:45:16Z",
      "updated_at": "2026-01-27T17:56:04Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/31282",
      "labels": [
        "rocm",
        "ready",
        "v1"
      ],
      "draft": false
    },
    {
      "number": 31295,
      "title": "[Bugfix][Hardware][AMD] Use dynamic WARP_SIZE in sampler vectorized_process",
      "author": "c0de128",
      "state": "closed",
      "merged": true,
      "created_at": "2025-12-24T15:02:32Z",
      "updated_at": "2026-01-27T17:55:59Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/31295",
      "labels": [
        "rocm",
        "ready"
      ],
      "draft": false
    },
    {
      "number": 32649,
      "title": "[ROCm][Deepseekv3.2][Perf] dsv3.2 further optimization on vllm",
      "author": "ganyi1996ppo",
      "state": "open",
      "merged": false,
      "created_at": "2026-01-20T07:50:21Z",
      "updated_at": "2026-01-27T02:19:09Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/32649",
      "labels": [
        "rocm",
        "needs-rebase",
        "v1",
        "deepseek"
      ],
      "draft": true
    },
    {
      "number": 28888,
      "title": "Upstream triton fp4 weight preshuffle",
      "author": "maleksan85",
      "state": "closed",
      "merged": true,
      "created_at": "2025-11-17T23:25:22Z",
      "updated_at": "2026-01-26T12:02:47Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/28888",
      "labels": [
        "rocm",
        "ready"
      ],
      "draft": false
    },
    {
      "number": 33043,
      "title": "[rocm][aiter] add env var VLLM_ROCM_USE_AITER_SAMPLING",
      "author": "yuguo68",
      "state": "open",
      "merged": false,
      "created_at": "2026-01-25T23:19:15Z",
      "updated_at": "2026-01-25T23:28:23Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/33043",
      "labels": [
        "rocm",
        "v1"
      ],
      "draft": false
    },
    {
      "number": 32754,
      "title": "[Bugfix][ROCm] Fix DeepSeek-R1 repetition via hybrid sampler routing",
      "author": "vllmellm",
      "state": "open",
      "merged": false,
      "created_at": "2026-01-21T03:52:11Z",
      "updated_at": "2026-01-22T16:31:10Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/32754",
      "labels": [
        "bug",
        "rocm",
        "v1",
        "deepseek"
      ],
      "draft": false
    },
    {
      "number": 30978,
      "title": "Add positional embedding and kv_cache fusion for llama and gpt-oss",
      "author": "dllehr-amd",
      "state": "open",
      "merged": false,
      "created_at": "2025-12-18T17:57:04Z",
      "updated_at": "2026-01-20T23:04:56Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/30978",
      "labels": [
        "rocm",
        "needs-rebase",
        "v1",
        "llama",
        "gpt-oss"
      ],
      "draft": true
    },
    {
      "number": 32413,
      "title": "[ROCm][Bugfix] Disable hip sampler to fix deepseek's accuracy issue on ROCm",
      "author": "ganyi1996ppo",
      "state": "closed",
      "merged": true,
      "created_at": "2026-01-15T13:53:46Z",
      "updated_at": "2026-01-20T16:04:24Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/32413",
      "labels": [
        "bug",
        "rocm",
        "ready",
        "v1",
        "deepseek"
      ],
      "draft": false
    },
    {
      "number": 32408,
      "title": "[CI][Hardware][AMD] Fix test_rotary_embedding_mla_cache_fused",
      "author": "mawong-amd",
      "state": "closed",
      "merged": true,
      "created_at": "2026-01-15T10:27:06Z",
      "updated_at": "2026-01-19T08:26:51Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/32408",
      "labels": [
        "rocm",
        "ready"
      ],
      "draft": false
    },
    {
      "number": 21184,
      "title": "Some initial Vulkan boilerplate",
      "author": "ericcurtin",
      "state": "open",
      "merged": false,
      "created_at": "2025-07-18T12:04:58Z",
      "updated_at": "2026-01-19T02:17:47Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/21184",
      "labels": [
        "needs-rebase",
        "ci/build",
        "unstale"
      ],
      "draft": false
    },
    {
      "number": 31077,
      "title": "Fix ROCm CUDA graph replay synchronization bug (issue #29521)",
      "author": "westers",
      "state": "open",
      "merged": false,
      "created_at": "2025-12-20T08:15:59Z",
      "updated_at": "2026-01-14T07:45:43Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/31077",
      "labels": [
        "bug",
        "documentation",
        "rocm",
        "needs-rebase",
        "ci/build",
        "v1",
        "nvidia"
      ],
      "draft": false
    },
    {
      "number": 30471,
      "title": "[Optimization]: Add fused router for GPTOSS",
      "author": "ijpq",
      "state": "open",
      "merged": false,
      "created_at": "2025-12-11T07:55:47Z",
      "updated_at": "2026-01-13T16:13:29Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/30471",
      "labels": [
        "needs-rebase",
        "gpt-oss"
      ],
      "draft": true
    },
    {
      "number": 31079,
      "title": "Fix ROCm build to respect PYTORCH_ROCM_ARCH for GPU_TARGETS (issue #22590)",
      "author": "westers",
      "state": "open",
      "merged": false,
      "created_at": "2025-12-20T08:24:58Z",
      "updated_at": "2025-12-20T18:10:07Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/31079",
      "labels": [
        "documentation",
        "rocm",
        "ci/build",
        "v1",
        "nvidia"
      ],
      "draft": false
    },
    {
      "number": 31062,
      "title": "[ROCm][Docker] Add gfx1103 support to Docker builds",
      "author": "westers",
      "state": "open",
      "merged": false,
      "created_at": "2025-12-20T04:22:00Z",
      "updated_at": "2025-12-20T06:43:35Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/31062",
      "labels": [
        "rocm",
        "ci/build"
      ],
      "draft": false
    },
    {
      "number": 24068,
      "title": "Gfx908 attn fix",
      "author": "UD-mmcminn",
      "state": "open",
      "merged": false,
      "created_at": "2025-09-02T03:19:25Z",
      "updated_at": "2025-12-18T02:24:18Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/24068",
      "labels": [
        "rocm",
        "unstale"
      ],
      "draft": false
    },
    {
      "number": 29363,
      "title": "[ROCm][fusion] Enable qk_norm mRoPE fusion for Qwen VL models",
      "author": "gbyu-amd",
      "state": "open",
      "merged": false,
      "created_at": "2025-11-25T02:37:40Z",
      "updated_at": "2025-11-25T03:08:08Z",
      "html_url": "https://github.com/vllm-project/vllm/pull/29363",
      "labels": [
        "rocm",
        "qwen"
      ],
      "draft": true
    }
  ]
}