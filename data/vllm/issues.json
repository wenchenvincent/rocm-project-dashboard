{
  "collected_at": "2026-02-25T08:34:54Z",
  "issues": [
    {
      "number": 35191,
      "title": "[Bug]: Qwen3.5 397B FP8 fills 1TB RAM and OOM killed with high-concurrency multimodal requests",
      "author": "FWao",
      "state": "open",
      "created_at": "2026-02-24T12:45:47Z",
      "updated_at": "2026-02-25T07:45:15Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/35191",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 35266,
      "title": "[Bug]: Missing opening brace for Qwen3.5 streaming tool calls",
      "author": "AsterisMono",
      "state": "open",
      "created_at": "2026-02-25T06:35:20Z",
      "updated_at": "2026-02-25T07:19:14Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/35266",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 30679,
      "title": "[RFC]: Replace `torch.cuda` API with `torch.accelerator` for better hardware compatiblity.",
      "author": "jikunshang",
      "state": "open",
      "created_at": "2025-12-15T08:23:45Z",
      "updated_at": "2026-02-25T06:49:05Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/30679",
      "labels": [
        "RFC"
      ]
    },
    {
      "number": 33638,
      "title": "[Bug]: DeepSeekV3.1 with fp8 kvcache in v0.15.0 produces garbled output",
      "author": "lyg95",
      "state": "open",
      "created_at": "2026-02-03T03:26:24Z",
      "updated_at": "2026-02-25T06:33:10Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/33638",
      "labels": [
        "bug",
        "deepseek"
      ]
    },
    {
      "number": 23577,
      "title": "[Bug]: default_weight_loader receives unexpected `weight_name` kwarg in GPT-OSS load_weights",
      "author": "cmao-at",
      "state": "open",
      "created_at": "2025-08-25T18:05:57Z",
      "updated_at": "2026-02-25T04:34:25Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/23577",
      "labels": [
        "bug",
        "stale"
      ]
    },
    {
      "number": 35163,
      "title": "[Bug]: AMD docker image still using torch 2.9 despite 2.10.0 in `requirements/rocm-build.txt`",
      "author": "mikaylagawarecki",
      "state": "open",
      "created_at": "2026-02-24T01:47:25Z",
      "updated_at": "2026-02-25T03:50:19Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/35163",
      "labels": [
        "bug",
        "rocm"
      ]
    },
    {
      "number": 35255,
      "title": "[Bug]: CUDA Error 803 on host with driver 590.48: `system has unsupported display driver / cuda driver combination",
      "author": "git-jxj",
      "state": "open",
      "created_at": "2026-02-25T03:18:30Z",
      "updated_at": "2026-02-25T03:44:13Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/35255",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 34449,
      "title": "[Bug]: GLM-5-FP8 malformed tool calls",
      "author": "TALLEC-Scott",
      "state": "open",
      "created_at": "2026-02-12T18:20:25Z",
      "updated_at": "2026-02-25T03:23:52Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34449",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 35028,
      "title": "[Bug]: RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasGemmEx",
      "author": "shahizat",
      "state": "open",
      "created_at": "2026-02-21T17:55:04Z",
      "updated_at": "2026-02-25T03:05:50Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/35028",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 35091,
      "title": "[Bug]: Triton CompilationError in speculative decoding (draft_model)",
      "author": "rse173",
      "state": "open",
      "created_at": "2026-02-23T10:35:12Z",
      "updated_at": "2026-02-25T02:47:36Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/35091",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 34399,
      "title": "[Bug]: Nemotron 3 (all quants) take a LONG time to load",
      "author": "jiangwu300",
      "state": "open",
      "created_at": "2026-02-12T03:44:51Z",
      "updated_at": "2026-02-25T02:21:40Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34399",
      "labels": [
        "bug",
        "torch.compile"
      ]
    },
    {
      "number": 20261,
      "title": "[Bug]: Prefix caching ignores visual input, causing incorrect multimodal outputs under concurrency",
      "author": "Richar-Du",
      "state": "open",
      "created_at": "2025-06-30T14:28:28Z",
      "updated_at": "2026-02-25T02:17:25Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/20261",
      "labels": [
        "bug",
        "stale"
      ]
    },
    {
      "number": 28003,
      "title": "[Usage]:",
      "author": "amitmvyas",
      "state": "open",
      "created_at": "2025-11-03T21:19:15Z",
      "updated_at": "2026-02-25T02:15:42Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/28003",
      "labels": [
        "usage",
        "stale"
      ]
    },
    {
      "number": 29474,
      "title": "[P/D][Metrics] Consider combined/summed metrics (e.g. ttft and e2e_request_latency) for prefill and decode instances",
      "author": "mgw2168-1",
      "state": "open",
      "created_at": "2025-11-26T02:50:17Z",
      "updated_at": "2026-02-25T02:14:33Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/29474",
      "labels": [
        "usage",
        "stale",
        "kv-connector"
      ]
    },
    {
      "number": 29489,
      "title": "[Usage]: Removing last generated token from output and kv cache",
      "author": "josefdra",
      "state": "open",
      "created_at": "2025-11-26T09:35:37Z",
      "updated_at": "2026-02-25T02:14:29Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/29489",
      "labels": [
        "usage",
        "stale"
      ]
    },
    {
      "number": 29496,
      "title": "[Bug]: Qwen3-Embedding models get stuck when embedding input of max-model-len",
      "author": "jhradil",
      "state": "open",
      "created_at": "2025-11-26T13:51:22Z",
      "updated_at": "2026-02-25T02:14:26Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/29496",
      "labels": [
        "bug",
        "stale"
      ]
    },
    {
      "number": 31368,
      "title": "[Performance]: DeepSeek-v3.2 throughput&TTFT&TPOT is much slower than DeepSeek-v3.1 on 8*H200",
      "author": "princepride",
      "state": "open",
      "created_at": "2025-12-26T01:51:47Z",
      "updated_at": "2026-02-25T01:37:49Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/31368",
      "labels": [
        "performance"
      ]
    },
    {
      "number": 34994,
      "title": "[Feature]: Infrastructure Improvements for ROCm CI",
      "author": "AndreasKaratzas",
      "state": "open",
      "created_at": "2026-02-20T22:35:58Z",
      "updated_at": "2026-02-24T23:46:19Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34994",
      "labels": [
        "feature request",
        "rocm"
      ]
    },
    {
      "number": 35235,
      "title": "[CI Failure]:  mi355_1: Multi-Modal Models Test (Extended) 1",
      "author": "AndreasKaratzas",
      "state": "open",
      "created_at": "2026-02-24T21:17:28Z",
      "updated_at": "2026-02-24T21:18:41Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/35235",
      "labels": [
        "ci-failure"
      ]
    },
    {
      "number": 35233,
      "title": "[CI Failure]:  mi355_1: Language Models Test (Extended Generation)",
      "author": "AndreasKaratzas",
      "state": "open",
      "created_at": "2026-02-24T21:01:41Z",
      "updated_at": "2026-02-24T21:02:17Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/35233",
      "labels": [
        "ci-failure"
      ]
    },
    {
      "number": 29541,
      "title": "[CI Failure]: mi325_1: Entrypoints Integration Test (API Server 1)",
      "author": "AndreasKaratzas",
      "state": "open",
      "created_at": "2025-11-26T20:07:54Z",
      "updated_at": "2026-02-24T20:59:13Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/29541",
      "labels": [
        "ci-failure"
      ]
    },
    {
      "number": 35133,
      "title": "[CI Failure]:  mi355_4: LoRA TP Test (Distributed)",
      "author": "AndreasKaratzas",
      "state": "open",
      "created_at": "2026-02-23T18:34:13Z",
      "updated_at": "2026-02-24T19:56:33Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/35133",
      "labels": [
        "ci-failure"
      ]
    },
    {
      "number": 35138,
      "title": "[Bug]: Qwen/Qwen3.5-397B-A17B-FP8 and Qwen/Qwen3.5-397B-A17B has accuracy issues when running with Flashinfer Attention backend on Blackwell.",
      "author": "xinli-sw",
      "state": "open",
      "created_at": "2026-02-23T19:06:48Z",
      "updated_at": "2026-02-24T18:49:22Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/35138",
      "labels": [
        "bug",
        "nvidia"
      ]
    },
    {
      "number": 33748,
      "title": "[Bug][Infrastructure]: Inconsistent Docker Image Versioning and Missing Tags on Docker Hub",
      "author": "abeltre1",
      "state": "open",
      "created_at": "2026-02-04T01:42:57Z",
      "updated_at": "2026-02-24T14:16:00Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/33748",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 34705,
      "title": "[Bug]: Old torch compile files cause poor CPU utilisation",
      "author": "almayne",
      "state": "open",
      "created_at": "2026-02-17T14:27:14Z",
      "updated_at": "2026-02-24T12:34:19Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34705",
      "labels": [
        "bug",
        "torch.compile"
      ]
    },
    {
      "number": 34817,
      "title": "[Bug]: Trying to run gpt-oss-120b on rtx pro 6000",
      "author": "chadbek",
      "state": "open",
      "created_at": "2026-02-18T15:37:43Z",
      "updated_at": "2026-02-24T10:42:38Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34817",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 35169,
      "title": "[Bug]: Memory Access Fault during Step-3.5-Flash inference (ROCM)",
      "author": "ColinZ22",
      "state": "open",
      "created_at": "2026-02-24T04:41:04Z",
      "updated_at": "2026-02-24T04:41:57Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/35169",
      "labels": [
        "bug",
        "rocm"
      ]
    },
    {
      "number": 25771,
      "title": "[Bug]: Too many values to unpack in dispatch_cpu_unquantized_gemm [LiquidAi/LMF2]",
      "author": "littlechicks",
      "state": "open",
      "created_at": "2025-09-26T16:10:10Z",
      "updated_at": "2026-02-24T03:54:54Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/25771",
      "labels": [
        "bug",
        "unstale",
        "cpu"
      ]
    },
    {
      "number": 20561,
      "title": "[Bug]: Bad result with parallel generation.",
      "author": "hscspring",
      "state": "open",
      "created_at": "2025-07-07T10:00:51Z",
      "updated_at": "2026-02-24T02:17:53Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/20561",
      "labels": [
        "bug",
        "stale"
      ]
    },
    {
      "number": 29317,
      "title": "[Bug]: triton 3.5 for gpt-oss fails on sm11.0a cu130",
      "author": "mcr-ksh",
      "state": "open",
      "created_at": "2025-11-24T15:16:21Z",
      "updated_at": "2026-02-24T02:14:55Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/29317",
      "labels": [
        "bug",
        "stale"
      ]
    },
    {
      "number": 29361,
      "title": "[Bug]: CUDA illegal memory access in fused_marlin_moe for Kimi-K2-Thinking on H20 4-nodes 32-ranks(DP4, TP8, EP32)",
      "author": "TianyiZhao1437",
      "state": "open",
      "created_at": "2025-11-25T02:06:56Z",
      "updated_at": "2026-02-24T02:14:51Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/29361",
      "labels": [
        "bug",
        "stale"
      ]
    },
    {
      "number": 29368,
      "title": "[Bug]:llama4 AttributeError: 'dict' object has no attribute 'model_type'",
      "author": "win10ogod",
      "state": "open",
      "created_at": "2025-11-25T03:19:29Z",
      "updated_at": "2026-02-24T02:14:48Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/29368",
      "labels": [
        "bug",
        "stale"
      ]
    },
    {
      "number": 35128,
      "title": "[CI Failure]:  mi355_1: Language Models Tests (Standard)",
      "author": "AndreasKaratzas",
      "state": "open",
      "created_at": "2026-02-23T18:16:36Z",
      "updated_at": "2026-02-23T23:38:55Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/35128",
      "labels": [
        "ci-failure"
      ]
    },
    {
      "number": 33147,
      "title": "[Bug]: vLLM 0.11 SSL Initialization Failure (ssl.SSLError: [CRYPTO] unknown error) on MicroOS 5.5 with FIPS Enabled",
      "author": "fyuan1316",
      "state": "open",
      "created_at": "2026-01-27T07:01:23Z",
      "updated_at": "2026-02-23T22:27:11Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/33147",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 35089,
      "title": "[RFC]: In-Tree AMD Zen CPU Backend via zentorch",
      "author": "amd-lalithnc",
      "state": "open",
      "created_at": "2026-02-23T09:36:32Z",
      "updated_at": "2026-02-23T21:59:13Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/35089",
      "labels": [
        "rocm",
        "RFC",
        "cpu"
      ]
    },
    {
      "number": 32373,
      "title": "[Bug]: Fail to load vLLM on new NVIDIA driver",
      "author": "huydhn",
      "state": "open",
      "created_at": "2026-01-15T03:15:17Z",
      "updated_at": "2026-02-23T20:24:03Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/32373",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 32412,
      "title": "[RFC]: online quantization user facing API",
      "author": "vkuzo",
      "state": "open",
      "created_at": "2026-01-15T12:58:44Z",
      "updated_at": "2026-02-23T19:33:20Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/32412",
      "labels": [
        "RFC"
      ]
    },
    {
      "number": 34851,
      "title": "[Feature]: Refactor Quark MoE and mxfp4 MoE to align with MoE oracle/MK",
      "author": "BowenBao",
      "state": "open",
      "created_at": "2026-02-18T23:27:55Z",
      "updated_at": "2026-02-23T19:28:39Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34851",
      "labels": [
        "feature request"
      ]
    },
    {
      "number": 35126,
      "title": "[CI Failure]:  mi355_1: Kernels MoE Test %N",
      "author": "AndreasKaratzas",
      "state": "open",
      "created_at": "2026-02-23T18:11:06Z",
      "updated_at": "2026-02-23T19:10:03Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/35126",
      "labels": [
        "rocm",
        "ci-failure"
      ]
    },
    {
      "number": 35129,
      "title": "[CI Failure]:  mi355_4: 2 Node Tests (4 GPUs in total)",
      "author": "AndreasKaratzas",
      "state": "open",
      "created_at": "2026-02-23T18:18:18Z",
      "updated_at": "2026-02-23T18:56:35Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/35129",
      "labels": [
        "ci-failure"
      ]
    },
    {
      "number": 35132,
      "title": "[CI Failure][ROCm]:  CrossLayer KV layout Distributed NixlConnector PD accuracy tests (4 GPUs)",
      "author": "AndreasKaratzas",
      "state": "open",
      "created_at": "2026-02-23T18:28:34Z",
      "updated_at": "2026-02-23T18:29:10Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/35132",
      "labels": [
        "rocm",
        "ci-failure"
      ]
    },
    {
      "number": 31845,
      "title": "[Bug]: [H200] DeepSeek V3.2 MTP > 1 run into error (FLASHMLA_SPARSE backend)",
      "author": "jhaotingc",
      "state": "open",
      "created_at": "2026-01-06T23:39:29Z",
      "updated_at": "2026-02-23T17:05:58Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/31845",
      "labels": [
        "bug",
        "speculative-decoding",
        "deepseek"
      ]
    },
    {
      "number": 26480,
      "title": "[Bug][v0.11.0]: gpt-oss-120b generates with no output",
      "author": "AlessandroSpallina",
      "state": "open",
      "created_at": "2025-10-09T09:45:22Z",
      "updated_at": "2026-02-23T16:35:31Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/26480",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 35084,
      "title": "[Bug]: VLLM tries to load \"inductor\" instead of custom compiler",
      "author": "mergian",
      "state": "open",
      "created_at": "2026-02-23T07:51:57Z",
      "updated_at": "2026-02-23T15:13:47Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/35084",
      "labels": [
        "bug",
        "torch.compile"
      ]
    },
    {
      "number": 35031,
      "title": "[Bug]: MTP Speculative Decoding with NVFP4: Weight Shape Mismatch",
      "author": "eleqtrizit",
      "state": "open",
      "created_at": "2026-02-21T19:33:33Z",
      "updated_at": "2026-02-23T14:30:40Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/35031",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 35057,
      "title": "[Bug]: Qwen3.5 `scheduler_metadata must have shape (metadata_size)` with Decode Context Parallel (DCP)",
      "author": "ehfd",
      "state": "open",
      "created_at": "2026-02-22T15:30:54Z",
      "updated_at": "2026-02-23T10:17:20Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/35057",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 34545,
      "title": "[Installation]: unrecognized arguments: --omni",
      "author": "HenryBao91",
      "state": "open",
      "created_at": "2026-02-14T01:17:36Z",
      "updated_at": "2026-02-22T12:26:55Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34545",
      "labels": [
        "installation"
      ]
    },
    {
      "number": 29520,
      "title": "[CI Failure]: mi325_1: Multi-Modal Models Test (Standard)",
      "author": "AndreasKaratzas",
      "state": "open",
      "created_at": "2025-11-26T18:24:37Z",
      "updated_at": "2026-02-22T08:00:05Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/29520",
      "labels": [
        "ci-failure"
      ]
    },
    {
      "number": 31631,
      "title": "[CI Failure]:  mi325_1: V1 Test others",
      "author": "AndreasKaratzas",
      "state": "open",
      "created_at": "2026-01-02T22:59:12Z",
      "updated_at": "2026-02-22T04:09:58Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/31631",
      "labels": [
        "ci-failure"
      ]
    },
    {
      "number": 29176,
      "title": "[CI Failure]: [AMD] Nixl PD tests",
      "author": "NickLucche",
      "state": "open",
      "created_at": "2025-11-21T10:33:58Z",
      "updated_at": "2026-02-22T02:14:34Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/29176",
      "labels": [
        "rocm",
        "unstale",
        "ci-failure"
      ]
    },
    {
      "number": 29138,
      "title": "[Bug]: AttributeError: 'NoneType' object has no attribute 'use_mxfp4_w4a16'",
      "author": "nole69",
      "state": "open",
      "created_at": "2025-11-21T01:34:26Z",
      "updated_at": "2026-02-21T02:14:13Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/29138",
      "labels": [
        "bug",
        "stale"
      ]
    },
    {
      "number": 25179,
      "title": "[Performance]: Custom fused kernel tracking",
      "author": "ProExpertProg",
      "state": "open",
      "created_at": "2025-09-18T15:31:02Z",
      "updated_at": "2026-02-21T00:43:36Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/25179",
      "labels": [
        "performance",
        "torch.compile"
      ]
    }
  ]
}