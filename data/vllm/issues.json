{
  "collected_at": "2026-02-17T19:45:34Z",
  "issues": [
    {
      "number": 33857,
      "title": "[Bug]: Qwen3-Coder-Next fails with Triton allocator error on DGX Spark cluster (GB10, sm121)",
      "author": "eugr",
      "state": "open",
      "created_at": "2026-02-05T02:15:14Z",
      "updated_at": "2026-02-17T19:31:45Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/33857",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 34583,
      "title": "[Bug] Missing Vocabulary Validation for MTP and Eagle Speculative Methods leads to potential OOB Access",
      "author": "amadhan882",
      "state": "open",
      "created_at": "2026-02-15T13:31:28Z",
      "updated_at": "2026-02-17T18:36:42Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34583",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 33702,
      "title": "[Roadmap]: PD Disaggregation with `NixlConnector` Roadmap",
      "author": "NickLucche",
      "state": "open",
      "created_at": "2026-02-03T14:55:43Z",
      "updated_at": "2026-02-17T17:50:07Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/33702",
      "labels": [
        "feature request"
      ]
    },
    {
      "number": 31856,
      "title": "[Bug]: Text degeneration / repetition loops with MiniMax-M2.1-NVFP4 on v0.14.0rc1.dev308",
      "author": "ktsaou",
      "state": "open",
      "created_at": "2026-01-07T01:36:58Z",
      "updated_at": "2026-02-17T17:41:37Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/31856",
      "labels": []
    },
    {
      "number": 34650,
      "title": "Bug: Speculative Decoding (MTP) Causes </think> Detection Failure in Structured Output + Reasoning Mode",
      "author": "cicirori",
      "state": "open",
      "created_at": "2026-02-16T22:09:56Z",
      "updated_at": "2026-02-17T17:06:02Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34650",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 34437,
      "title": "[Bug]: Qwen3 Next with heterogeneous GPU (FP8 overflow?)",
      "author": "Nepherpitou",
      "state": "open",
      "created_at": "2026-02-12T14:29:01Z",
      "updated_at": "2026-02-17T16:38:03Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34437",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 30320,
      "title": "[Bug]: v1 scheduler assert num_new_tokens > 0",
      "author": "sszgwdk",
      "state": "open",
      "created_at": "2025-12-09T08:41:19Z",
      "updated_at": "2026-02-17T16:25:36Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/30320",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 34619,
      "title": "[Bug]: Qwen3.5. `illegal memory access`",
      "author": "vadiklyutiy",
      "state": "open",
      "created_at": "2026-02-16T12:52:21Z",
      "updated_at": "2026-02-17T16:12:31Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34619",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 18455,
      "title": "[Bug]: Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.",
      "author": "tonyz0x0",
      "state": "open",
      "created_at": "2025-05-21T05:23:40Z",
      "updated_at": "2026-02-17T15:10:16Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/18455",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 34705,
      "title": "[Bug]: Old torch compile files cause poor CPU utilisation",
      "author": "almayne",
      "state": "open",
      "created_at": "2026-02-17T14:27:14Z",
      "updated_at": "2026-02-17T14:29:37Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34705",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 34694,
      "title": "[Bug]: BF16 NVFP4 Marlin produces garbled output on GPUs without native FP4 support",
      "author": "ricky-chaoju",
      "state": "open",
      "created_at": "2026-02-17T12:39:51Z",
      "updated_at": "2026-02-17T12:43:34Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34694",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 26363,
      "title": "[Bug]: xgrammar cleanup leakage",
      "author": "BramVanroy",
      "state": "open",
      "created_at": "2025-10-07T16:47:55Z",
      "updated_at": "2026-02-17T12:37:47Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/26363",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 32554,
      "title": "[Bug]: Error in inspecting model architecture 'Gemma3ForConditionalGeneration'",
      "author": "Skullians",
      "state": "open",
      "created_at": "2026-01-18T15:23:24Z",
      "updated_at": "2026-02-17T11:37:21Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/32554",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 34684,
      "title": "[Bug]: Qwen3.5-397B-A17B - reasoning in content with qwen3 reasoning parser",
      "author": "FWao",
      "state": "open",
      "created_at": "2026-02-17T09:56:00Z",
      "updated_at": "2026-02-17T10:53:27Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34684",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 34449,
      "title": "[Bug]: GLM-5-FP8 malformed tool calls",
      "author": "TALLEC-Scott",
      "state": "open",
      "created_at": "2026-02-12T18:20:25Z",
      "updated_at": "2026-02-17T08:24:24Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34449",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 32730,
      "title": "[Bug]: CPU tests hit CUDA path when VLLM_TARGET_DEVICE=cpu [CPU Backend]",
      "author": "wjhrdy",
      "state": "open",
      "created_at": "2026-01-20T22:18:02Z",
      "updated_at": "2026-02-17T08:00:40Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/32730",
      "labels": [
        "bug",
        "cpu"
      ]
    },
    {
      "number": 34256,
      "title": "[Model Performance SIG]: Improve MoE Oracle",
      "author": "robertgshaw2-redhat",
      "state": "open",
      "created_at": "2026-02-10T16:49:31Z",
      "updated_at": "2026-02-17T06:46:01Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34256",
      "labels": [
        "feature request",
        "rocm",
        "model-bash"
      ]
    },
    {
      "number": 34573,
      "title": "[Installation/Runtime]: Linux ROCM7 /  RuntimeError: No HIP GPUs are available",
      "author": "NickJLange",
      "state": "open",
      "created_at": "2026-02-15T05:46:42Z",
      "updated_at": "2026-02-17T06:06:23Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34573",
      "labels": [
        "installation",
        "rocm"
      ]
    },
    {
      "number": 22497,
      "title": "[Bug]: Crashed when loading ggml quantized Gemma3",
      "author": "Imagium719",
      "state": "open",
      "created_at": "2025-08-08T05:30:18Z",
      "updated_at": "2026-02-17T02:17:28Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/22497",
      "labels": [
        "bug",
        "stale"
      ]
    },
    {
      "number": 22533,
      "title": "[Bug]: gpt-oss-20b flaky BadRequest 400",
      "author": "simonfl",
      "state": "open",
      "created_at": "2025-08-08T18:02:00Z",
      "updated_at": "2026-02-17T02:17:26Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/22533",
      "labels": [
        "bug",
        "stale"
      ]
    },
    {
      "number": 24147,
      "title": "[Bug]: model failure for OpenGVLab/InternVL3-38B-hf",
      "author": "thesillystudent",
      "state": "open",
      "created_at": "2025-09-03T04:57:42Z",
      "updated_at": "2026-02-17T02:17:09Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/24147",
      "labels": [
        "bug",
        "stale"
      ]
    },
    {
      "number": 28640,
      "title": "[Bug]: LoRA/Adapter Loading Error with Qwen3-VL-8B-Instruct Multimodal Model in vLLM Deployment (AssertionError in lora_shrink_op)",
      "author": "pidanshourouzhou",
      "state": "open",
      "created_at": "2025-11-13T12:37:36Z",
      "updated_at": "2026-02-17T02:14:57Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/28640",
      "labels": [
        "bug",
        "unstale"
      ]
    },
    {
      "number": 29523,
      "title": "[CI Failure]: mi325_4: Distributed Tests (4 GPUs)",
      "author": "AndreasKaratzas",
      "state": "open",
      "created_at": "2025-11-26T18:33:22Z",
      "updated_at": "2026-02-16T23:13:43Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/29523",
      "labels": [
        "ci-failure"
      ]
    },
    {
      "number": 33809,
      "title": "[CI Failure]:  Kernels MoE Test %N",
      "author": "AndreasKaratzas",
      "state": "open",
      "created_at": "2026-02-04T17:31:26Z",
      "updated_at": "2026-02-16T23:11:18Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/33809",
      "labels": [
        "ci-failure"
      ]
    },
    {
      "number": 31920,
      "title": "[Bug]: Prefix cache hit rate remains 0 in multi-round conversation with history of identical prompts.",
      "author": "fdarbeha-amd-com",
      "state": "open",
      "created_at": "2026-01-07T20:53:40Z",
      "updated_at": "2026-02-16T21:40:35Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/31920",
      "labels": [
        "bug",
        "rocm"
      ]
    },
    {
      "number": 29511,
      "title": "[CI Failure]: mi325_1: Multi-Modal Models Test (Extended) 1",
      "author": "AndreasKaratzas",
      "state": "open",
      "created_at": "2025-11-26T17:36:17Z",
      "updated_at": "2026-02-16T20:11:55Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/29511",
      "labels": [
        "ci-failure"
      ]
    },
    {
      "number": 34331,
      "title": "[RFC]: Ahead of time dequantization of weights for quantization emulation (OCP MX, NVFP4) on unsupported devices",
      "author": "fxmarty-amd",
      "state": "open",
      "created_at": "2026-02-11T10:26:38Z",
      "updated_at": "2026-02-16T19:15:27Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34331",
      "labels": [
        "rocm",
        "RFC"
      ]
    },
    {
      "number": 34641,
      "title": "[ROCm] Default VLLM_ROCM_USE_AITER_FP4BMM=True crashes on MI300X (gfx942)",
      "author": "khairulkabir1661",
      "state": "open",
      "created_at": "2026-02-16T19:02:38Z",
      "updated_at": "2026-02-16T19:04:53Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34641",
      "labels": [
        "rocm"
      ]
    },
    {
      "number": 34634,
      "title": "[Bug]: SharedStorageConnector: vectorized_gather_kernel assertion on Blackwell (B200) GPUs",
      "author": "mmkamani7",
      "state": "open",
      "created_at": "2026-02-16T17:21:43Z",
      "updated_at": "2026-02-16T17:58:17Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34634",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 31244,
      "title": "[CI Failure]:  mi325_2: Plugin Tests (2 GPUs)",
      "author": "AndreasKaratzas",
      "state": "open",
      "created_at": "2025-12-23T22:43:40Z",
      "updated_at": "2026-02-16T17:53:53Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/31244",
      "labels": [
        "ci-failure"
      ]
    },
    {
      "number": 29466,
      "title": "[CI Failure]: mi325_1: Language Models Test (Extended Pooling)",
      "author": "AndreasKaratzas",
      "state": "open",
      "created_at": "2025-11-26T00:41:57Z",
      "updated_at": "2026-02-16T17:51:05Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/29466",
      "labels": [
        "ci-failure"
      ]
    },
    {
      "number": 29463,
      "title": "[CI Failure]: mi325_1: Language Models Tests (Standard)",
      "author": "AndreasKaratzas",
      "state": "open",
      "created_at": "2025-11-26T00:24:27Z",
      "updated_at": "2026-02-16T17:49:55Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/29463",
      "labels": [
        "ci-failure"
      ]
    },
    {
      "number": 34637,
      "title": "[CI Failure]:  mi325_1: Entrypoints Integration Test (API Server 2)",
      "author": "AndreasKaratzas",
      "state": "open",
      "created_at": "2026-02-16T17:46:24Z",
      "updated_at": "2026-02-16T17:46:34Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34637",
      "labels": [
        "ci-failure"
      ]
    },
    {
      "number": 31631,
      "title": "[CI Failure]:  mi325_1: V1 Test others",
      "author": "AndreasKaratzas",
      "state": "open",
      "created_at": "2026-01-02T22:59:12Z",
      "updated_at": "2026-02-16T17:38:48Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/31631",
      "labels": [
        "ci-failure"
      ]
    },
    {
      "number": 34561,
      "title": "[Bug]: GLM-4.7-Flash-AWQ fails with AttributeError: 'ColumnParallelLinear' object has no attribute 'weight'",
      "author": "eugr",
      "state": "open",
      "created_at": "2026-02-14T18:29:27Z",
      "updated_at": "2026-02-16T17:22:25Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34561",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 34399,
      "title": "[Bug]: Nemotron 3 (all quants) take a LONG time to load",
      "author": "jiangwu300",
      "state": "open",
      "created_at": "2026-02-12T03:44:51Z",
      "updated_at": "2026-02-16T17:19:35Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34399",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 31845,
      "title": "[Bug]: [H200] DeepSeek V3.2 MTP > 1 run into error (FLASHMLA_SPARSE backend)",
      "author": "jhaotingc",
      "state": "open",
      "created_at": "2026-01-06T23:39:29Z",
      "updated_at": "2026-02-16T16:41:51Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/31845",
      "labels": [
        "bug",
        "speculative-decoding",
        "deepseek"
      ]
    },
    {
      "number": 34579,
      "title": "[Performance]: vLLM's throughput lags behind llama.cpp for single prompt",
      "author": "kathirvel-balakrishnan",
      "state": "open",
      "created_at": "2026-02-15T11:19:25Z",
      "updated_at": "2026-02-16T09:30:30Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34579",
      "labels": [
        "performance"
      ]
    },
    {
      "number": 26362,
      "title": "[Bug]: whitespace_pattern not doing anything",
      "author": "BramVanroy",
      "state": "open",
      "created_at": "2025-10-07T16:45:39Z",
      "updated_at": "2026-02-16T08:53:33Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/26362",
      "labels": [
        "bug",
        "unstale"
      ]
    },
    {
      "number": 26571,
      "title": "[Bug]: failed to build from source on sm120 machine",
      "author": "ZJY0516",
      "state": "open",
      "created_at": "2025-10-10T07:54:31Z",
      "updated_at": "2026-02-16T02:16:59Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/26571",
      "labels": [
        "bug",
        "stale"
      ]
    },
    {
      "number": 28014,
      "title": "[Bug]: EngineDeadError, illegal memory access error encountered when serving qwen3-vl on h800/h20",
      "author": "WingEdge777",
      "state": "open",
      "created_at": "2025-11-04T03:11:55Z",
      "updated_at": "2026-02-16T02:15:37Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/28014",
      "labels": [
        "bug",
        "stale"
      ]
    },
    {
      "number": 28098,
      "title": "[Bug]: BF16 and INT8 dtype mismatch when running quantized model on vLLM",
      "author": "logesh13",
      "state": "open",
      "created_at": "2025-11-05T05:22:47Z",
      "updated_at": "2026-02-16T02:15:29Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/28098",
      "labels": [
        "bug",
        "stale"
      ]
    },
    {
      "number": 28228,
      "title": "[Bug]: Kimi Linear KV cache size estimation and usage not making sens",
      "author": "johnr14",
      "state": "open",
      "created_at": "2025-11-06T16:33:07Z",
      "updated_at": "2026-02-16T02:15:20Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/28228",
      "labels": [
        "bug",
        "stale"
      ]
    },
    {
      "number": 28572,
      "title": "[Bug]: vllm refuses to serve LLM in the presence of multiple GPUs",
      "author": "tigran123",
      "state": "open",
      "created_at": "2025-11-12T17:42:25Z",
      "updated_at": "2026-02-16T02:15:04Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/28572",
      "labels": [
        "bug",
        "stale"
      ]
    },
    {
      "number": 28626,
      "title": "[Bug]:Qwen3-VL-32B-AWQ model memory usage: 8k context limit with 40GB VRAM?",
      "author": "maxin9966",
      "state": "open",
      "created_at": "2025-11-13T08:00:20Z",
      "updated_at": "2026-02-16T02:15:01Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/28626",
      "labels": [
        "bug",
        "stale"
      ]
    },
    {
      "number": 28650,
      "title": "[Bug][XPU]: Error spam \"Unsupported gpu_arch of paged_attention_vllm!!\"",
      "author": "DatCaptainHorse",
      "state": "open",
      "created_at": "2025-11-13T13:34:53Z",
      "updated_at": "2026-02-16T02:14:56Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/28650",
      "labels": [
        "bug",
        "intel-gpu",
        "stale"
      ]
    },
    {
      "number": 25179,
      "title": "[Performance]: Custom fused kernel tracking",
      "author": "ProExpertProg",
      "state": "open",
      "created_at": "2025-09-18T15:31:02Z",
      "updated_at": "2026-02-15T18:39:07Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/25179",
      "labels": [
        "performance",
        "torch.compile"
      ]
    },
    {
      "number": 27433,
      "title": "[Feature]: Batch Invariant Feature and Performance Optimization",
      "author": "yewentao256",
      "state": "open",
      "created_at": "2025-10-23T19:38:03Z",
      "updated_at": "2026-02-15T16:23:53Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/27433",
      "labels": [
        "good first issue",
        "feature request"
      ]
    },
    {
      "number": 34545,
      "title": "[Installation]: unrecognized arguments: --omni",
      "author": "HenryBao91",
      "state": "open",
      "created_at": "2026-02-14T01:17:36Z",
      "updated_at": "2026-02-15T10:39:59Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34545",
      "labels": [
        "installation"
      ]
    },
    {
      "number": 28649,
      "title": "[Feature]: Someone please upstream this gfx1201/RDNA4 FP8 Patch into vllm-rocm",
      "author": "Rob-P-Smith",
      "state": "open",
      "created_at": "2025-11-13T13:23:35Z",
      "updated_at": "2026-02-15T03:49:32Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/28649",
      "labels": [
        "feature request",
        "rocm"
      ]
    },
    {
      "number": 28806,
      "title": "[Bug]: Hermes tool call parser drops empty arguments for parameterless tools while streaming",
      "author": "shakez0901",
      "state": "open",
      "created_at": "2025-11-16T11:48:10Z",
      "updated_at": "2026-02-15T02:14:36Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/28806",
      "labels": [
        "bug",
        "stale"
      ]
    },
    {
      "number": 21336,
      "title": "[Bug]: vLLM crashes when using --enable-sleep-mode with Blackwell PRO 6000 GPUs",
      "author": "0xhaggis",
      "state": "open",
      "created_at": "2025-07-21T21:45:48Z",
      "updated_at": "2026-02-14T12:26:54Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/21336",
      "labels": [
        "bug",
        "unstale"
      ]
    }
  ]
}