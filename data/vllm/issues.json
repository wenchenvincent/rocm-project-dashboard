{
  "collected_at": "2026-02-22T08:18:51Z",
  "issues": [
    {
      "number": 34994,
      "title": "[Feature]: Infrastructure Improvements for ROCm CI",
      "author": "AndreasKaratzas",
      "state": "open",
      "created_at": "2026-02-20T22:35:58Z",
      "updated_at": "2026-02-22T08:05:51Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34994",
      "labels": [
        "feature request",
        "rocm"
      ]
    },
    {
      "number": 29520,
      "title": "[CI Failure]: mi325_1: Multi-Modal Models Test (Standard)",
      "author": "AndreasKaratzas",
      "state": "open",
      "created_at": "2025-11-26T18:24:37Z",
      "updated_at": "2026-02-22T08:00:05Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/29520",
      "labels": [
        "ci-failure"
      ]
    },
    {
      "number": 34954,
      "title": "[Bug]: Triton Error [CUDA]: out of memory when received query",
      "author": "kwonmha",
      "state": "open",
      "created_at": "2026-02-20T13:46:28Z",
      "updated_at": "2026-02-22T06:06:52Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34954",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 34859,
      "title": "[Bug]: missing shards from quantized checkpoint fails silently",
      "author": "andrea-fasoli",
      "state": "open",
      "created_at": "2026-02-19T00:22:43Z",
      "updated_at": "2026-02-22T06:06:51Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34859",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 34812,
      "title": "[Bug]: GraniteMoeHybridModel not applying embedding_multiplier to input embeddings",
      "author": "gabe-l-hart",
      "state": "open",
      "created_at": "2026-02-18T15:09:32Z",
      "updated_at": "2026-02-22T06:06:51Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34812",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 31631,
      "title": "[CI Failure]:  mi325_1: V1 Test others",
      "author": "AndreasKaratzas",
      "state": "open",
      "created_at": "2026-01-02T22:59:12Z",
      "updated_at": "2026-02-22T04:09:58Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/31631",
      "labels": [
        "ci-failure"
      ]
    },
    {
      "number": 13941,
      "title": "[Bug]: wake up OOM (72B model in 8*A800(40G))",
      "author": "LugerW-A",
      "state": "open",
      "created_at": "2025-02-27T03:37:20Z",
      "updated_at": "2026-02-22T02:18:02Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/13941",
      "labels": [
        "bug",
        "stale"
      ]
    },
    {
      "number": 27364,
      "title": "[Bug]: Qwen3-VL {4B,8B} FP8 on vLLM returns only exclamation marks (\"!!!!!...\") on Jetson Thor",
      "author": "mantyni",
      "state": "open",
      "created_at": "2025-10-22T19:11:19Z",
      "updated_at": "2026-02-22T02:16:14Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/27364",
      "labels": [
        "bug",
        "stale"
      ]
    },
    {
      "number": 27602,
      "title": "[Bug]: quantized medgemma-27b-text-it producing garbage outputs",
      "author": "kritiyer",
      "state": "open",
      "created_at": "2025-10-27T19:29:20Z",
      "updated_at": "2026-02-22T02:15:46Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/27602",
      "labels": [
        "bug",
        "stale"
      ]
    },
    {
      "number": 29176,
      "title": "[CI Failure]: [AMD] Nixl PD tests",
      "author": "NickLucche",
      "state": "open",
      "created_at": "2025-11-21T10:33:58Z",
      "updated_at": "2026-02-22T02:14:34Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/29176",
      "labels": [
        "rocm",
        "unstale",
        "ci-failure"
      ]
    },
    {
      "number": 27157,
      "title": "[Bug]: Qwen3-VL-30B-A3B-Instruct keeps outputting the same phrases over and over",
      "author": "kozanryusui",
      "state": "open",
      "created_at": "2025-10-18T23:27:10Z",
      "updated_at": "2026-02-22T02:09:10Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/27157",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 35031,
      "title": "[Bug]: MTP Speculative Decoding with NVFP4: Weight Shape Mismatch",
      "author": "eleqtrizit",
      "state": "open",
      "created_at": "2026-02-21T19:33:33Z",
      "updated_at": "2026-02-21T19:33:33Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/35031",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 35028,
      "title": "[Bug]: RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasGemmEx",
      "author": "shahizat",
      "state": "open",
      "created_at": "2026-02-21T17:55:04Z",
      "updated_at": "2026-02-21T17:55:04Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/35028",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 31845,
      "title": "[Bug]: [H200] DeepSeek V3.2 MTP > 1 run into error (FLASHMLA_SPARSE backend)",
      "author": "jhaotingc",
      "state": "open",
      "created_at": "2026-01-06T23:39:29Z",
      "updated_at": "2026-02-21T17:04:58Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/31845",
      "labels": [
        "bug",
        "speculative-decoding",
        "deepseek"
      ]
    },
    {
      "number": 30493,
      "title": "[Bug]: 5090 RTX seems to be broken",
      "author": "mobicham",
      "state": "open",
      "created_at": "2025-12-11T15:56:47Z",
      "updated_at": "2026-02-21T16:16:25Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/30493",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 34090,
      "title": "what am I doing wrong ? libmpi_cxx.so.40: cannot open shared object file: No such file or directory",
      "author": "peter247",
      "state": "open",
      "created_at": "2026-02-08T15:24:48Z",
      "updated_at": "2026-02-21T04:43:38Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34090",
      "labels": [
        "usage"
      ]
    },
    {
      "number": 28110,
      "title": "[Bug]: spark can not run MoE GEMM",
      "author": "qiyuxinlin",
      "state": "open",
      "created_at": "2025-11-05T07:58:49Z",
      "updated_at": "2026-02-21T02:15:05Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/28110",
      "labels": [
        "bug",
        "stale"
      ]
    },
    {
      "number": 29138,
      "title": "[Bug]: AttributeError: 'NoneType' object has no attribute 'use_mxfp4_w4a16'",
      "author": "nole69",
      "state": "open",
      "created_at": "2025-11-21T01:34:26Z",
      "updated_at": "2026-02-21T02:14:13Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/29138",
      "labels": [
        "bug",
        "stale"
      ]
    },
    {
      "number": 25179,
      "title": "[Performance]: Custom fused kernel tracking",
      "author": "ProExpertProg",
      "state": "open",
      "created_at": "2025-09-18T15:31:02Z",
      "updated_at": "2026-02-21T00:43:36Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/25179",
      "labels": [
        "performance",
        "torch.compile"
      ]
    },
    {
      "number": 29373,
      "title": "[Bug]: Multinode inference request with Ray and vLLM crashes - regression from vLLM v0.7.3",
      "author": "ysimeonovatnvidia",
      "state": "open",
      "created_at": "2025-11-25T05:01:15Z",
      "updated_at": "2026-02-20T20:09:13Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/29373",
      "labels": [
        "bug",
        "ray"
      ]
    },
    {
      "number": 29462,
      "title": "[CI Failure]: mi325_8: Language Models Tests (Hybrid) %N",
      "author": "AndreasKaratzas",
      "state": "open",
      "created_at": "2025-11-26T00:21:48Z",
      "updated_at": "2026-02-20T18:34:44Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/29462",
      "labels": [
        "ci-failure"
      ]
    },
    {
      "number": 34331,
      "title": "[RFC]: Ahead of time dequantization of weights for quantization emulation (OCP MX, NVFP4) on unsupported devices",
      "author": "fxmarty-amd",
      "state": "open",
      "created_at": "2026-02-11T10:26:38Z",
      "updated_at": "2026-02-20T17:51:40Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34331",
      "labels": [
        "rocm",
        "RFC"
      ]
    },
    {
      "number": 34326,
      "title": "[Bug]: --served-model-name causes model detection issues",
      "author": "ssendev",
      "state": "open",
      "created_at": "2026-02-11T09:21:49Z",
      "updated_at": "2026-02-20T17:38:00Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34326",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 34705,
      "title": "[Bug]: Old torch compile files cause poor CPU utilisation",
      "author": "almayne",
      "state": "open",
      "created_at": "2026-02-17T14:27:14Z",
      "updated_at": "2026-02-20T17:27:40Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34705",
      "labels": [
        "bug",
        "torch.compile"
      ]
    },
    {
      "number": 34650,
      "title": "Bug: Speculative Decoding (MTP) Causes </think> Detection Failure in Structured Output + Reasoning Mode",
      "author": "cicirori",
      "state": "open",
      "created_at": "2026-02-16T22:09:56Z",
      "updated_at": "2026-02-20T17:02:08Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34650",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 26211,
      "title": "[Bug]: vLLM does not support DeepSeek series on RTX PRO 6000/SM120",
      "author": "yuanyuan19",
      "state": "open",
      "created_at": "2025-10-04T05:52:15Z",
      "updated_at": "2026-02-20T15:58:47Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/26211",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 34886,
      "title": "[Bug]: #32618 performance issue",
      "author": "gengchaogit",
      "state": "open",
      "created_at": "2026-02-19T10:38:26Z",
      "updated_at": "2026-02-20T12:48:49Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34886",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 34496,
      "title": "[Bug]: Responses API crashes with KeyError when reasoning input item has no `content` field",
      "author": "jeonsworld",
      "state": "open",
      "created_at": "2026-02-13T07:12:56Z",
      "updated_at": "2026-02-20T12:37:56Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34496",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 32180,
      "title": "[Bug]: Performance Bottlenecks and V1 Engine Instability on AMD gfx1151 (Strix Halo)",
      "author": "kgundbrain",
      "state": "open",
      "created_at": "2026-01-12T14:03:38Z",
      "updated_at": "2026-02-20T06:25:28Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/32180",
      "labels": [
        "bug",
        "performance",
        "feature request",
        "rocm"
      ]
    },
    {
      "number": 34939,
      "title": "[CI Failure]: V1 e2e + engine : Cannot re-initialize CUDA in forked subprocess",
      "author": "varun-sundar-rabindranath",
      "state": "open",
      "created_at": "2026-02-20T05:11:36Z",
      "updated_at": "2026-02-20T05:11:36Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34939",
      "labels": [
        "ci-failure"
      ]
    },
    {
      "number": 33672,
      "title": "[Bug]: HTTP API multimodal embedding causes image_pad token duplication, producing incorrect results",
      "author": "ojipadeson",
      "state": "open",
      "created_at": "2026-02-03T09:08:23Z",
      "updated_at": "2026-02-20T03:53:20Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/33672",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 26897,
      "title": "[Bug]: deepseekv3.2 tool_calls failure",
      "author": "CallmeZhangChenchen",
      "state": "open",
      "created_at": "2025-10-15T08:34:45Z",
      "updated_at": "2026-02-20T02:22:41Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/26897",
      "labels": [
        "bug",
        "stale"
      ]
    },
    {
      "number": 27300,
      "title": "[Bug]: vLLM produces invalid UTF-8 tokens and \u201c\ufffd\u201d replacement characters when returning logprobs",
      "author": "yinggeh",
      "state": "open",
      "created_at": "2025-10-21T22:17:25Z",
      "updated_at": "2026-02-20T01:05:51Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/27300",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 34752,
      "title": "[Bug]: Improve `--kv-cache-dtype` behavior when checkpoint specifies `kv_cache_quant_algo`",
      "author": "pavanimajety",
      "state": "open",
      "created_at": "2026-02-17T21:29:55Z",
      "updated_at": "2026-02-20T00:39:49Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34752",
      "labels": [
        "bug",
        "good first issue"
      ]
    },
    {
      "number": 34851,
      "title": "[Feature]: Refactor Quark MoE and mxfp4 MoE to align with MoE oracle/MK",
      "author": "BowenBao",
      "state": "open",
      "created_at": "2026-02-18T23:27:55Z",
      "updated_at": "2026-02-20T00:37:45Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34851",
      "labels": [
        "feature request"
      ]
    },
    {
      "number": 34118,
      "title": "[Feature]: [ROCm]: GPTQ INT4 MoE kernel fails on non-SiLU activations - no Marlin fallback on AMD",
      "author": "ehartford",
      "state": "open",
      "created_at": "2026-02-09T05:28:24Z",
      "updated_at": "2026-02-19T18:42:48Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34118",
      "labels": [
        "feature request",
        "rocm"
      ]
    },
    {
      "number": 32455,
      "title": "[Roadmap] vLLM Roadmap Q1 2026",
      "author": "simon-mo",
      "state": "open",
      "created_at": "2026-01-16T04:23:29Z",
      "updated_at": "2026-02-19T17:14:39Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/32455",
      "labels": [
        "rocm"
      ]
    },
    {
      "number": 34817,
      "title": "[Bug]: Trying to run gpt-oss-120b on rtx pro 6000",
      "author": "chadbek",
      "state": "open",
      "created_at": "2026-02-18T15:37:43Z",
      "updated_at": "2026-02-19T11:34:00Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34817",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 34759,
      "title": "[Bug]: nvidia/Llama-3.3-70B-Instruct-NVFP4 Degraded / Gibberish Output with TRITON_ATTN",
      "author": "frankwang28",
      "state": "open",
      "created_at": "2026-02-17T23:19:47Z",
      "updated_at": "2026-02-19T07:22:17Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34759",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 27645,
      "title": "[Bug]: Qwen3-VL-235B-A22B-Instruct stuck with assert placeholder < len(self._out_of_band_tensors)",
      "author": "yry0008",
      "state": "open",
      "created_at": "2025-10-28T09:53:39Z",
      "updated_at": "2026-02-19T02:16:14Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/27645",
      "labels": [
        "bug",
        "stale"
      ]
    },
    {
      "number": 28234,
      "title": "Online Dynamic FP8 Quantization (--quantization=\"fp8\") is slower than BF16/FP16 on RTX 5090",
      "author": "rEwfii",
      "state": "open",
      "created_at": "2025-11-06T18:18:29Z",
      "updated_at": "2026-02-19T02:15:25Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/28234",
      "labels": [
        "bug",
        "stale"
      ]
    },
    {
      "number": 28371,
      "title": "[Installation]: Recipe Installation fails due to missing linux aarch64.whl",
      "author": "SourBhow",
      "state": "open",
      "created_at": "2025-11-10T01:30:20Z",
      "updated_at": "2026-02-19T02:15:15Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/28371",
      "labels": [
        "installation",
        "stale"
      ]
    },
    {
      "number": 28456,
      "title": "[Usage]: benchmark_moe Usage",
      "author": "ekmekovski",
      "state": "open",
      "created_at": "2025-11-11T09:22:33Z",
      "updated_at": "2026-02-19T02:15:10Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/28456",
      "labels": [
        "usage",
        "stale"
      ]
    },
    {
      "number": 28669,
      "title": "vLLM 0.11.0 CUDA Library Mismatch on ARM64 with CUDA 13.x",
      "author": "swatson1000000",
      "state": "open",
      "created_at": "2025-11-13T17:06:38Z",
      "updated_at": "2026-02-19T02:14:58Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/28669",
      "labels": [
        "installation",
        "stale"
      ]
    },
    {
      "number": 28843,
      "title": "[Bug]: GPTQ quants fails to run ( RuntimeError: gpt_marlin_gemm only supports bfloat16 and float16 )",
      "author": "drrros",
      "state": "open",
      "created_at": "2025-11-17T07:58:37Z",
      "updated_at": "2026-02-19T02:14:43Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/28843",
      "labels": [
        "bug",
        "stale"
      ]
    },
    {
      "number": 29014,
      "title": "[Bug]: stride mismatch when using torch compile on graphs with splitting_ops and non-standard tensor dimensions",
      "author": "tomeras91",
      "state": "open",
      "created_at": "2025-11-19T15:48:38Z",
      "updated_at": "2026-02-19T02:14:28Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/29014",
      "labels": [
        "bug",
        "torch.compile",
        "stale"
      ]
    },
    {
      "number": 26206,
      "title": "[Bug]: Qwen3-Next-80B-A3B-Thinking fails to load with CPU offload",
      "author": "br00t4c",
      "state": "open",
      "created_at": "2025-10-04T00:45:39Z",
      "updated_at": "2026-02-19T00:02:53Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/26206",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 34205,
      "title": "[Bug]: Set env ROCP_TOOL_ATTACH=1 caused vllm server stopped",
      "author": "BigFaceBoy",
      "state": "open",
      "created_at": "2026-02-10T03:50:51Z",
      "updated_at": "2026-02-18T22:54:58Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34205",
      "labels": [
        "bug",
        "rocm"
      ]
    },
    {
      "number": 34755,
      "title": "Qwen3-Coder-Next-FP8 with tool calling causes system hard-freeze on multi-GPU tensor parallel (v0.15.1)",
      "author": "zaidorx",
      "state": "open",
      "created_at": "2026-02-17T21:59:44Z",
      "updated_at": "2026-02-18T17:07:14Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34755",
      "labels": [
        "usage"
      ]
    },
    {
      "number": 34573,
      "title": "[Installation/Runtime]: Linux ROCM7 /  RuntimeError: No HIP GPUs are available",
      "author": "NickJLange",
      "state": "open",
      "created_at": "2026-02-15T05:46:42Z",
      "updated_at": "2026-02-18T14:26:07Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34573",
      "labels": [
        "installation",
        "rocm"
      ]
    },
    {
      "number": 29516,
      "title": "[CI Failure]: mi325_4: Distributed Tests (A100)",
      "author": "AndreasKaratzas",
      "state": "open",
      "created_at": "2025-11-26T18:12:19Z",
      "updated_at": "2026-02-18T04:46:14Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/29516",
      "labels": [
        "ci-failure"
      ]
    },
    {
      "number": 29006,
      "title": "[Bug]: OpenAI completion error: 500 Unable to allocate 31.6 GiB for an array with shape (65158, 65158) and data type int64",
      "author": "abhiram1809",
      "state": "open",
      "created_at": "2025-11-19T10:46:01Z",
      "updated_at": "2026-02-18T02:14:43Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/29006",
      "labels": [
        "bug",
        "stale"
      ]
    },
    {
      "number": 29007,
      "title": "[Bug]: 0.11.1 A6000x2 120B OSS wrong generations",
      "author": "Nokimann",
      "state": "open",
      "created_at": "2025-11-19T10:57:06Z",
      "updated_at": "2026-02-18T02:14:41Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/29007",
      "labels": [
        "bug",
        "stale"
      ]
    },
    {
      "number": 32864,
      "title": "[Bug] [ROCm]: Loading Qwen3-MoE-MXFP4 Weights in v0.14.",
      "author": "tjtanaa",
      "state": "open",
      "created_at": "2026-01-22T15:31:23Z",
      "updated_at": "2026-02-18T01:45:06Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/32864",
      "labels": [
        "bug",
        "rocm"
      ]
    },
    {
      "number": 34607,
      "title": "[Bug]: specualative decoding error in 0.15.1",
      "author": "hocop",
      "state": "open",
      "created_at": "2026-02-16T07:46:49Z",
      "updated_at": "2026-02-18T01:21:54Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34607",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 31028,
      "title": "[RFC]: AMD-Quark Online Quantization",
      "author": "hangy-amd",
      "state": "open",
      "created_at": "2025-12-19T12:27:00Z",
      "updated_at": "2026-02-17T23:38:12Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/31028",
      "labels": [
        "rocm",
        "RFC"
      ]
    }
  ]
}