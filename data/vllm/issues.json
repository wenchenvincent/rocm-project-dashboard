{
  "collected_at": "2026-02-23T08:15:19Z",
  "issues": [
    {
      "number": 33654,
      "title": "[Bug]: The content of response from Kimi-K2.5 is empty.",
      "author": "WangTuoxytt",
      "state": "open",
      "created_at": "2026-02-03T06:23:40Z",
      "updated_at": "2026-02-23T07:59:20Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/33654",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 35084,
      "title": "[Bug]: VLLM tries to load \"inductor\" instead of custom compiler",
      "author": "mergian",
      "state": "open",
      "created_at": "2026-02-23T07:51:57Z",
      "updated_at": "2026-02-23T07:51:57Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/35084",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 35057,
      "title": "[Bug]: Qwen3.5 `scheduler_metadata must have shape (metadata_size)` with Decode Context Parallel (DCP)",
      "author": "ehfd",
      "state": "open",
      "created_at": "2026-02-22T15:30:54Z",
      "updated_at": "2026-02-23T07:40:13Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/35057",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 35028,
      "title": "[Bug]: RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasGemmEx",
      "author": "shahizat",
      "state": "open",
      "created_at": "2026-02-21T17:55:04Z",
      "updated_at": "2026-02-23T07:28:09Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/35028",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 35056,
      "title": "[Bug]: Qwen3.5 `AttributeError: 'MRotaryEmbedding' object has no attribute 'truncate'` with RoPE Scaling",
      "author": "ehfd",
      "state": "open",
      "created_at": "2026-02-22T15:10:20Z",
      "updated_at": "2026-02-23T06:56:15Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/35056",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 30493,
      "title": "[Bug]: 5090 RTX seems to be broken",
      "author": "mobicham",
      "state": "open",
      "created_at": "2025-12-11T15:56:47Z",
      "updated_at": "2026-02-23T06:21:47Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/30493",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 24865,
      "title": "[Bug]: v0.10.2 Qwen 3 Next 80b FP8 Slow first request and potential format mismatch: seq_len (4) < num_heads (8)",
      "author": "Syst3m1cAn0maly",
      "state": "open",
      "created_at": "2025-09-15T08:42:46Z",
      "updated_at": "2026-02-23T05:42:49Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/24865",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 34994,
      "title": "[Feature]: Infrastructure Improvements for ROCm CI",
      "author": "AndreasKaratzas",
      "state": "open",
      "created_at": "2026-02-20T22:35:58Z",
      "updated_at": "2026-02-23T05:07:34Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34994",
      "labels": [
        "feature request",
        "rocm"
      ]
    },
    {
      "number": 35031,
      "title": "[Bug]: MTP Speculative Decoding with NVFP4: Weight Shape Mismatch",
      "author": "eleqtrizit",
      "state": "open",
      "created_at": "2026-02-21T19:33:33Z",
      "updated_at": "2026-02-23T05:03:18Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/35031",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 13941,
      "title": "[Bug]: wake up OOM (72B model in 8*A800(40G))",
      "author": "LugerW-A",
      "state": "open",
      "created_at": "2025-02-27T03:37:20Z",
      "updated_at": "2026-02-23T02:18:11Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/13941",
      "labels": [
        "bug",
        "unstale"
      ]
    },
    {
      "number": 25870,
      "title": "[Bug]: gpt-oss-120b failed with data-parallel-size >1",
      "author": "Yaomt",
      "state": "open",
      "created_at": "2025-09-29T09:36:08Z",
      "updated_at": "2026-02-23T02:17:17Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/25870",
      "labels": [
        "bug",
        "stale"
      ]
    },
    {
      "number": 25994,
      "title": "[Bug]: DeepSeek-V3.1 gives garbage output",
      "author": "nicolexin",
      "state": "open",
      "created_at": "2025-09-30T21:39:37Z",
      "updated_at": "2026-02-23T02:17:14Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/25994",
      "labels": [
        "bug",
        "stale"
      ]
    },
    {
      "number": 29151,
      "title": "[Bug]: VLLM Sleep on NVIDIA H100 leading to model producing slow invalid results",
      "author": "relyt0925",
      "state": "open",
      "created_at": "2025-11-21T05:36:46Z",
      "updated_at": "2026-02-23T02:14:48Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/29151",
      "labels": [
        "bug",
        "stale"
      ]
    },
    {
      "number": 29248,
      "title": "[Bug]: Encoder disaggregation example endpoint timeout (Only when PD disaggregation enabled)",
      "author": "chungen04",
      "state": "open",
      "created_at": "2025-11-22T22:11:23Z",
      "updated_at": "2026-02-23T02:14:42Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/29248",
      "labels": [
        "bug",
        "stale"
      ]
    },
    {
      "number": 34296,
      "title": "[Usage]:  vllm/vllm-openai:v0.15.1  No CUDA GPUs are available,0.10.1.1 is ok",
      "author": "ooodwbooo",
      "state": "open",
      "created_at": "2026-02-11T01:09:18Z",
      "updated_at": "2026-02-23T02:08:10Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34296",
      "labels": [
        "usage"
      ]
    },
    {
      "number": 32373,
      "title": "[Bug]: Fail to load vLLM on new NVIDIA driver",
      "author": "huydhn",
      "state": "open",
      "created_at": "2026-01-15T03:15:17Z",
      "updated_at": "2026-02-22T20:58:25Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/32373",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 35061,
      "title": "[Bug]: [torch.compile] occasional failure to save AOT compiled function after successful graph compilation",
      "author": "cjackal",
      "state": "open",
      "created_at": "2026-02-22T17:34:46Z",
      "updated_at": "2026-02-22T17:34:46Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/35061",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 25771,
      "title": "[Bug]: Too many values to unpack in dispatch_cpu_unquantized_gemm [LiquidAi/LMF2]",
      "author": "littlechicks",
      "state": "open",
      "created_at": "2025-09-26T16:10:10Z",
      "updated_at": "2026-02-22T16:24:17Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/25771",
      "labels": [
        "bug",
        "unstale",
        "cpu"
      ]
    },
    {
      "number": 34545,
      "title": "[Installation]: unrecognized arguments: --omni",
      "author": "HenryBao91",
      "state": "open",
      "created_at": "2026-02-14T01:17:36Z",
      "updated_at": "2026-02-22T12:26:55Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34545",
      "labels": [
        "installation"
      ]
    },
    {
      "number": 29520,
      "title": "[CI Failure]: mi325_1: Multi-Modal Models Test (Standard)",
      "author": "AndreasKaratzas",
      "state": "open",
      "created_at": "2025-11-26T18:24:37Z",
      "updated_at": "2026-02-22T08:00:05Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/29520",
      "labels": [
        "ci-failure"
      ]
    },
    {
      "number": 34954,
      "title": "[Bug]: Triton Error [CUDA]: out of memory when received query",
      "author": "kwonmha",
      "state": "open",
      "created_at": "2026-02-20T13:46:28Z",
      "updated_at": "2026-02-22T06:06:52Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34954",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 34859,
      "title": "[Bug]: missing shards from quantized checkpoint fails silently",
      "author": "andrea-fasoli",
      "state": "open",
      "created_at": "2026-02-19T00:22:43Z",
      "updated_at": "2026-02-22T06:06:51Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34859",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 34812,
      "title": "[Bug]: GraniteMoeHybridModel not applying embedding_multiplier to input embeddings",
      "author": "gabe-l-hart",
      "state": "open",
      "created_at": "2026-02-18T15:09:32Z",
      "updated_at": "2026-02-22T06:06:51Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34812",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 31631,
      "title": "[CI Failure]:  mi325_1: V1 Test others",
      "author": "AndreasKaratzas",
      "state": "open",
      "created_at": "2026-01-02T22:59:12Z",
      "updated_at": "2026-02-22T04:09:58Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/31631",
      "labels": [
        "ci-failure"
      ]
    },
    {
      "number": 27364,
      "title": "[Bug]: Qwen3-VL {4B,8B} FP8 on vLLM returns only exclamation marks (\"!!!!!...\") on Jetson Thor",
      "author": "mantyni",
      "state": "open",
      "created_at": "2025-10-22T19:11:19Z",
      "updated_at": "2026-02-22T02:16:14Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/27364",
      "labels": [
        "bug",
        "stale"
      ]
    },
    {
      "number": 27602,
      "title": "[Bug]: quantized medgemma-27b-text-it producing garbage outputs",
      "author": "kritiyer",
      "state": "open",
      "created_at": "2025-10-27T19:29:20Z",
      "updated_at": "2026-02-22T02:15:46Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/27602",
      "labels": [
        "bug",
        "stale"
      ]
    },
    {
      "number": 29176,
      "title": "[CI Failure]: [AMD] Nixl PD tests",
      "author": "NickLucche",
      "state": "open",
      "created_at": "2025-11-21T10:33:58Z",
      "updated_at": "2026-02-22T02:14:34Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/29176",
      "labels": [
        "rocm",
        "unstale",
        "ci-failure"
      ]
    },
    {
      "number": 27157,
      "title": "[Bug]: Qwen3-VL-30B-A3B-Instruct keeps outputting the same phrases over and over",
      "author": "kozanryusui",
      "state": "open",
      "created_at": "2025-10-18T23:27:10Z",
      "updated_at": "2026-02-22T02:09:10Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/27157",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 31845,
      "title": "[Bug]: [H200] DeepSeek V3.2 MTP > 1 run into error (FLASHMLA_SPARSE backend)",
      "author": "jhaotingc",
      "state": "open",
      "created_at": "2026-01-06T23:39:29Z",
      "updated_at": "2026-02-21T17:04:58Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/31845",
      "labels": [
        "bug",
        "speculative-decoding",
        "deepseek"
      ]
    },
    {
      "number": 34090,
      "title": "what am I doing wrong ? libmpi_cxx.so.40: cannot open shared object file: No such file or directory",
      "author": "peter247",
      "state": "open",
      "created_at": "2026-02-08T15:24:48Z",
      "updated_at": "2026-02-21T04:43:38Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34090",
      "labels": [
        "usage"
      ]
    },
    {
      "number": 28110,
      "title": "[Bug]: spark can not run MoE GEMM",
      "author": "qiyuxinlin",
      "state": "open",
      "created_at": "2025-11-05T07:58:49Z",
      "updated_at": "2026-02-21T02:15:05Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/28110",
      "labels": [
        "bug",
        "stale"
      ]
    },
    {
      "number": 29138,
      "title": "[Bug]: AttributeError: 'NoneType' object has no attribute 'use_mxfp4_w4a16'",
      "author": "nole69",
      "state": "open",
      "created_at": "2025-11-21T01:34:26Z",
      "updated_at": "2026-02-21T02:14:13Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/29138",
      "labels": [
        "bug",
        "stale"
      ]
    },
    {
      "number": 25179,
      "title": "[Performance]: Custom fused kernel tracking",
      "author": "ProExpertProg",
      "state": "open",
      "created_at": "2025-09-18T15:31:02Z",
      "updated_at": "2026-02-21T00:43:36Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/25179",
      "labels": [
        "performance",
        "torch.compile"
      ]
    },
    {
      "number": 29373,
      "title": "[Bug]: Multinode inference request with Ray and vLLM crashes - regression from vLLM v0.7.3",
      "author": "ysimeonovatnvidia",
      "state": "open",
      "created_at": "2025-11-25T05:01:15Z",
      "updated_at": "2026-02-20T20:09:13Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/29373",
      "labels": [
        "bug",
        "ray"
      ]
    },
    {
      "number": 29462,
      "title": "[CI Failure]: mi325_8: Language Models Tests (Hybrid) %N",
      "author": "AndreasKaratzas",
      "state": "open",
      "created_at": "2025-11-26T00:21:48Z",
      "updated_at": "2026-02-20T18:34:44Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/29462",
      "labels": [
        "ci-failure"
      ]
    },
    {
      "number": 34331,
      "title": "[RFC]: Ahead of time dequantization of weights for quantization emulation (OCP MX, NVFP4) on unsupported devices",
      "author": "fxmarty-amd",
      "state": "open",
      "created_at": "2026-02-11T10:26:38Z",
      "updated_at": "2026-02-20T17:51:40Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34331",
      "labels": [
        "rocm",
        "RFC"
      ]
    },
    {
      "number": 34326,
      "title": "[Bug]: --served-model-name causes model detection issues",
      "author": "ssendev",
      "state": "open",
      "created_at": "2026-02-11T09:21:49Z",
      "updated_at": "2026-02-20T17:38:00Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34326",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 34705,
      "title": "[Bug]: Old torch compile files cause poor CPU utilisation",
      "author": "almayne",
      "state": "open",
      "created_at": "2026-02-17T14:27:14Z",
      "updated_at": "2026-02-20T17:27:40Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34705",
      "labels": [
        "bug",
        "torch.compile"
      ]
    },
    {
      "number": 34650,
      "title": "Bug: Speculative Decoding (MTP) Causes </think> Detection Failure in Structured Output + Reasoning Mode",
      "author": "cicirori",
      "state": "open",
      "created_at": "2026-02-16T22:09:56Z",
      "updated_at": "2026-02-20T17:02:08Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34650",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 34496,
      "title": "[Bug]: Responses API crashes with KeyError when reasoning input item has no `content` field",
      "author": "jeonsworld",
      "state": "open",
      "created_at": "2026-02-13T07:12:56Z",
      "updated_at": "2026-02-20T12:37:56Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34496",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 32180,
      "title": "[Bug]: Performance Bottlenecks and V1 Engine Instability on AMD gfx1151 (Strix Halo)",
      "author": "kgundbrain",
      "state": "open",
      "created_at": "2026-01-12T14:03:38Z",
      "updated_at": "2026-02-20T06:25:28Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/32180",
      "labels": [
        "bug",
        "performance",
        "feature request",
        "rocm"
      ]
    },
    {
      "number": 34939,
      "title": "[CI Failure]: V1 e2e + engine : Cannot re-initialize CUDA in forked subprocess",
      "author": "varun-sundar-rabindranath",
      "state": "open",
      "created_at": "2026-02-20T05:11:36Z",
      "updated_at": "2026-02-20T05:11:36Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34939",
      "labels": [
        "ci-failure"
      ]
    },
    {
      "number": 34851,
      "title": "[Feature]: Refactor Quark MoE and mxfp4 MoE to align with MoE oracle/MK",
      "author": "BowenBao",
      "state": "open",
      "created_at": "2026-02-18T23:27:55Z",
      "updated_at": "2026-02-20T00:37:45Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34851",
      "labels": [
        "feature request"
      ]
    },
    {
      "number": 34118,
      "title": "[Feature]: [ROCm]: GPTQ INT4 MoE kernel fails on non-SiLU activations - no Marlin fallback on AMD",
      "author": "ehartford",
      "state": "open",
      "created_at": "2026-02-09T05:28:24Z",
      "updated_at": "2026-02-19T18:42:48Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34118",
      "labels": [
        "feature request",
        "rocm"
      ]
    },
    {
      "number": 32455,
      "title": "[Roadmap] vLLM Roadmap Q1 2026",
      "author": "simon-mo",
      "state": "open",
      "created_at": "2026-01-16T04:23:29Z",
      "updated_at": "2026-02-19T17:14:39Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/32455",
      "labels": [
        "rocm"
      ]
    },
    {
      "number": 28456,
      "title": "[Usage]: benchmark_moe Usage",
      "author": "ekmekovski",
      "state": "open",
      "created_at": "2025-11-11T09:22:33Z",
      "updated_at": "2026-02-19T02:15:10Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/28456",
      "labels": [
        "usage",
        "stale"
      ]
    },
    {
      "number": 29014,
      "title": "[Bug]: stride mismatch when using torch compile on graphs with splitting_ops and non-standard tensor dimensions",
      "author": "tomeras91",
      "state": "open",
      "created_at": "2025-11-19T15:48:38Z",
      "updated_at": "2026-02-19T02:14:28Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/29014",
      "labels": [
        "bug",
        "torch.compile",
        "stale"
      ]
    },
    {
      "number": 26206,
      "title": "[Bug]: Qwen3-Next-80B-A3B-Thinking fails to load with CPU offload",
      "author": "br00t4c",
      "state": "open",
      "created_at": "2025-10-04T00:45:39Z",
      "updated_at": "2026-02-19T00:02:53Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/26206",
      "labels": [
        "bug"
      ]
    },
    {
      "number": 34205,
      "title": "[Bug]: Set env ROCP_TOOL_ATTACH=1 caused vllm server stopped",
      "author": "BigFaceBoy",
      "state": "open",
      "created_at": "2026-02-10T03:50:51Z",
      "updated_at": "2026-02-18T22:54:58Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34205",
      "labels": [
        "bug",
        "rocm"
      ]
    },
    {
      "number": 34755,
      "title": "Qwen3-Coder-Next-FP8 with tool calling causes system hard-freeze on multi-GPU tensor parallel (v0.15.1)",
      "author": "zaidorx",
      "state": "open",
      "created_at": "2026-02-17T21:59:44Z",
      "updated_at": "2026-02-18T17:07:14Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34755",
      "labels": [
        "usage"
      ]
    },
    {
      "number": 34573,
      "title": "[Installation/Runtime]: Linux ROCM7 /  RuntimeError: No HIP GPUs are available",
      "author": "NickJLange",
      "state": "open",
      "created_at": "2026-02-15T05:46:42Z",
      "updated_at": "2026-02-18T14:26:07Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/34573",
      "labels": [
        "installation",
        "rocm"
      ]
    },
    {
      "number": 29516,
      "title": "[CI Failure]: mi325_4: Distributed Tests (A100)",
      "author": "AndreasKaratzas",
      "state": "open",
      "created_at": "2025-11-26T18:12:19Z",
      "updated_at": "2026-02-18T04:46:14Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/29516",
      "labels": [
        "ci-failure"
      ]
    },
    {
      "number": 29006,
      "title": "[Bug]: OpenAI completion error: 500 Unable to allocate 31.6 GiB for an array with shape (65158, 65158) and data type int64",
      "author": "abhiram1809",
      "state": "open",
      "created_at": "2025-11-19T10:46:01Z",
      "updated_at": "2026-02-18T02:14:43Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/29006",
      "labels": [
        "bug",
        "stale"
      ]
    },
    {
      "number": 29007,
      "title": "[Bug]: 0.11.1 A6000x2 120B OSS wrong generations",
      "author": "Nokimann",
      "state": "open",
      "created_at": "2025-11-19T10:57:06Z",
      "updated_at": "2026-02-18T02:14:41Z",
      "html_url": "https://github.com/vllm-project/vllm/issues/29007",
      "labels": [
        "bug",
        "stale"
      ]
    }
  ]
}