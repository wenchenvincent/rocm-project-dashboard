{
  "collected_at": "2026-02-25T08:34:35Z",
  "issues": [
    {
      "number": 175728,
      "title": "Numerical discrepancy in nn.Embedding between eager and compile modes",
      "author": "zifan6699",
      "state": "open",
      "created_at": "2026-02-25T08:15:46Z",
      "updated_at": "2026-02-25T08:17:26Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/175728",
      "labels": [
        "triage review",
        "module: numerical-stability",
        "oncall: pt2",
        "module: inductor",
        "bot-triaged"
      ]
    },
    {
      "number": 174166,
      "title": "torch.compile does not support Python try/except",
      "author": "Shawn0v0",
      "state": "open",
      "created_at": "2026-02-03T06:59:14Z",
      "updated_at": "2026-02-25T07:45:28Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/174166",
      "labels": [
        "good first issue",
        "triaged",
        "oncall: pt2",
        "module: dynamo",
        "dynamo-triage-dec2025"
      ]
    },
    {
      "number": 175724,
      "title": "[Distributed][NCCL] Request for Backport: SIGSEGV in HeartbeatMonitor due to thread-unsafe getenv/setenv race (#167523)",
      "author": "tomjen12",
      "state": "open",
      "created_at": "2026-02-25T07:01:10Z",
      "updated_at": "2026-02-25T07:24:13Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/175724",
      "labels": [
        "oncall: distributed",
        "bot-triaged"
      ]
    },
    {
      "number": 175720,
      "title": "DISABLED test_custom_op_with_memory_format_arg_xpu (__main__.AOTInductorTestABICompatibleGpu)",
      "author": "etaf",
      "state": "open",
      "created_at": "2026-02-25T06:33:35Z",
      "updated_at": "2026-02-25T06:36:44Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/175720",
      "labels": [
        "module: tests",
        "triaged",
        "skipped",
        "oncall: pt2",
        "oncall: export",
        "module: aotinductor",
        "module: xpu",
        "bot-triaged"
      ]
    },
    {
      "number": 175719,
      "title": "DISABLED test_flex_attention_with_dynamic_max_autotune_graph_partition_xpu (__main__.TestLearnableBiasesXPU)",
      "author": "etaf",
      "state": "open",
      "created_at": "2026-02-25T06:33:11Z",
      "updated_at": "2026-02-25T06:35:56Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/175719",
      "labels": [
        "module: tests",
        "triaged",
        "skipped",
        "oncall: pt2",
        "module: inductor",
        "module: xpu",
        "module: flex attention",
        "bot-triaged"
      ]
    },
    {
      "number": 175718,
      "title": "DISABLED test_errors_nn_MultiMarginLoss_xpu_float64 (__main__.TestModuleXPU)",
      "author": "etaf",
      "state": "open",
      "created_at": "2026-02-25T06:32:27Z",
      "updated_at": "2026-02-25T06:34:46Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/175718",
      "labels": [
        "module: tests",
        "triaged",
        "skipped",
        "module: xpu",
        "bot-triaged"
      ]
    },
    {
      "number": 175717,
      "title": "DISABLED test_errors_nn_MultiMarginLoss_xpu_float32 (__main__.TestModuleXPU)",
      "author": "etaf",
      "state": "open",
      "created_at": "2026-02-25T06:31:51Z",
      "updated_at": "2026-02-25T06:33:35Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/175717",
      "labels": [
        "module: tests",
        "triaged",
        "skipped",
        "module: xpu",
        "bot-triaged"
      ]
    },
    {
      "number": 175637,
      "title": "Conv2d output inconsistency across different execution modes (device/dtype/optimization)",
      "author": "zifan6699",
      "state": "open",
      "created_at": "2026-02-24T16:32:29Z",
      "updated_at": "2026-02-25T03:25:32Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/175637",
      "labels": [
        "needs reproduction",
        "bot-triaged"
      ]
    },
    {
      "number": 170049,
      "title": "`torch.compile` fails to capture user-defined kernels with latest Triton",
      "author": "jjvraw",
      "state": "open",
      "created_at": "2025-12-10T06:40:23Z",
      "updated_at": "2026-02-25T03:02:50Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/170049",
      "labels": [
        "high priority",
        "triage review",
        "oncall: pt2",
        "module: inductor",
        "upstream triton"
      ]
    },
    {
      "number": 175600,
      "title": "[Inductor][PrivateUse1]: Stride mismatch in constant_pad_nd between privateuse1 and native aten implementation",
      "author": "markc-614",
      "state": "open",
      "created_at": "2026-02-24T02:07:27Z",
      "updated_at": "2026-02-25T01:52:35Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/175600",
      "labels": [
        "triage review",
        "triaged",
        "module: padding",
        "module: meta tensors",
        "oncall: pt2",
        "module: inductor",
        "module: PrivateUse1",
        "bot-triaged"
      ]
    },
    {
      "number": 175690,
      "title": "Dtensor Shard->Replicate redistribution corrupts symbolic shapes under torch.compile",
      "author": "Lucaskabela",
      "state": "open",
      "created_at": "2026-02-25T00:00:09Z",
      "updated_at": "2026-02-25T00:43:25Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/175690",
      "labels": [
        "oncall: distributed",
        "oncall: pt2",
        "bot-triaged"
      ]
    },
    {
      "number": 173525,
      "title": "[MPS] layer_norm backward numerical issues",
      "author": "malfet",
      "state": "open",
      "created_at": "2026-01-27T15:47:00Z",
      "updated_at": "2026-02-25T00:33:10Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/173525",
      "labels": [
        "triaged",
        "module: edge cases",
        "module: mps"
      ]
    },
    {
      "number": 173125,
      "title": "Seq Faults after update [gfx1151]",
      "author": "richardlayman",
      "state": "open",
      "created_at": "2026-01-23T00:48:04Z",
      "updated_at": "2026-02-24T23:49:42Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/173125",
      "labels": [
        "module: rocm",
        "triaged"
      ]
    },
    {
      "number": 24422,
      "title": "Label tracking meta-issue (edit me to get automatically CC'ed on issues! cc bot)",
      "author": "ezyang",
      "state": "open",
      "created_at": "2019-08-15T18:28:22Z",
      "updated_at": "2026-02-24T23:44:05Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/24422",
      "labels": [
        "triaged"
      ]
    },
    {
      "number": 173369,
      "title": "Exporting ONNX model with captum heatmaps generation",
      "author": "Rayndell",
      "state": "open",
      "created_at": "2026-01-26T14:31:36Z",
      "updated_at": "2026-02-24T23:14:19Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/173369",
      "labels": [
        "module: onnx",
        "triaged",
        "oncall: pt2",
        "oncall: export"
      ]
    },
    {
      "number": 175608,
      "title": "torch.compile fails to trace try-except semantic and throw `RuntimeError`",
      "author": "Shawn0v0",
      "state": "open",
      "created_at": "2026-02-24T04:25:26Z",
      "updated_at": "2026-02-24T21:00:20Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/175608",
      "labels": [
        "oncall: pt2"
      ]
    },
    {
      "number": 175533,
      "title": "FlexAttention's `BlockMask._adjust` does not update the sequence lengths",
      "author": "nicolo-domyn",
      "state": "open",
      "created_at": "2026-02-23T13:21:25Z",
      "updated_at": "2026-02-24T20:30:19Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/175533",
      "labels": [
        "module: nn",
        "triaged",
        "oncall: pt2",
        "module: flex attention",
        "bot-triaged"
      ]
    },
    {
      "number": 172747,
      "title": "`torch.compile` silent bug in GGUF dequant, possibly because of `view(dtype)`",
      "author": "woct0rdho",
      "state": "open",
      "created_at": "2026-01-18T16:12:15Z",
      "updated_at": "2026-02-24T19:34:36Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/172747",
      "labels": [
        "high priority",
        "triage review",
        "triaged",
        "oncall: pt2",
        "module: dynamic shapes",
        "module: inductor"
      ]
    },
    {
      "number": 175610,
      "title": "`torch.compile` crashes with `InternalTorchDynamoError: AttributeError` when tracing generator iteration over tensor subclass",
      "author": "sssssh1228",
      "state": "open",
      "created_at": "2026-02-24T04:51:40Z",
      "updated_at": "2026-02-24T18:51:43Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/175610",
      "labels": [
        "oncall: pt2"
      ]
    },
    {
      "number": 146129,
      "title": "torch.compile on Mamba2 model produces NaNs",
      "author": "emmay78",
      "state": "open",
      "created_at": "2025-01-31T04:11:53Z",
      "updated_at": "2026-02-24T18:38:46Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/146129",
      "labels": [
        "triaged",
        "oncall: pt2",
        "module: dynamo"
      ]
    },
    {
      "number": 173707,
      "title": "[Build Success / ROCm 7.2] Workaround for undefined symbol errors (const_data_ptr / mutable_data_ptr) when building PyTorch from source",
      "author": "rashh666",
      "state": "open",
      "created_at": "2026-01-28T21:26:04Z",
      "updated_at": "2026-02-24T18:37:27Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/173707",
      "labels": [
        "module: build",
        "module: rocm",
        "triaged"
      ]
    },
    {
      "number": 158725,
      "title": "including rocm_smi.h without checking",
      "author": "trixirt",
      "state": "open",
      "created_at": "2025-07-20T22:29:13Z",
      "updated_at": "2026-02-24T18:13:37Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/158725",
      "labels": [
        "module: build",
        "module: rocm",
        "triaged",
        "actionable"
      ]
    },
    {
      "number": 175615,
      "title": "torch.compile does not support operator override for user-defined tensor subclass",
      "author": "Shawn0v0",
      "state": "open",
      "created_at": "2026-02-24T05:52:47Z",
      "updated_at": "2026-02-24T16:40:19Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/175615",
      "labels": [
        "oncall: pt2"
      ]
    },
    {
      "number": 174066,
      "title": "How to prevent operator fusion at specific points in TorchInductor?",
      "author": "sujuyu",
      "state": "open",
      "created_at": "2026-02-02T12:16:05Z",
      "updated_at": "2026-02-24T16:09:26Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/174066",
      "labels": [
        "triaged",
        "oncall: pt2",
        "module: inductor"
      ]
    },
    {
      "number": 167636,
      "title": "TorchDynamo Compilation Error: Invalid Stride Handling for FFT in Custom Model During Compilation",
      "author": "Blooming-Tree",
      "state": "open",
      "created_at": "2025-11-12T11:34:05Z",
      "updated_at": "2026-02-24T16:02:45Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/167636",
      "labels": [
        "triaged",
        "module: fft",
        "oncall: pt2",
        "module: inductor"
      ]
    },
    {
      "number": 142834,
      "title": "Segmentation fault in `replication_pad2d_backward`",
      "author": "LongZE666",
      "state": "open",
      "created_at": "2024-12-11T02:59:38Z",
      "updated_at": "2026-02-24T15:42:59Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/142834",
      "labels": [
        "module: crash",
        "module: nn",
        "triaged",
        "actionable",
        "module: edge cases"
      ]
    },
    {
      "number": 145064,
      "title": "`_pdist_forward` causes segmentation fault for 3D tensor with last dimension of size 0",
      "author": "WLFJ",
      "state": "open",
      "created_at": "2025-01-17T11:29:13Z",
      "updated_at": "2026-02-24T15:42:46Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/145064",
      "labels": [
        "module: crash",
        "module: error checking",
        "triaged",
        "actionable",
        "module: empty tensor",
        "topic: fuzzer"
      ]
    },
    {
      "number": 173765,
      "title": "TorchInductor out of shared memory while compiling backwards pass",
      "author": "iczero",
      "state": "open",
      "created_at": "2026-01-29T04:24:29Z",
      "updated_at": "2026-02-24T14:09:54Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/173765",
      "labels": [
        "high priority",
        "triage review",
        "triaged",
        "oncall: pt2",
        "module: inductor"
      ]
    },
    {
      "number": 160759,
      "title": "ROCm on Windows python processes do not terminate on their own",
      "author": "ScottTodd",
      "state": "open",
      "created_at": "2025-08-15T17:40:51Z",
      "updated_at": "2026-02-24T12:29:55Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/160759",
      "labels": [
        "module: rocm",
        "triaged"
      ]
    },
    {
      "number": 175545,
      "title": "FlexAttention does not allow captured tensor of ndim>0",
      "author": "mseeger",
      "state": "open",
      "created_at": "2026-02-23T17:10:11Z",
      "updated_at": "2026-02-24T10:05:51Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/175545",
      "labels": [
        "module: nn",
        "triaged",
        "bot-triaged"
      ]
    },
    {
      "number": 174468,
      "title": "Memory leak by torch.compile",
      "author": "fanganpai",
      "state": "open",
      "created_at": "2026-02-06T12:27:50Z",
      "updated_at": "2026-02-24T10:02:16Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/174468",
      "labels": [
        "needs reproduction",
        "module: memory usage",
        "triaged",
        "module: regression",
        "oncall: pt2",
        "bot-triaged"
      ]
    },
    {
      "number": 172668,
      "title": "Pipeline communication blocks the execution of pipeline stages",
      "author": "yuankaichen-amd",
      "state": "open",
      "created_at": "2026-01-16T19:57:05Z",
      "updated_at": "2026-02-24T00:08:03Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/172668",
      "labels": [
        "high priority",
        "triage review",
        "oncall: distributed",
        "pipeline parallelism"
      ]
    },
    {
      "number": 145498,
      "title": "Unexpected behavior of `torch.nn.init.trunc_normal` with bf16 tensors",
      "author": "hjlee1371",
      "state": "open",
      "created_at": "2025-01-23T17:09:24Z",
      "updated_at": "2026-02-23T18:28:22Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/145498",
      "labels": [
        "high priority",
        "module: distributions",
        "module: nn",
        "module: cpu",
        "triaged",
        "module: random",
        "module: bfloat16"
      ]
    },
    {
      "number": 175368,
      "title": "`F.embedding_bag` segfaults when intermediate offsets exceed indices length",
      "author": "SilentTester73",
      "state": "open",
      "created_at": "2026-02-19T22:32:12Z",
      "updated_at": "2026-02-23T18:13:56Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/175368",
      "labels": [
        "module: nn",
        "module: error checking",
        "triaged",
        "actionable",
        "topic: fuzzer",
        "bot-triaged"
      ]
    },
    {
      "number": 174939,
      "title": "`torch.nn.functional.scaled_dot_product_attention` crashes with a segmentation fault when given zero-sized tensors with specific dimension patterns",
      "author": "Nyovelt",
      "state": "open",
      "created_at": "2026-02-13T02:01:37Z",
      "updated_at": "2026-02-23T18:04:26Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/174939",
      "labels": [
        "module: crash",
        "module: cpu",
        "module: error checking",
        "triaged",
        "topic: fuzzer",
        "module: sdpa",
        "bot-triaged"
      ]
    },
    {
      "number": 175370,
      "title": "`F.embedding_bag` segfaults with float64 weight and empty offsets",
      "author": "SilentTester73",
      "state": "open",
      "created_at": "2026-02-19T22:33:53Z",
      "updated_at": "2026-02-23T17:50:29Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/175370",
      "labels": [
        "module: crash",
        "module: cpu",
        "triaged",
        "module: embedding",
        "module: empty tensor",
        "topic: fuzzer",
        "bot-triaged"
      ]
    },
    {
      "number": 174984,
      "title": "`torch.fft.rfft` errors out with MKL FFT error when given an empty tensor",
      "author": "SilentTester73",
      "state": "open",
      "created_at": "2026-02-13T18:51:12Z",
      "updated_at": "2026-02-23T17:49:21Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/174984",
      "labels": [
        "module: error checking",
        "triaged",
        "actionable",
        "module: fft",
        "module: intel",
        "module: edge cases",
        "module: empty tensor",
        "topic: fuzzer",
        "bot-triaged"
      ]
    },
    {
      "number": 175530,
      "title": "torch.compile fails during backward for ConvNeXt LayerNorm2d (permute + layer_norm)",
      "author": "hassonofer",
      "state": "open",
      "created_at": "2026-02-23T10:59:55Z",
      "updated_at": "2026-02-23T13:41:23Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/175530",
      "labels": [
        "oncall: pt2"
      ]
    },
    {
      "number": 175431,
      "title": "out\u2011of\u2011memory error, although most of GPU memory is still available.",
      "author": "amd-xiaoyu12",
      "state": "open",
      "created_at": "2026-02-20T19:18:06Z",
      "updated_at": "2026-02-23T01:57:07Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/175431",
      "labels": [
        "module: rocm",
        "module: memory usage",
        "triaged",
        "module: CUDACachingAllocator",
        "bot-triaged"
      ]
    },
    {
      "number": 115516,
      "title": "[FakeTensor] FakeTensorMode dispatch won't change generator state",
      "author": "shingjan",
      "state": "open",
      "created_at": "2023-12-11T01:50:38Z",
      "updated_at": "2026-02-22T18:20:05Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/115516",
      "labels": [
        "triaged",
        "module: random",
        "needs design",
        "oncall: pt2",
        "module: fakeTensor",
        "module: pt2-dispatcher"
      ]
    },
    {
      "number": 122860,
      "title": "Do not use assert for user triggered issues",
      "author": "stellaraccident",
      "state": "open",
      "created_at": "2024-03-28T02:56:16Z",
      "updated_at": "2026-02-22T03:48:28Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/122860",
      "labels": [
        "triaged",
        "better-engineering",
        "oncall: pt2",
        "module: functorch",
        "oncall: export",
        "module: pt2-dispatcher"
      ]
    },
    {
      "number": 175482,
      "title": "DISABLED test_index_put_error_cuda (__main__.TestNestedTensorSubclassCUDA)",
      "author": "jithunnair-amd",
      "state": "open",
      "created_at": "2026-02-22T00:06:48Z",
      "updated_at": "2026-02-22T00:08:03Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/175482",
      "labels": [
        "module: rocm",
        "triaged",
        "skipped",
        "bot-triaged"
      ]
    },
    {
      "number": 158212,
      "title": "wrong gradients with compiled flex attention",
      "author": "tsengalb99",
      "state": "open",
      "created_at": "2025-07-14T03:44:01Z",
      "updated_at": "2026-02-21T13:49:46Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/158212",
      "labels": [
        "high priority",
        "triaged",
        "oncall: pt2",
        "upstream triton",
        "module: higher order operators",
        "module: flex attention"
      ]
    },
    {
      "number": 77764,
      "title": "General MPS op coverage tracking issue",
      "author": "albanD",
      "state": "open",
      "created_at": "2022-05-18T18:12:47Z",
      "updated_at": "2026-02-21T12:16:55Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/77764",
      "labels": [
        "feature",
        "triaged",
        "tracker",
        "module: mps"
      ]
    },
    {
      "number": 174794,
      "title": "REGRESSION: Shadowed variable name crashes `torch.compile` in `2.10` (not `2.9`)",
      "author": "rwkeane",
      "state": "open",
      "created_at": "2026-02-11T19:01:05Z",
      "updated_at": "2026-02-21T03:12:40Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/174794",
      "labels": [
        "triaged",
        "oncall: pt2",
        "module: dynamo"
      ]
    },
    {
      "number": 122029,
      "title": "AOTAutograd has high fixed overheads",
      "author": "jansel",
      "state": "open",
      "created_at": "2024-03-16T17:54:15Z",
      "updated_at": "2026-02-21T02:20:57Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/122029",
      "labels": [
        "triaged",
        "better-engineering",
        "oncall: pt2",
        "module: aotdispatch",
        "module: pt2-dispatcher"
      ]
    },
    {
      "number": 40770,
      "title": "Incremental version of pca_lowrank",
      "author": "eitanrich",
      "state": "open",
      "created_at": "2020-06-30T12:56:44Z",
      "updated_at": "2026-02-20T22:13:52Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/40770",
      "labels": [
        "feature",
        "module: cuda",
        "triaged",
        "function request"
      ]
    },
    {
      "number": 174417,
      "title": "[release 2.11] [triton] test/inductor/test_loop_ordering.py::LoopOrderingTest::test_fp8_cast_and_t",
      "author": "atalman",
      "state": "open",
      "created_at": "2026-02-05T20:47:03Z",
      "updated_at": "2026-02-20T18:15:52Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/174417",
      "labels": [
        "triaged",
        "oncall: pt2",
        "module: inductor",
        "upstream triton",
        "module: floatx (formerly float8)",
        "bot-triaged"
      ]
    },
    {
      "number": 171687,
      "title": "gfx1151 (Strix Halo) \u2014 LLM decode is ~90% hipMemcpyWithStream in FP16 & 4-bit; kernels not compute-bound",
      "author": "BellaDoggie",
      "state": "open",
      "created_at": "2026-01-04T23:53:11Z",
      "updated_at": "2026-02-20T16:30:23Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/171687",
      "labels": [
        "module: rocm",
        "triaged",
        "actionable"
      ]
    }
  ]
}