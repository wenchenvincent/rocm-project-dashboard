# Weekly Digest

Week of 2026-02-11 to 2026-02-18

## New Releases

- **vllm**: [v0.16.0](https://github.com/vllm-project/vllm/releases/tag/v0.16.0)

## PRs This Week

### pytorch
- Opened: [#175152](https://github.com/pytorch/pytorch/pull/175152) [ROCM][CI] Timeout 360 for ROCm nightly binaries (@amdfaa)
- Opened: [#175073](https://github.com/pytorch/pytorch/pull/175073) [inductor] Decompose mm to pointwise mul when K==1 (@romanmeta)
- Opened: [#174749](https://github.com/pytorch/pytorch/pull/174749) [inductor] Add FMA-based lerp lowering for CUDA parity (@mlazos)
- Opened: [#175056](https://github.com/pytorch/pytorch/pull/175056) [ROCm] Enable mixed-precision batchnorm tests with relaxed t (@roshanrateria)
- Opened: [#175180](https://github.com/pytorch/pytorch/pull/175180) [rocm] Fix build_amd.py failure when MSLK submodule is missi (@radeksm)
- Opened: [#175047](https://github.com/pytorch/pytorch/pull/175047) [ROCm] Relax gradcheck_nondet_tol for grid_sampler ops (@roshanrateria)
- Opened: [#175054](https://github.com/pytorch/pytorch/pull/175054) [ROCm] Fix test_compile_kernel_advanced TF32 precision misma (@roshanrateria)
- Opened: [#175055](https://github.com/pytorch/pytorch/pull/175055) [ROCm] Fix test_profiler_cuda_sync_events for ROCTracer (@roshanrateria)
- Opened: [#175196](https://github.com/pytorch/pytorch/pull/175196) Make traceback capture work with error already set (@albanD)
- Opened: [#175036](https://github.com/pytorch/pytorch/pull/175036) [docker] Speed up CI docker image builds (@seemethere)
- Opened: [#175179](https://github.com/pytorch/pytorch/pull/175179) [ROCm][CI] Update periodic-rocm-mi200.yml to use linux.rocm. (@amdfaa)
- Opened: [#175079](https://github.com/pytorch/pytorch/pull/175079) Link aotriton when USE_MEM_EFF_ATTENTION is enabled for ROCm (@CalebisGross)
- Opened: [#174855](https://github.com/pytorch/pytorch/pull/174855) [ROCm] triton 37 disable async copy testing + llvm bump (@jataylo)
- Opened: [#175076](https://github.com/pytorch/pytorch/pull/175076) [ROCm] auto-detect GPU architecture for cpp extensions (@CalebisGross)
- Opened: [#175075](https://github.com/pytorch/pytorch/pull/175075) [ROCm] allow AOTRITON_COMMIT env var to override git hash (@CalebisGross)
- Opened: [#175052](https://github.com/pytorch/pytorch/pull/175052) [ROCm] Fix test_transformerencoder_fastpath on MI300X (@roshanrateria)
- Opened: [#175051](https://github.com/pytorch/pytorch/pull/175051) [ROCm] Fix TF32 affine rotation tests on MI300X (@roshanrateria)
- Opened: [#175048](https://github.com/pytorch/pytorch/pull/175048) [ROCm] Fix flaky test_graph_concurrent_replay (@roshanrateria)
- Opened: [#175049](https://github.com/pytorch/pytorch/pull/175049) [ROCm] Fix flaky test_mem_get_info (@roshanrateria)
- Opened: [#175164](https://github.com/pytorch/pytorch/pull/175164) [ROCm] fixed random seed and device mismatch (@anvishwa-amd)
- Opened: [#175095](https://github.com/pytorch/pytorch/pull/175095) Revert "[CI] Enable TIMM pretrained model caching on shared  (@jeffdaily)
- Opened: [#175094](https://github.com/pytorch/pytorch/pull/175094) Revert "[fix] DISABLED test_index (__main__.DistTensorOpsTes (@jeffdaily)
- Opened: [#175096](https://github.com/pytorch/pytorch/pull/175096) Update inductor expected accuracy files (@pytorchbot)
- Merged: [#172179](https://github.com/pytorch/pytorch/pull/172179) Bump fbgemm and torchrec pinned commit (@pytorchbot)

### jax
- Opened: [#35167](https://github.com/jax-ml/jax/pull/35167) Refactor Github Action per b/485167538 (@google-admin)
- Opened: [#35072](https://github.com/jax-ml/jax/pull/35072) A few pre-commit tweaks (@superbobry)
- Opened: [#35111](https://github.com/jax-ml/jax/pull/35111) [ROCm] Add ROCm support for eigh export backwards compatibil (@AratiGanesh)
- Opened: [#35115](https://github.com/jax-ml/jax/pull/35115) [ROCm] Add hip_threefry2x32_ffi to stable custom call target (@AratiGanesh)
- Opened: [#35102](https://github.com/jax-ml/jax/pull/35102) [ROCm] Set release rpaths to rocm so targets (@alekstheod)
- Opened: [#35091](https://github.com/jax-ml/jax/pull/35091) fixed scan crash on GPU with non-default matmul precision (@sarayusapa)
- Opened: [#35011](https://github.com/jax-ml/jax/pull/35011) [ROCm] Remove incorrect ROCm lowering for scaled_matmul to p (@Ruturaj4)
- Merged: [#31768](https://github.com/jax-ml/jax/pull/31768) [ROCm] Support lowering through PJRT_Triton_Extension (@amd-jianli12)
- Merged: [#34829](https://github.com/jax-ml/jax/pull/34829) [ROCm] Add ROCm LU solver to backward compatibility tests (@AratiGanesh)
- Merged: [#34929](https://github.com/jax-ml/jax/pull/34929) [ROCm] Modified `test_with_memory_space` to include ROCm tes (@tsrw2048)
- Merged: [#34966](https://github.com/jax-ml/jax/pull/34966) [ROCm] Skip test_batch_axis_sharding_jvp (@AratiGanesh)
- Merged: [#34561](https://github.com/jax-ml/jax/pull/34561) [ROCm] Enable ToeplitzSymmetricConstruction and condition nu (@tsrw2048)
- Merged: [#34870](https://github.com/jax-ml/jax/pull/34870) [ROCm] Add ROCm backward compatibility test for lu_pivots_to (@AratiGanesh)
- Merged: [#34501](https://github.com/jax-ml/jax/pull/34501) [ROCm] Enable cuda array interface test on ROCm (@magaonka-amd)
- Merged: [#34894](https://github.com/jax-ml/jax/pull/34894) Add ROCm backward compatibility test for cholesky solver (@AratiGanesh)
- Merged: [#33157](https://github.com/jax-ml/jax/pull/33157) [ROCm] Resolve undefined behavior in bitshift unit test (@mminutoli)
- Merged: [#34974](https://github.com/jax-ml/jax/pull/34974) [ROCm] Added ROCm tests to `device_test.py` unit test file. (@tsrw2048)
- Merged: [#34574](https://github.com/jax-ml/jax/pull/34574) [ROCm] Enable test_variadic_reduce_window on GPUs (@magaonka-amd)
- Merged: [#34500](https://github.com/jax-ml/jax/pull/34500) [ROCm] Fix KeyError for bytes_reservable_limit on ROCm (@magaonka-amd)
- Merged: [#34675](https://github.com/jax-ml/jax/pull/34675) [ROCm] Update Skip Reason Outputs (@gulsumgudukbay)
- Merged: [#34474](https://github.com/jax-ml/jax/pull/34474) [ROCm] Added support for GESVDJ on ROCm devices (@tsrw2048)
- Merged: [#34802](https://github.com/jax-ml/jax/pull/34802) [ROCm] Enable lax backend scipy tests on ROCm GPUs (@magaonka-amd)
- Merged: [#34774](https://github.com/jax-ml/jax/pull/34774) [ROCm] Enable lobpcg tests on ROCm platform (@magaonka-amd)
- Merged: [#34575](https://github.com/jax-ml/jax/pull/34575) [ROCm] Enabled the Triton Pallas tests to run for ROCm. (@tsrw2048)
- Merged: [#34893](https://github.com/jax-ml/jax/pull/34893) [ROCm] Enable test deviceless aot compile test on ROCm (@magaonka-amd)
- Merged: [#34494](https://github.com/jax-ml/jax/pull/34494) [ROCm] Enabled ROCm devices to default to Jacobi SVD on smal (@tsrw2048)
- Merged: [#34875](https://github.com/jax-ml/jax/pull/34875) [ROCm] Add ROCm backward compatibility test for threefry2x32 (@AratiGanesh)
- Merged: [#34832](https://github.com/jax-ml/jax/pull/34832) [ROCm] Add ROCm support to annotate_device_placement backwar (@AratiGanesh)
- Merged: [#34869](https://github.com/jax-ml/jax/pull/34869) [ROCm] Added back compatibility test for hipsolver_gesvd (@tsrw2048)
- Merged: [#34689](https://github.com/jax-ml/jax/pull/34689) [ROCm] Fix ROCm GPU architecture detection and route to Trit (@Ruturaj4)
- Merged: [#34578](https://github.com/jax-ml/jax/pull/34578) [ROCm] Unskip supported dtypes for testConvolutionsPreferred (@gulsumgudukbay)
- Merged: [#34534](https://github.com/jax-ml/jax/pull/34534) [ROCm] Enable testDotAlgorithm BF16/TF32 tests on ROCm (@magaonka-amd)
- Merged: [#34577](https://github.com/jax-ml/jax/pull/34577) [ROCm] Enabled RNN unit test "test_no_workspace_overflow" fo (@tsrw2048)
- Merged: [#34567](https://github.com/jax-ml/jax/pull/34567) [ROCm]Unskip testMultivariateNormalSingularCovariance on ROC (@AratiGanesh)
- Merged: [#34571](https://github.com/jax-ml/jax/pull/34571) [ROCm] Enable reduce_window tests on ROCm (@magaonka-amd)
- Merged: [#34890](https://github.com/jax-ml/jax/pull/34890) [ROCm] Enable memory space export tests on ROCm GPUs (@magaonka-amd)
- Merged: [#34304](https://github.com/jax-ml/jax/pull/34304) [ROCm] Add ROCm platform support for psend/precv collective  (@AratiGanesh)
- Merged: [#34662](https://github.com/jax-ml/jax/pull/34662) [ROCm] Enable array interoperability tests on ROCm platform (@magaonka-amd)
- Merged: [#34560](https://github.com/jax-ml/jax/pull/34560) [ROCm] Enable optimizer tests on ROCm (@magaonka-amd)

### vllm
- Opened: [#34636](https://github.com/vllm-project/vllm/pull/34636) [ROCm][Bugfix]: Only save unpadded sizes for shared_experts  (@Rohan138)
- Opened: [#34677](https://github.com/vllm-project/vllm/pull/34677) [Bugfix][CPU] Fix basic unit tests failing in CPU platforms (@jasonyanwenl)
- Opened: [#34753](https://github.com/vllm-project/vllm/pull/34753) [ROCm][CI] Removed hard-coded attn backend requirement for Q (@AndreasKaratzas)
- Opened: [#34653](https://github.com/vllm-project/vllm/pull/34653) [BugFix] [Build] fix string literals comparison in indexer_k (@hongxiayang)
- Opened: [#34760](https://github.com/vllm-project/vllm/pull/34760) Add platform method to enable custom collective ops registra (@nkm-meta)
- Opened: [#34726](https://github.com/vllm-project/vllm/pull/34726) [ROCm] Enable DBO (Dynamic Batch Optimization) on ROCm (@raviguptaamd)
- Opened: [#34631](https://github.com/vllm-project/vllm/pull/34631) [ROCm] Make Whisper causal attention backend-agnostic (@laudney)
- Opened: [#34735](https://github.com/vllm-project/vllm/pull/34735) [AMD][CI] Fix test_custom_allreduce for A100 testgroup (@rjrock)
- Opened: [#34574](https://github.com/vllm-project/vllm/pull/34574) [Frontend] Support multimodal inputs for late-interaction sc (@craftsangjae)
- Opened: [#34756](https://github.com/vllm-project/vllm/pull/34756) preliminary attempt on nightly rocm docker (@hongxiayang)
- Opened: [#34750](https://github.com/vllm-project/vllm/pull/34750) [Rocm][CI] Fix LM Eval Large Models (H100) test group (@charlifu)
- Opened: [#34632](https://github.com/vllm-project/vllm/pull/34632) [ROCm] Add MXFP4 inline dequant Triton kernel for RDNA4/gfx1 (@laudney)
- Opened: [#34709](https://github.com/vllm-project/vllm/pull/34709) [ROCm] Enable wvSplitK skinny GEMM kernel for RDNA4/gfx1x de (@laudney)
- Opened: [#34741](https://github.com/vllm-project/vllm/pull/34741) [ROCm] Enable FP8 KV-cache and relax constraints for RDNA4 c (@laudney)
- Opened: [#34740](https://github.com/vllm-project/vllm/pull/34740) [ROCm] Use supports_fp8() for FP8 feature gates instead of a (@laudney)
- Opened: [#34455](https://github.com/vllm-project/vllm/pull/34455) [Bugfix] Remove assert causing hipErrorStreamCaptureUnsuppor (@JadenMathias)
- Opened: [#34652](https://github.com/vllm-project/vllm/pull/34652) [AMD][CI] Fix test new_weight_syncing/rlhf.py (@rjrock)
- Opened: [#34655](https://github.com/vllm-project/vllm/pull/34655) [CI][AMD][BugFix] Skip tests in test_unquantized_backend_sel (@rasmith)
- Opened: [#34507](https://github.com/vllm-project/vllm/pull/34507) [Bugfix] Fix fused MoE int32 overflow in stride*offset witho (@haosdent)
- Opened: [#34692](https://github.com/vllm-project/vllm/pull/34692) [ROCm] Enable DeepEP ROCm as all2allbackend for AMD GPUs.  (@lcskrishna)
- Opened: [#34301](https://github.com/vllm-project/vllm/pull/34301) [ROCm][Quantization] Add Composable Kernel (CK) backend supp (@dllehr-amd)
- Opened: [#34695](https://github.com/vllm-project/vllm/pull/34695) [WIP][Bugfix] Fix MLA attention crash with AWQ/GPTQ quantize (@haosdent)
- Opened: [#34688](https://github.com/vllm-project/vllm/pull/34688) [ROCm] Enable bitsandbytes quantization support on ROCm (@Abdennacer-Badaoui)
- Opened: [#34324](https://github.com/vllm-project/vllm/pull/34324) Fixed whisper CPU test that does not spawn properly. (@almayne)
- Opened: [#34387](https://github.com/vllm-project/vllm/pull/34387) [ROCm] Update the torch version in rocm_build.txt to use the (@SageMoore)
- Opened: [#34678](https://github.com/vllm-project/vllm/pull/34678) [GGUF][Model] Add Qwen3-Coder-Next GGUF support (@rudybear)
- Opened: [#34647](https://github.com/vllm-project/vllm/pull/34647) [ROCm] Add hardware detection for FP4 BMM to prevent MI300X  (@khairulkabir1661)
- Opened: [#34570](https://github.com/vllm-project/vllm/pull/34570) [ROCm][AITER] Fix aiter paged_attention_v1 decode for slidin (@AndreasKaratzas)
- Opened: [#34481](https://github.com/vllm-project/vllm/pull/34481) [Bugfix][Hardware][AMD] Add ahead-of-time weight dequantizat (@c0de128)
- Opened: [#34307](https://github.com/vllm-project/vllm/pull/34307) [ROCm] [CI] Add new fusion test cases that are relevant to v (@tjtanaa)
- Opened: [#34567](https://github.com/vllm-project/vllm/pull/34567) [CI] Fix ColBERT HF comparison tests on AMD CI + refactor (@AndreasKaratzas)
- Opened: [#34566](https://github.com/vllm-project/vllm/pull/34566) [CI][Metrics] Stabilize tests with polling and subprocess gu (@AndreasKaratzas)
- Opened: [#34589](https://github.com/vllm-project/vllm/pull/34589) [ROCm][CI] Fix plugins test group; updating terratorch and d (@AndreasKaratzas)
- Opened: [#34629](https://github.com/vllm-project/vllm/pull/34629) Targeting the MI355 agent pool with all existing tests (@Alexei-V-Ivanov-AMD)
- Opened: [#34320](https://github.com/vllm-project/vllm/pull/34320) [Bugfix] Fix Dynamo unexpected keyword argument  (@samutamm)
- Opened: [#34590](https://github.com/vllm-project/vllm/pull/34590) [CI][Frontend] Return 422 instead of 500 for invalid Anthrop (@AndreasKaratzas)
- Opened: [#34468](https://github.com/vllm-project/vllm/pull/34468) [CI][Entrypoints] Validate detokenize token IDs to prevent i (@AndreasKaratzas)
- Opened: [#34537](https://github.com/vllm-project/vllm/pull/34537) [Kernels] Fix Helion GPU utils to use platform-agnostic devi (@AndreasKaratzas)
- Opened: [#34378](https://github.com/vllm-project/vllm/pull/34378) Use paged_attention_v1 for sliding window decode in rocm_ait (@iseeyuan)
- Opened: [#34538](https://github.com/vllm-project/vllm/pull/34538) [ROCm][CI] Guard sparse MLA backend imports for ROCm compati (@AndreasKaratzas)
- Opened: [#34304](https://github.com/vllm-project/vllm/pull/34304) Improvements to wvSplitKrc skinny GEMM solution (@amd-hhashemi)
- Opened: [#34294](https://github.com/vllm-project/vllm/pull/34294) [CI] Heavy refactoring of Voxtral multimodal audio model tes (@AndreasKaratzas)
- Opened: [#34543](https://github.com/vllm-project/vllm/pull/34543) [Bugfix] Fix ROCm UVA CPU weight offloading broken by #32993 (@AndreasKaratzas)
- Opened: [#34454](https://github.com/vllm-project/vllm/pull/34454) [Bugfix]: Fix structured output in multi-turn gpt-oss (@bbrowning)
- Opened: [#34469](https://github.com/vllm-project/vllm/pull/34469) [Bugfix][Hardware][AMD] Fix string literal comparison in DIS (@c0de128)
- Opened: [#34447](https://github.com/vllm-project/vllm/pull/34447) [ROCm][CI] Pin TorchCodec to v0.10.0 for ROCm compatibility (@AndreasKaratzas)
- Opened: [#34431](https://github.com/vllm-project/vllm/pull/34431) [ROCm][quantization] improve OCP weight quant parser robust (@xuebwang-amd)
- Opened: [#34384](https://github.com/vllm-project/vllm/pull/34384) [ROCm][CI] Revert Test Groups From mi325_8 to mi325_1 Agent  (@micah-wil)
- Opened: [#34350](https://github.com/vllm-project/vllm/pull/34350) [ROCm] [CI] fix test_unrecognized_env (@tjtanaa)
- Merged: [#34279](https://github.com/vllm-project/vllm/pull/34279) [Bugfix] Fix fused MoE IMA (sans chunking) by using int64 fo (@tlrmchlsmth)
- Merged: [#33493](https://github.com/vllm-project/vllm/pull/33493) Perf tuning and expansion of cases covered for wvSplitKrc (@amd-hhashemi)
- Merged: [#32183](https://github.com/vllm-project/vllm/pull/32183) [MM Encoder] Add Triton ViT attention backend (@Isotr0py)
- Merged: [#32993](https://github.com/vllm-project/vllm/pull/32993) [Feature] Support CPU Offloading without Pytorch Pinned Memo (@wzhao18)
- Merged: [#34047](https://github.com/vllm-project/vllm/pull/34047) [ROCm][CI] Fix serving tokens test failures (@AndreasKaratzas)
- Merged: [#32458](https://github.com/vllm-project/vllm/pull/32458) [CI][BugFix] Fix silent failure in shellcheck hook and basel (@junuxyz)
- Merged: [#34130](https://github.com/vllm-project/vllm/pull/34130) [Perf] fused_moe: add int4_w4a16 benchmark support and tunin (@mgehre-amd)
- Merged: [#29556](https://github.com/vllm-project/vllm/pull/29556) [CI/Build] Skip ray tests on ROCm (@rjrock)
- Merged: [#31834](https://github.com/vllm-project/vllm/pull/31834) [CI/Build] Enable test_kv_cache_events_dp for AMD (@rjrock)
- Merged: [#30272](https://github.com/vllm-project/vllm/pull/30272) [CI/Build] Use spawn subprocess for ROCm (@rjrock)
- Merged: [#8515](https://github.com/vllm-project/vllm/pull/8515) [Model] Add mistral function calling format to all models lo (@patrickvonplaten)
- Merged: [#34192](https://github.com/vllm-project/vllm/pull/34192) [ROCm] Enable MXFP4 MoE weight pre-shuffling on gfx950 and u (@dllehr-amd)
- Merged: [#33626](https://github.com/vllm-project/vllm/pull/33626) [ci] Integrate AMD tests into CI (@khluu)
- Merged: [#33681](https://github.com/vllm-project/vllm/pull/33681) [ROCm] [aiter] Split KV cache update for AiterFlashAttention (@kliuae)
- Merged: [#33948](https://github.com/vllm-project/vllm/pull/33948) [Bugfix]: Fix ROCm fusion attn test; use AttentionBackend ut (@Rohan138)
- Merged: [#24322](https://github.com/vllm-project/vllm/pull/24322) feat: spec decode with draft models (@tomasruizt)
- Merged: [#34013](https://github.com/vllm-project/vllm/pull/34013) Threshold fix wvSplitk for occasional CI fails (@amd-hhashemi)
- Merged: [#34149](https://github.com/vllm-project/vllm/pull/34149) [Bugfix] Fix benchmark_moe.py inplace assertion with torch > (@mgehre-amd)
- Merged: [#34280](https://github.com/vllm-project/vllm/pull/34280) [ROCm][CI] Fix test_sequence_parallel.py location in AMD CI  (@micah-wil)

### sglang
- Opened: [#18951](https://github.com/sgl-project/sglang/pull/18951) [DO NOT MERGE] [AMD] Fix MI35x DeepSeek-V3.2 MTP nightly tes (@michaelzhang-ai)
- Opened: [#18919](https://github.com/sgl-project/sglang/pull/18919) [bugfix?] update outdated unittest document (@SoluMilken)
- Opened: [#18862](https://github.com/sgl-project/sglang/pull/18862) Update torch to 2.10.0 (@Fridge003)
- Opened: [#18811](https://github.com/sgl-project/sglang/pull/18811) [AMD] fix: hip rotary fallback avoiding CUDA JIT (@alphabetc1)
- Opened: [#18734](https://github.com/sgl-project/sglang/pull/18734) [Docs] Refactor SGLang Diffusion Docs (@qianyue76)
- Opened: [#18911](https://github.com/sgl-project/sglang/pull/18911) [AMD] Add GLM-5 nightly test (@michaelzhang-ai)
- Opened: [#18916](https://github.com/sgl-project/sglang/pull/18916) [TorchAO] Enable TorchAO LinearMethod and TorchAOConfig (@ZhiweiYan-96)
- Opened: [#18930](https://github.com/sgl-project/sglang/pull/18930) [AMD] Unit tests for mtp in GLM-4.7  (@almaslof)
- Opened: [#18761](https://github.com/sgl-project/sglang/pull/18761) [AMD] Fix nightly 1-GPU test failures and bench_serving regr (@michaelzhang-ai)
- Opened: [#18920](https://github.com/sgl-project/sglang/pull/18920) ROCm use rotary_embedding from sgl-kernel (@HaiShaw)
- Opened: [#18922](https://github.com/sgl-project/sglang/pull/18922) Revert "[AMD] Fix RotaryEmbedding crash on AMD/ROCm (regress (@HaiShaw)
- Opened: [#18903](https://github.com/sgl-project/sglang/pull/18903) [AMD] Fix RotaryEmbedding crash on AMD/ROCm (regression from (@michaelzhang-ai)
- Opened: [#18860](https://github.com/sgl-project/sglang/pull/18860) update pre-commit config (@SoluMilken)
- Opened: [#18753](https://github.com/sgl-project/sglang/pull/18753) [AMD] Fix/qwen3 5 amd rope cutedsl fallback (@andyluo7)
- Opened: [#18624](https://github.com/sgl-project/sglang/pull/18624) [AMD] DSR1/V3 use fp8 bmm in MLA for MI300X (@zhentaocc)
- Opened: [#18836](https://github.com/sgl-project/sglang/pull/18836) [AMD] Fix sgl-model-gateway Build Errors in ROCm Docker Rele (@bingxche)
- Opened: [#18602](https://github.com/sgl-project/sglang/pull/18602) [CI] feat: add early exit to wait_for_server when process di (@alphabetc1)
- Opened: [#18805](https://github.com/sgl-project/sglang/pull/18805) add testcase for Qwen3 235b Instruct 2507 (@mqhc2020)
- Opened: [#18733](https://github.com/sgl-project/sglang/pull/18733) Add DeepSeek V32 PD disaggregation test (@ShangmingCai)
- Opened: [#18788](https://github.com/sgl-project/sglang/pull/18788) Cleanup unused rerun stages (@ispobock)
- Opened: [#18654](https://github.com/sgl-project/sglang/pull/18654) [schedule] Fix streaming return of customized_info (@yinghai)
- Opened: [#18619](https://github.com/sgl-project/sglang/pull/18619) [diffusion] feat: support tp for qwen-image-edit-2511 (@xiaoyewww)
- Opened: [#18716](https://github.com/sgl-project/sglang/pull/18716) [AMD] Fix Multimodal Test 1 GPU (@bingxche)
- Opened: [#18741](https://github.com/sgl-project/sglang/pull/18741) Build ROCm7.2 Image with latest AITER v0.1.10.post3 (@HaiShaw)
- Opened: [#18738](https://github.com/sgl-project/sglang/pull/18738) [AMD] Test aiter regression (@yctseng0211)
- Opened: [#18708](https://github.com/sgl-project/sglang/pull/18708) Revert: [diffusion] fix: fix fsdp #18187 (@bingxche)
- Opened: [#18684](https://github.com/sgl-project/sglang/pull/18684) [AMD] Pad MoE weights and scales (@mqhc2020)
- Opened: [#18607](https://github.com/sgl-project/sglang/pull/18607) [AMD] Fix accuracy issue when running TP4 dsv3 model with mt (@1am9trash)
- Opened: [#18707](https://github.com/sgl-project/sglang/pull/18707) [AMD] reset AMD image release time and reduce CI queue time (@yctseng0211)
- Opened: [#18698](https://github.com/sgl-project/sglang/pull/18698) [AMD] Enable release image build for ROCm 7.2.0 (@akao-amd)
- Opened: [#18623](https://github.com/sgl-project/sglang/pull/18623) fix(rocm): add parentheses to chained boolean in Triton kern (@Buywatermelon)
- Merged: [#17993](https://github.com/sgl-project/sglang/pull/17993) [3/N] Quantization Refactor: ModelSlim MoE schemes (@TamirBaydasov)
- Merged: [#18395](https://github.com/sgl-project/sglang/pull/18395) [Doc] Convert the speculative decoding notebook to markdow (@alphabetc1)
- Merged: [#17503](https://github.com/sgl-project/sglang/pull/17503) [2/N] Quantization Refactor: Compressed tensors MoE schemes (@TamirBaydasov)
- Merged: [#18437](https://github.com/sgl-project/sglang/pull/18437) [AMD] MORI-EP inter kernel type switch (@Duyi-Wang)
- Merged: [#18496](https://github.com/sgl-project/sglang/pull/18496) [FIX] Correct JIT kernel compilation on newer GPUs with outd (@muse-coder)
- Merged: [#18456](https://github.com/sgl-project/sglang/pull/18456) [diffusion][MUSA] fix: MUSA platform breakage caused by PR # (@yeahdongcn)
- Merged: [#18480](https://github.com/sgl-project/sglang/pull/18480) Added cuda availability guard (@mattteochen)
- Merged: [#18187](https://github.com/sgl-project/sglang/pull/18187) [diffusion] fix: fix fsdp (@mickqian)
- Merged: [#18500](https://github.com/sgl-project/sglang/pull/18500) [Flashinfer Autotune] Fix FlashInfer FP4 MoE autotuning cras (@YAMY1234)
- Merged: [#17799](https://github.com/sgl-project/sglang/pull/17799) [AMD] rocm 7.2 image release, PR test, Nightly Test (@yctseng0211)
- Merged: [#18095](https://github.com/sgl-project/sglang/pull/18095) [diffusion] docs: consolidate diffusion documentation into d (@qianyue76)
- Merged: [#17780](https://github.com/sgl-project/sglang/pull/17780) add support to enable lora with embedding models (@vedantjh2)
- Merged: [#17756](https://github.com/sgl-project/sglang/pull/17756) Register cp-atten-allgather buffers with symm memory (@wangfakang)
- Merged: [#18528](https://github.com/sgl-project/sglang/pull/18528) Fp8 prefill attn kernel integration (@1am9trash)
- Merged: [#18269](https://github.com/sgl-project/sglang/pull/18269) [AMD] Fix Janus-Pro crash and add Kimi-K2.5 nightly test  (@michaelzhang-ai)
- Merged: [#10635](https://github.com/sgl-project/sglang/pull/10635) [Feature] support regex strings as a stopping condition (@glenliu21)

### aiter
- Opened: [#2056](https://github.com/ROCm/aiter/pull/2056) Enabling FPMX4 GEMM on non-FPMX4 devices (Navi31 in particul (@ekuznetsov139)
- Opened: [#2058](https://github.com/ROCm/aiter/pull/2058) fix aiter.ops.triton.rope import (@Rohan138)
- Opened: [#2049](https://github.com/ROCm/aiter/pull/2049) [TRITON] Add smoothquant int8 MoE kernel (@nsusanto)
- Opened: [#2034](https://github.com/ROCm/aiter/pull/2034) Optimize TopK-TopP Sampler Kernel (@aryaman-gupta)
- Opened: [#2053](https://github.com/ROCm/aiter/pull/2053) Support per_block for Pa PS (@ZhangLirong-amd)
- Opened: [#2055](https://github.com/ROCm/aiter/pull/2055) Silence certain warnings stemming from CK (@Micky774)
- Opened: [#2044](https://github.com/ROCm/aiter/pull/2044) [TEST] Flash Attention Integration CI from fork (@micmelesse)
- Opened: [#2052](https://github.com/ROCm/aiter/pull/2052) Prepare repository for size optimization (@sunway513)
- Opened: [#2050](https://github.com/ROCm/aiter/pull/2050) Add Model Benchmarking Tool (@lucas-santos-amd)
- Opened: [#2036](https://github.com/ROCm/aiter/pull/2036) gfx12 gemm a8w8 (@ahmed-bsod)
- Opened: [#2047](https://github.com/ROCm/aiter/pull/2047) GFX1250 Gluon MoE A4W4 Kernel (@farlukas)
- Opened: [#2028](https://github.com/ROCm/aiter/pull/2028) [MOE]: add qwen3-VL UT (@xudoyuan)
- Opened: [#2042](https://github.com/ROCm/aiter/pull/2042) upload mla_a8w8_qh64_qseqlen4_gqaratio16 co in MI300 (@minmengdie)
- Opened: [#2029](https://github.com/ROCm/aiter/pull/2029) [FIX] fix a16 causal mha bwd case for python api (@JaxChen29)
- Opened: [#2039](https://github.com/ROCm/aiter/pull/2039) Introduce HipKittens based nhead=128 MLA Kernel (@ruanjm)
- Opened: [#2025](https://github.com/ROCm/aiter/pull/2025) update ut (@amd-ruitang3)
- Opened: [#2038](https://github.com/ROCm/aiter/pull/2038) gfx1250 gluon initial gemm for a8w8 MoE blockscale kernel (@nsusanto)
- Opened: [#2027](https://github.com/ROCm/aiter/pull/2027) [not ready] Fuse  rms rope blk quant kernel (@yzhou103)
- Opened: [#2057](https://github.com/ROCm/aiter/pull/2057) hotfix a8w8 gemm config (@valarLip)
- Opened: [#2048](https://github.com/ROCm/aiter/pull/2048) [Gluon] Unified Attention 3D development for gfx12 (@k50112113)
- Opened: [#2040](https://github.com/ROCm/aiter/pull/2040) [OPUS] enhance opus UT by adding more tests (@carlushuang)
- Opened: [#2045](https://github.com/ROCm/aiter/pull/2045) [TRITON] fav3 sage optmization (@Chi-Chu319)
- Opened: [#2041](https://github.com/ROCm/aiter/pull/2041) Rocking/fix benchmark mha fwd (@rocking5566)
- Opened: [#2043](https://github.com/ROCm/aiter/pull/2043) Fix qk_norm_rope_cache_quant ut (@ganyi1996ppo)
- Opened: [#2035](https://github.com/ROCm/aiter/pull/2035) Fix accuracy issues in top-p sampling kernels (@kliuae)
- Opened: [#2030](https://github.com/ROCm/aiter/pull/2030) fix: correct duplicate knl_name in mla_asm.csv causing PP8 f (@chun-wan)
- Opened: [#2026](https://github.com/ROCm/aiter/pull/2026) remove asm mask type (@slippedJim)
- Opened: [#2037](https://github.com/ROCm/aiter/pull/2037) Add MI355X tuned GEMM configs for FP4 and FP8 (@sunway513)
- Opened: [#2031](https://github.com/ROCm/aiter/pull/2031) Add support to dpsk-fp4 tp2/tp4(head=64/32) cases (@1am9trash)
- Opened: [#2051](https://github.com/ROCm/aiter/pull/2051) Prepare repository for size optimization (@sunway513)
- Merged: [#1954](https://github.com/ROCm/aiter/pull/1954) feat(ck_tile): add a8w8 blockscale gemm with preshuffleB sup (@kensclin)
- Merged: [#2016](https://github.com/ROCm/aiter/pull/2016) tune triton gemm kernel for MI355 DSV3 DP+EP configuration (@inkcherry)
- Merged: [#1966](https://github.com/ROCm/aiter/pull/1966) Fix known issues in mha cpp api (@slippedJim)
- Merged: [#2024](https://github.com/ROCm/aiter/pull/2024) [gfx942]Add new GEMM configuration files for DSKR1 (@zhentaocc)
- Merged: [#1973](https://github.com/ROCm/aiter/pull/1973) Defer expensive build operations to build_ext.run() (@paradigm)
- Merged: [#2009](https://github.com/ROCm/aiter/pull/2009) enable hd192_128 cas br kernel in python test (@JaxChen29)
- Merged: [#1957](https://github.com/ROCm/aiter/pull/1957) fix mha fwd_v3 _s_buff_Q/K/V/D address overflow (@minmengdie)
- Merged: [#1978](https://github.com/ROCm/aiter/pull/1978) add rmsnorm CK_TILE_FLOAT_TO_BFLOAT16_DEFAULT compile config (@zhyajie)
- Merged: [#2017](https://github.com/ROCm/aiter/pull/2017) [OPUS] add opus UT (@carlushuang)
- Merged: [#2014](https://github.com/ROCm/aiter/pull/2014) Adding gfx1150/51 to RDNA arch (@saeid-rostami)
- Merged: [#1912](https://github.com/ROCm/aiter/pull/1912) Add gfx950 mla a8w8 qh32 kernel (@slippedJim)
- Merged: [#1990](https://github.com/ROCm/aiter/pull/1990) Add `allreduce+rmsnorm+quant` fusion pass (@xytpai)
- Merged: [#2015](https://github.com/ROCm/aiter/pull/2015) update UT (@amd-ruitang3)
- Merged: [#2022](https://github.com/ROCm/aiter/pull/2022) [CK]: Devperf fp8 ptpc tp8 bugfix (@xudoyuan)

### atom
- Opened: [#222](https://github.com/ROCm/ATOM/pull/222) Fix prefix caching crash: recalculate num_new_tokens after b (@ChuanLi1101)
- Opened: [#220](https://github.com/ROCm/ATOM/pull/220) Enable Triton MXFP4 MoE on gfx950 for GPT-OSS (@ChuanLi1101)
- Opened: [#212](https://github.com/ROCm/ATOM/pull/212) Fix CI container name collision for parallel matrix jobs (@sunway513)
- Opened: [#218](https://github.com/ROCm/ATOM/pull/218) Enable AllReduce+RMSNorm fusion for GPT-OSS model (@ChuanLi1101)
- Opened: [#210](https://github.com/ROCm/ATOM/pull/210) CI: Add thresholds for models accuracy tests (@gyohuangxin)
- Opened: [#208](https://github.com/ROCm/ATOM/pull/208) Not yet ready for review - Add support for Kimi-K2 and Kimi- (@thpereir)
- Opened: [#206](https://github.com/ROCm/ATOM/pull/206) Revert "CI: Use DeepSeek-R1-0528-mtp-mxfp4 models for deepse (@gyohuangxin)
- Opened: [#219](https://github.com/ROCm/ATOM/pull/219) mtp refine (@valarLip)
- Opened: [#209](https://github.com/ROCm/ATOM/pull/209) Fix exclude layer (@ZhangLirong-amd)
- Opened: [#217](https://github.com/ROCm/ATOM/pull/217) Kill all Docker containers before 8gpu workloads launch (@okakarpa)
- Opened: [#216](https://github.com/ROCm/ATOM/pull/216) Revert PR #215: Remove kill-containers workflow (@okakarpa)
- Opened: [#215](https://github.com/ROCm/ATOM/pull/215) Add workflow to kill Docker containers and check ROCm on MI3 (@okakarpa)
- Opened: [#214](https://github.com/ROCm/ATOM/pull/214) Revert PR #213: Remove kill-containers workflow (@okakarpa)
- Opened: [#213](https://github.com/ROCm/ATOM/pull/213) Add workflow to kill Docker containers and check ROCm on MI3 (@okakarpa)
- Opened: [#211](https://github.com/ROCm/ATOM/pull/211) Print debug logs for inference workload (@dhonnappa-amd)
- Opened: [#207](https://github.com/ROCm/ATOM/pull/207) Engine_refine2 (@valarLip)
- Merged: [#204](https://github.com/ROCm/ATOM/pull/204) Add GPU-free unit test suite for core engine components (@sunway513)
- Merged: [#171](https://github.com/ROCm/ATOM/pull/171) Support Qwen3-Next on ATOM Framework (@PerryZhang01)

### mori
- Opened: [#170](https://github.com/ROCm/mori/pull/170) Optimize: EP4 intranode kernel for FP4 dispatch + FP8 combin (@jhchouuu)
- Opened: [#169](https://github.com/ROCm/mori/pull/169) Feat: Enable intra-node FP4 dispatch and BF16 cast to FP8 co (@isytwu)
- Opened: [#167](https://github.com/ROCm/mori/pull/167) Feature: add fp4 support  (@TianDi101)
- Opened: [#166](https://github.com/ROCm/mori/pull/166) Feat: Fp8 direct cast in Combine (@maning00)

## New Issues This Week

### pytorch
- [#175192](https://github.com/pytorch/pytorch/issues/175192) [MPS] linalg.solve backward gives wrong gradients for both A (@npinto)
- [#175188](https://github.com/pytorch/pytorch/issues/175188) [MPS] tanh/sigmoid/silu backward produces wrong gradients on (@npinto)
- [#175190](https://github.com/pytorch/pytorch/issues/175190) [MPS] AvgPool2d/AdaptiveAvgPool2d backward crashes (SIGABRT) (@npinto)
- [#175211](https://github.com/pytorch/pytorch/issues/175211) CUDA/ROCm/Accelerator testing should replace get_device_capa (@jeffdaily)
- [#175187](https://github.com/pytorch/pytorch/issues/175187) [MPS] sort and digamma produce wrong results on non-contiguo (@npinto)
- [#175189](https://github.com/pytorch/pytorch/issues/175189) [MPS] BatchNorm2d backward produces wildly wrong weight grad (@npinto)
- [#175182](https://github.com/pytorch/pytorch/issues/175182) RuntimeError not raised on Thor/Spark in `test_float8_basics (@gderossi)
- [#175145](https://github.com/pytorch/pytorch/issues/175145) [torch.disitributed] Persistent Deadlock when overlapping NC (@ilmarkov)
- [#174884](https://github.com/pytorch/pytorch/issues/174884) Inductor BF16 training crashes with autograd INTERNAL ASSERT (@kumartanmay-28)
- [#174949](https://github.com/pytorch/pytorch/issues/174949) [vllm] CUBLAS_STATUS_INVALID_VALUE in cublasGemmEx after upg (@ZJY0516)
- [#175025](https://github.com/pytorch/pytorch/issues/175025) Mega-Cache generate mismatched guard states when loading the (@liyineeek-source)
- [#175160](https://github.com/pytorch/pytorch/issues/175160) check if file exsits before hipifying (@trixirt)
- [#174794](https://github.com/pytorch/pytorch/issues/174794) REGRESSION: Shadowed variable name crashes `torch.compile` i (@rwkeane)
- [#174984](https://github.com/pytorch/pytorch/issues/174984) `torch.fft.rfft` errors out with MKL FFT error when given an (@SilentTester73)
- [#174763](https://github.com/pytorch/pytorch/issues/174763) torch._grouped_mm is not autocast-compatible, causes dtype m (@Mr-Neutr0n)
- [#175064](https://github.com/pytorch/pytorch/issues/175064) DISABLED test_index (__main__.DistTensorOpsTest) (@seemethere)
- [#174986](https://github.com/pytorch/pytorch/issues/174986) `torch.istft` returns an unhelpful internal error (@SilentTester73)
- [#174985](https://github.com/pytorch/pytorch/issues/174985) `torch.isclose` fails with a broadcast when comparing with ` (@SilentTester73)
- [#174939](https://github.com/pytorch/pytorch/issues/174939) `torch.nn.functional.scaled_dot_product_attention` crashes w (@Nyovelt)
- [#174913](https://github.com/pytorch/pytorch/issues/174913) Test: TestLinalg.test_tensorinv (@jeffdaily)
- [#174876](https://github.com/pytorch/pytorch/issues/174876) [export] while_loop raises GuardOnDataDependentSymNode if an (@Callidior)

### vllm
- [#34781](https://github.com/vllm-project/vllm/issues/34781) [Feature]: parity with cuda - ROCm Kimi K2.5 disagg PD +wide (@functionstackx)
- [#34650](https://github.com/vllm-project/vllm/issues/34650) Bug: Speculative Decoding (MTP) Causes </think> Detection Fa (@cicirori)
- [#34752](https://github.com/vllm-project/vllm/issues/34752) [Bug]: Improve `--kv-cache-dtype` behavior when checkpoint s (@pavanimajety)
- [#34759](https://github.com/vllm-project/vllm/issues/34759) [Bug]: nvidia/Llama-3.3-70B-Instruct-NVFP4 Degraded / Gibber (@frankwang28)
- [#34755](https://github.com/vllm-project/vllm/issues/34755) Qwen3-Coder-Next-FP8 with tool calling causes system hard-fr (@zaidorx)
- [#34607](https://github.com/vllm-project/vllm/issues/34607) [Bug]: specualative decoding error in 0.15.1 (@hocop)
- [#34331](https://github.com/vllm-project/vllm/issues/34331) [RFC]: Ahead of time dequantization of weights for quantizat (@fxmarty-amd)
- [#34583](https://github.com/vllm-project/vllm/issues/34583) [Bug] Missing Vocabulary Validation for MTP and Eagle Specul (@amadhan882)
- [#34437](https://github.com/vllm-project/vllm/issues/34437) [Bug]: Qwen3 Next with heterogeneous GPU (FP8 overflow?) (@Nepherpitou)
- [#34619](https://github.com/vllm-project/vllm/issues/34619) [Bug]: Qwen3.5. `illegal memory access` (@vadiklyutiy)
- [#34705](https://github.com/vllm-project/vllm/issues/34705) [Bug]: Old torch compile files cause poor CPU utilisation (@almayne)
- [#34694](https://github.com/vllm-project/vllm/issues/34694) [Bug]: BF16 NVFP4 Marlin produces garbled output on GPUs wit (@ricky-chaoju)
- [#34449](https://github.com/vllm-project/vllm/issues/34449) [Bug]: GLM-5-FP8 malformed tool calls (@TALLEC-Scott)
- [#34573](https://github.com/vllm-project/vllm/issues/34573) [Installation/Runtime]: Linux ROCM7 /  RuntimeError: No HIP  (@NickJLange)
- [#34641](https://github.com/vllm-project/vllm/issues/34641) [ROCm] Default VLLM_ROCM_USE_AITER_FP4BMM=True crashes on MI (@khairulkabir1661)
- [#34637](https://github.com/vllm-project/vllm/issues/34637) [CI Failure]:  mi325_1: Entrypoints Integration Test (API Se (@AndreasKaratzas)
- [#34561](https://github.com/vllm-project/vllm/issues/34561) [Bug]: GLM-4.7-Flash-AWQ fails with AttributeError: 'ColumnP (@eugr)
- [#34399](https://github.com/vllm-project/vllm/issues/34399) [Bug]: Nemotron 3 (all quants) take a LONG time to load (@jiangwu300)
- [#34579](https://github.com/vllm-project/vllm/issues/34579) [Performance]: vLLM's throughput lags behind llama.cpp for s (@kathirvel-balakrishnan)

### sglang
- [#18812](https://github.com/sgl-project/sglang/issues/18812) [Bug] RotaryEmbedding fallback requires CUDA_HOME on HIP (@alphabetc1)
- [#18749](https://github.com/sgl-project/sglang/issues/18749) [Bug] DP Attention FP4 Disagg AMD is broken (@functionstackx)

### aiter
- [#2059](https://github.com/ROCm/aiter/issues/2059) [Issue]: GLM-5 aiter fused_moe with SGLang + MI355 (@ozziemoreno)
- [#2054](https://github.com/ROCm/aiter/issues/2054) [Feature]: Migrate Python bindings from pybind11 to apache-t (@carlushuang)
- [#2046](https://github.com/ROCm/aiter/issues/2046) Questions about topk_per_row_kernel in topk_plain_kernels.cu (@zjin-lcf)
- [#2033](https://github.com/ROCm/aiter/issues/2033) [Feature]: Add OPUS tests in Aiter CI (@gyohuangxin)

### atom
- [#221](https://github.com/ROCm/ATOM/issues/221) [Issue]: ATOM fails on Qwen3 model when the flag "--enable_p (@vecheruk-amd)

### mori
- [#168](https://github.com/ROCm/mori/issues/168) [Issue]: MORI-EP bug on MI300X+CX7 (@TianDi101)
