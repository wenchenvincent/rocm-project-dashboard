# Weekly Digest

Week of 2026-02-10 to 2026-02-17

## New Releases

- **vllm**: [v0.16.0](https://github.com/vllm-project/vllm/releases/tag/v0.16.0)

## PRs This Week

### aiter
- Opened: [#2052](https://github.com/ROCm/aiter/pull/2052) Prepare repository for size optimization (@sunway513)
- Opened: [#2051](https://github.com/ROCm/aiter/pull/2051) Prepare repository for size optimization (@sunway513)

### atom
- Opened: [#212](https://github.com/ROCm/ATOM/pull/212) Fix CI container name collision for parallel matrix jobs (@sunway513)
- Opened: [#204](https://github.com/ROCm/ATOM/pull/204) Add GPU-free unit test suite for core engine components (@sunway513)

### vllm
- Opened: [#34652](https://github.com/vllm-project/vllm/pull/34652) [AMD][CI] Fix test new_weight_syncing/rlhf.py (@rjrock)
- Opened: [#34655](https://github.com/vllm-project/vllm/pull/34655) [CI][AMD][BugFix] Skip tests in test_unquantized_backend_sel (@rasmith)
- Opened: [#34735](https://github.com/vllm-project/vllm/pull/34735) [AMD][CI] Fix test_custom_allreduce for A100 testgroup (@rjrock)
- Opened: [#34726](https://github.com/vllm-project/vllm/pull/34726) [ROCm] Enable DBO (Dynamic Batch Optimization) on ROCm (@raviguptaamd)
- Opened: [#34275](https://github.com/vllm-project/vllm/pull/34275) [ROCm] Add RDNA3 tile-size heuristic for "triton_scaled_mm"  (@monajafi-amd)
- Opened: [#34653](https://github.com/vllm-project/vllm/pull/34653) [BugFix] [Build] fix string literals comparison in indexer_k (@hongxiayang)
- Opened: [#34636](https://github.com/vllm-project/vllm/pull/34636) [ROCm][Bugfix]: Only save unpadded sizes for shared_experts  (@Rohan138)
- Opened: [#34692](https://github.com/vllm-project/vllm/pull/34692) [ROCm] Enable DeepEP ROCm as all2allbackend for AMD GPUs.  (@lcskrishna)
- Opened: [#34301](https://github.com/vllm-project/vllm/pull/34301) [ROCm][Quantization] Add Composable Kernel (CK) backend supp (@dllehr-amd)
- Opened: [#34695](https://github.com/vllm-project/vllm/pull/34695) [WIP][Bugfix] Fix MLA attention crash with AWQ/GPTQ quantize (@haosdent)
- Opened: [#34455](https://github.com/vllm-project/vllm/pull/34455) [Bugfix] Remove assert causing hipErrorStreamCaptureUnsuppor (@JadenMathias)
- Opened: [#34688](https://github.com/vllm-project/vllm/pull/34688) [ROCm] Enable bitsandbytes quantization support on ROCm (@Abdennacer-Badaoui)
- Opened: [#34709](https://github.com/vllm-project/vllm/pull/34709) [ROCm] Enable wvSplitK skinny GEMM kernel for RDNA4/gfx1x de (@laudney)
- Opened: [#34574](https://github.com/vllm-project/vllm/pull/34574) [Frontend] Support multimodal inputs for late-interaction sc (@craftsangjae)
- Opened: [#34677](https://github.com/vllm-project/vllm/pull/34677) [Bugfix][CPU] Fix basic unit tests failing in CPU platforms (@jasonyanwenl)
- Opened: [#34387](https://github.com/vllm-project/vllm/pull/34387) [ROCm] Update the torch version in rocm_build.txt to use the (@SageMoore)
- Opened: [#34678](https://github.com/vllm-project/vllm/pull/34678) [GGUF][Model] Add Qwen3-Coder-Next GGUF support (@rudybear)
- Opened: [#34631](https://github.com/vllm-project/vllm/pull/34631) [ROCm] Make Whisper causal attention backend-agnostic (@laudney)
- Opened: [#34647](https://github.com/vllm-project/vllm/pull/34647) [ROCm] Add hardware detection for FP4 BMM to prevent MI300X  (@khairulkabir1661)
- Opened: [#34285](https://github.com/vllm-project/vllm/pull/34285) [Refactor] Move FusedMoE hidden_size roundup to quant_method (@BowenBao)
- Opened: [#34644](https://github.com/vllm-project/vllm/pull/34644) [release 2.11] Update to torch 2.11-rc1 (@atalman)
- Opened: [#34265](https://github.com/vllm-project/vllm/pull/34265) [Perf][Kernel] Improve topKperRow for large context decode p (@LopezCastroRoberto)
- Opened: [#34570](https://github.com/vllm-project/vllm/pull/34570) [ROCm][AITER] Fix aiter paged_attention_v1 decode for slidin (@AndreasKaratzas)
- Opened: [#34481](https://github.com/vllm-project/vllm/pull/34481) [Bugfix][Hardware][AMD] Add ahead-of-time weight dequantizat (@c0de128)
- Opened: [#34456](https://github.com/vllm-project/vllm/pull/34456) [CI/Build] Add .deps to .dockerignore to prevent state from  (@tlrmchlsmth)
- Opened: [#34307](https://github.com/vllm-project/vllm/pull/34307) [ROCm] [CI] Add new fusion test cases that are relevant to v (@tjtanaa)
- Opened: [#34567](https://github.com/vllm-project/vllm/pull/34567) [CI] Fix ColBERT HF comparison tests on AMD CI + refactor (@AndreasKaratzas)
- Opened: [#34304](https://github.com/vllm-project/vllm/pull/34304) Improvements to wvSplitKrc skinny GEMM solution (@amd-hhashemi)
- Opened: [#34540](https://github.com/vllm-project/vllm/pull/34540) [Kernel] [Helion] [8/N] Remove fake_impl usage and inference (@gmagogsfm)
- Opened: [#34469](https://github.com/vllm-project/vllm/pull/34469) [Bugfix][Hardware][AMD] Fix string literal comparison in DIS (@c0de128)

### sglang
- Opened: [#18919](https://github.com/sgl-project/sglang/pull/18919) [bugfix?] update outdated unittest document (@SoluMilken)
- Opened: [#18862](https://github.com/sgl-project/sglang/pull/18862) Update torch to 2.10.0 (@Fridge003)
- Opened: [#18811](https://github.com/sgl-project/sglang/pull/18811) [AMD] fix: hip rotary fallback avoiding CUDA JIT (@alphabetc1)
- Opened: [#18734](https://github.com/sgl-project/sglang/pull/18734) [Docs] Refactor SGLang Diffusion Docs (@qianyue76)
- Opened: [#18911](https://github.com/sgl-project/sglang/pull/18911) [AMD] Add GLM-5 nightly test (@michaelzhang-ai)
- Opened: [#18916](https://github.com/sgl-project/sglang/pull/18916) [TorchAO] Enable TorchAO LinearMethod and TorchAOConfig (@ZhiweiYan-96)
- Opened: [#18930](https://github.com/sgl-project/sglang/pull/18930) [AMD] Unit tests for mtp in GLM-4.7  (@almaslof)
- Opened: [#18624](https://github.com/sgl-project/sglang/pull/18624) [AMD] DSR1/V3 use fp8 bmm in MLA for MI300X (@zhentaocc)
- Opened: [#18530](https://github.com/sgl-project/sglang/pull/18530) [Diffusion] [AMD] fuse norm & rope for qwen-image (@qichu-yun)
- Opened: [#18805](https://github.com/sgl-project/sglang/pull/18805) add testcase for Qwen3 235b Instruct 2507 (@mqhc2020)
- Opened: [#18733](https://github.com/sgl-project/sglang/pull/18733) Add DeepSeek V32 PD disaggregation test (@ShangmingCai)
- Opened: [#18738](https://github.com/sgl-project/sglang/pull/18738) [AMD] Test aiter regression (@yctseng0211)
- Opened: [#18708](https://github.com/sgl-project/sglang/pull/18708) Revert: [diffusion] fix: fix fsdp #18187 (@bingxche)
- Opened: [#18684](https://github.com/sgl-project/sglang/pull/18684) [AMD] Pad MoE weights and scales (@mqhc2020)
- Opened: [#18526](https://github.com/sgl-project/sglang/pull/18526) [AMD] Enable cudagraph for aiter nsa backend and add aiter i (@wufann)
- Opened: [#18656](https://github.com/sgl-project/sglang/pull/18656) [AMD] [DO NOT MERGE] Test CI (@bingxche)
- Opened: [#18571](https://github.com/sgl-project/sglang/pull/18571) ROCm: Fix AITER attention for Qwen3-Coder-Next hybrid models (@jhinpan)
- Opened: [#18623](https://github.com/sgl-project/sglang/pull/18623) fix(rocm): add parentheses to chained boolean in Triton kern (@Buywatermelon)
- Opened: [#18547](https://github.com/sgl-project/sglang/pull/18547) chore: bump sgl-kernel version to 0.3.21.post1 (@sglang-bot)
- Opened: [#18537](https://github.com/sgl-project/sglang/pull/18537) [MUSA][11/N] ci: add MUSA 4.3 kernel build and release pipel (@johnnycxm)

### pytorch
- Opened: [#175079](https://github.com/pytorch/pytorch/pull/175079) Link aotriton when USE_MEM_EFF_ATTENTION is enabled for ROCm (@CalebisGross)
- Opened: [#174855](https://github.com/pytorch/pytorch/pull/174855) [ROCm] triton 37 disable async copy testing + llvm bump (@jataylo)
- Opened: [#174990](https://github.com/pytorch/pytorch/pull/174990) [reland] c10d: convert NanCheck to an op + tests (#174736) (@d4l3k)
- Opened: [#174748](https://github.com/pytorch/pytorch/pull/174748) Fix scatter_reduce in-place op handling in Inductor memref c (@sidt-meta)
- Opened: [#175036](https://github.com/pytorch/pytorch/pull/175036) [docker] Speed up CI docker image builds (@seemethere)
- Opened: [#175073](https://github.com/pytorch/pytorch/pull/175073) [inductor] Decompose mm to pointwise mul when K==1 (@romanmeta)
- Opened: [#175164](https://github.com/pytorch/pytorch/pull/175164) [ROCm] fixed random seed and device mismatch (@anvishwa-amd)
- Opened: [#175152](https://github.com/pytorch/pytorch/pull/175152) [ROCM][CI] Timeout 360 for ROCm nightly binaries (@amdfaa)
- Opened: [#174683](https://github.com/pytorch/pytorch/pull/174683) Unskipped some flex attention ROCm-specific skips (@AmdSampsa)
- Opened: [#175056](https://github.com/pytorch/pytorch/pull/175056) [ROCm] Enable mixed-precision batchnorm tests with relaxed t (@roshanrateria)
- Opened: [#175055](https://github.com/pytorch/pytorch/pull/175055) [ROCm] Fix test_profiler_cuda_sync_events for ROCTracer (@roshanrateria)
- Opened: [#175021](https://github.com/pytorch/pytorch/pull/175021) [ROCm] Fix multi-arch AOT Inductor compilation with newer Tr (@chinmaydk99)
- Opened: [#175054](https://github.com/pytorch/pytorch/pull/175054) [ROCm] Fix test_compile_kernel_advanced TF32 precision misma (@roshanrateria)
- Opened: [#175053](https://github.com/pytorch/pytorch/pull/175053) [ROCm/CUDA] Fix bfloat16 reflection padding decomposition te (@roshanrateria)
- Opened: [#175050](https://github.com/pytorch/pytorch/pull/175050) [ROCm] Enable test_sac_ilp_case1 on MI300/MI350 (@roshanrateria)
- Opened: [#175157](https://github.com/pytorch/pytorch/pull/175157) add nightly build option to FA3 build workflows (@liangel-02)
- Opened: [#175074](https://github.com/pytorch/pytorch/pull/175074) [inductor] Decompose addmm to pointwise ops when K==1 (@romanmeta)
- Opened: [#175159](https://github.com/pytorch/pytorch/pull/175159) [ROCm] forward fix #174087, take 4 (@pytorchbot)
- Opened: [#175163](https://github.com/pytorch/pytorch/pull/175163) Thread nondet_tol through _test_batched_grad_forward_ad (@CalebisGross)
- Opened: [#175161](https://github.com/pytorch/pytorch/pull/175161) Increase test_Linear TF32 tolerance for ROCm (@CalebisGross)
- Opened: [#175162](https://github.com/pytorch/pytorch/pull/175162) Increase TransformerEncoderLayer gelu TF32 tolerance for ROC (@CalebisGross)
- Opened: [#175148](https://github.com/pytorch/pytorch/pull/175148) [ROCm] Remove stale paths from hipify build script (@CalebisGross)
- Opened: [#175097](https://github.com/pytorch/pytorch/pull/175097) [DO NOT REBASE][ROCm][Inductor] New Inductor benchmarker bas (@naromero77amd)

### jax
- Opened: [#35111](https://github.com/jax-ml/jax/pull/35111) [ROCm] Add ROCm support for eigh export backwards compatibil (@AratiGanesh)
- Opened: [#35115](https://github.com/jax-ml/jax/pull/35115) [ROCm] Add hip_threefry2x32_ffi to stable custom call target (@AratiGanesh)
- Opened: [#35102](https://github.com/jax-ml/jax/pull/35102) [ROCm] Set release rpaths to rocm so targets (@alekstheod)
- Opened: [#35091](https://github.com/jax-ml/jax/pull/35091) fixed scan crash on GPU with non-default matmul precision (@sarayusapa)
- Opened: [#34971](https://github.com/jax-ml/jax/pull/34971) [ROCm] fix the performance issue when n=1 or 2 (@cj401-amd)
- Opened: [#35072](https://github.com/jax-ml/jax/pull/35072) A few pre-commit tweaks (@superbobry)

## New Issues This Week

### vllm
- [#34583](https://github.com/vllm-project/vllm/issues/34583) [Bug] Missing Vocabulary Validation for MTP and Eagle Specul (@amadhan882)
- [#34650](https://github.com/vllm-project/vllm/issues/34650) Bug: Speculative Decoding (MTP) Causes </think> Detection Fa (@cicirori)
- [#34437](https://github.com/vllm-project/vllm/issues/34437) [Bug]: Qwen3 Next with heterogeneous GPU (FP8 overflow?) (@Nepherpitou)
- [#34619](https://github.com/vllm-project/vllm/issues/34619) [Bug]: Qwen3.5. `illegal memory access` (@vadiklyutiy)
- [#34705](https://github.com/vllm-project/vllm/issues/34705) [Bug]: Old torch compile files cause poor CPU utilisation (@almayne)
- [#34694](https://github.com/vllm-project/vllm/issues/34694) [Bug]: BF16 NVFP4 Marlin produces garbled output on GPUs wit (@ricky-chaoju)
- [#34684](https://github.com/vllm-project/vllm/issues/34684) [Bug]: Qwen3.5-397B-A17B - reasoning in content with qwen3 r (@FWao)
- [#34449](https://github.com/vllm-project/vllm/issues/34449) [Bug]: GLM-5-FP8 malformed tool calls (@TALLEC-Scott)
- [#34256](https://github.com/vllm-project/vllm/issues/34256) [Model Performance SIG]: Improve MoE Oracle (@robertgshaw2-redhat)
- [#34573](https://github.com/vllm-project/vllm/issues/34573) [Installation/Runtime]: Linux ROCM7 /  RuntimeError: No HIP  (@NickJLange)
- [#34331](https://github.com/vllm-project/vllm/issues/34331) [RFC]: Ahead of time dequantization of weights for quantizat (@fxmarty-amd)
- [#34641](https://github.com/vllm-project/vllm/issues/34641) [ROCm] Default VLLM_ROCM_USE_AITER_FP4BMM=True crashes on MI (@khairulkabir1661)
- [#34634](https://github.com/vllm-project/vllm/issues/34634) [Bug]: SharedStorageConnector: vectorized_gather_kernel asse (@mmkamani7)
- [#34637](https://github.com/vllm-project/vllm/issues/34637) [CI Failure]:  mi325_1: Entrypoints Integration Test (API Se (@AndreasKaratzas)
- [#34561](https://github.com/vllm-project/vllm/issues/34561) [Bug]: GLM-4.7-Flash-AWQ fails with AttributeError: 'ColumnP (@eugr)
- [#34399](https://github.com/vllm-project/vllm/issues/34399) [Bug]: Nemotron 3 (all quants) take a LONG time to load (@jiangwu300)
- [#34579](https://github.com/vllm-project/vllm/issues/34579) [Performance]: vLLM's throughput lags behind llama.cpp for s (@kathirvel-balakrishnan)
- [#34545](https://github.com/vllm-project/vllm/issues/34545) [Installation]: unrecognized arguments: --omni (@HenryBao91)

### sglang
- [#18812](https://github.com/sgl-project/sglang/issues/18812) [Bug] RotaryEmbedding fallback requires CUDA_HOME on HIP (@alphabetc1)
- [#18749](https://github.com/sgl-project/sglang/issues/18749) [Bug] DP Attention FP4 Disagg AMD is broken (@functionstackx)

### pytorch
- [#174695](https://github.com/pytorch/pytorch/issues/174695) [Inductor] Missing host-side synchronization after non-block (@jeffdaily)
- [#174884](https://github.com/pytorch/pytorch/issues/174884) Inductor BF16 training crashes with autograd INTERNAL ASSERT (@kumartanmay-28)
- [#174949](https://github.com/pytorch/pytorch/issues/174949) [vllm] CUBLAS_STATUS_INVALID_VALUE in cublasGemmEx after upg (@ZJY0516)
- [#175025](https://github.com/pytorch/pytorch/issues/175025) Mega-Cache generate mismatched guard states when loading the (@liyineeek-source)
- [#174919](https://github.com/pytorch/pytorch/issues/174919) UNSTABLE inductor / inductor-test / test (inductor_torchbenc (@xmfan)
- [#175160](https://github.com/pytorch/pytorch/issues/175160) check if file exsits before hipifying (@trixirt)
- [#174682](https://github.com/pytorch/pytorch/issues/174682) spin lint doesn't regenerate cuda headers (@albanD)
- [#174943](https://github.com/pytorch/pytorch/issues/174943) CrossEntropyLoss missing type validation on MPS (@UjasShah)
- [#175145](https://github.com/pytorch/pytorch/issues/175145) [torch.disitributed] Persistent Deadlock when overlapping NC (@ilmarkov)
- [#175058](https://github.com/pytorch/pytorch/issues/175058) torch.compile VRAM usage regression between 2.9.1 and 2.10.0 (@dxqb)
- [#175057](https://github.com/pytorch/pytorch/issues/175057) torch.compile / Inductor generates invalid C++ (undeclared z (@griffinstalha)
- [#175143](https://github.com/pytorch/pytorch/issues/175143) UNSTABLE inductor-periodic / rocm-periodic-dynamo-benchmarks (@xmfan)
- [#175142](https://github.com/pytorch/pytorch/issues/175142) UNSTABLE inductor-periodic / rocm-periodic-dynamo-benchmarks (@xmfan)
- [#175141](https://github.com/pytorch/pytorch/issues/175141) UNSTABLE inductor-periodic / rocm-periodic-dynamo-benchmarks (@xmfan)
- [#175140](https://github.com/pytorch/pytorch/issues/175140) UNSTABLE inductor-periodic / rocm-periodic-dynamo-benchmarks (@xmfan)
- [#175139](https://github.com/pytorch/pytorch/issues/175139) UNSTABLE inductor-periodic / rocm-periodic-dynamo-benchmarks (@xmfan)
- [#174794](https://github.com/pytorch/pytorch/issues/174794) REGRESSION: Shadowed variable name crashes `torch.compile` i (@rwkeane)
- [#174984](https://github.com/pytorch/pytorch/issues/174984) `torch.fft.rfft` errors out with MKL FFT error when given an (@SilentTester73)
- [#174763](https://github.com/pytorch/pytorch/issues/174763) torch._grouped_mm is not autocast-compatible, causes dtype m (@Mr-Neutr0n)
- [#175064](https://github.com/pytorch/pytorch/issues/175064) DISABLED test_index (__main__.DistTensorOpsTest) (@seemethere)
- [#174986](https://github.com/pytorch/pytorch/issues/174986) `torch.istft` returns an unhelpful internal error (@SilentTester73)
- [#174985](https://github.com/pytorch/pytorch/issues/174985) `torch.isclose` fails with a broadcast when comparing with ` (@SilentTester73)
- [#174939](https://github.com/pytorch/pytorch/issues/174939) `torch.nn.functional.scaled_dot_product_attention` crashes w (@Nyovelt)
- [#174913](https://github.com/pytorch/pytorch/issues/174913) Test: TestLinalg.test_tensorinv (@jeffdaily)
